{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b88be0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UTTT(\n",
      "  (conv1): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.09, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.09, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.09, affine=True, track_running_stats=True)\n",
      "  (res2): ResidualBlock(\n",
      "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.09, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.09, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (res3): ResidualBlock(\n",
      "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.09, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.09, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (fc1): Linear(in_features=10368, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (pi): Linear(in_features=256, out_features=81, bias=True)\n",
      "  (v): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "from functools import lru_cache\n",
    "from multiprocessing import Pool\n",
    "import concurrent.futures\n",
    "\n",
    "from utils import State, Action, is_terminal, change_state, get_all_valid_actions, terminal_utility, is_valid_action, invert\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "#we can stack arbitrary number of Residualblock\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(channels, eps=1e-5, momentum=0.09)\n",
    "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(channels, eps=1e-5, momentum=0.09)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        return F.relu(out + residual)  # Skip connection\n",
    "\n",
    "#if using batchnorm, bias=False, can add additional FC/conv layer also\n",
    "class UTTT(nn.Module):\n",
    "    def __init__(self, residual=True, size=0, layers=\"MAX\", batchnorm=True):\n",
    "        super(UTTT, self).__init__()\n",
    "        \n",
    "        self.channels = 128 // (2**size)\n",
    "        self.residual = residual\n",
    "        self.fc_size1 = 512 if not size else 256 if layers==\"MAX\" else 128\n",
    "        self.fc_size2 = 256 if not size else 128\n",
    "        self.layers = layers\n",
    "        self.batchnorm = batchnorm\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, self.channels, kernel_size=3, stride=1, padding=1, bias= not self.batchnorm)\n",
    "        self.bn1 = nn.BatchNorm2d(self.channels, eps=1e-5, momentum=0.09) if self.batchnorm else None\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(self.channels, self.channels, kernel_size=3, stride=1, padding=1, bias= not self.batchnorm)\n",
    "        self.bn2 = nn.BatchNorm2d(self.channels, eps=1e-5, momentum=0.09) if self.batchnorm else None\n",
    "        self.conv3 = nn.Conv2d(self.channels, self.channels, kernel_size=3, stride=1, padding=1, bias= not self.batchnorm) if self.layers==\"MAX\" else None\n",
    "        self.bn3 = nn.BatchNorm2d(self.channels, eps=1e-5, momentum=0.09) if self.layers==\"MAX\" and self.batchnorm else None\n",
    "        \n",
    "        self.res2 = ResidualBlock(self.channels) if self.residual else None\n",
    "        self.res3 = ResidualBlock(self.channels) if self.residual else None\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(self.channels * 9 * 9, self.fc_size1)  # Input size: 128 filters × 9 × 9\n",
    "        self.fc2 = nn.Linear(self.fc_size1, self.fc_size2) if self.layers==\"MAX\" else None\n",
    "\n",
    "        # Output layers\n",
    "        self.pi = nn.Linear(self.fc_size2, 81)  # Policy output (Softmax for move probabilities)\n",
    "        self.v = nn.Linear(self.fc_size2, 1)    # Value output (Tanh for game state evaluation)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x))) if self.batchnorm else F.relu(self.conv1(x))\n",
    "\n",
    "        # Residual connections\n",
    "        if self.residual:\n",
    "            x = self.res2(x)\n",
    "            x = self.res3(x)\n",
    "        else:\n",
    "            x = F.relu(self.bn2(self.conv2(x))) if self.batchnorm else F.relu(self.conv2(x))\n",
    "            if self.layers==\"MAX\":\n",
    "                x = F.relu(self.bn3(self.conv3(x))) if self.batchnorm else F.relu(self.conv3(x))\n",
    "\n",
    "        # Flatten and pass through FC layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        if self.layers==\"MAX\":\n",
    "            x = F.relu(self.fc2(x))\n",
    "\n",
    "        # Outputs\n",
    "        pi = F.softmax(self.pi(x), dim=1)  # Policy head (logits, apply softmax in loss function)\n",
    "        v = F.tanh(self.v(x))  # Value head (range [-1, 1])\n",
    "\n",
    "        return pi, v\n",
    "\n",
    "    \n",
    "# Instantiate the model\n",
    "model = UTTT()\n",
    "model.to(device)\n",
    "\n",
    "# Define the optimizer\n",
    "def get_optimizer(model, lr=0.0001):\n",
    "    return optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Define loss functions\n",
    "def compute_policy_loss(predicted_policy, true_policy):\n",
    "    #return nn.CrossEntropyLoss()(predicted_policy, true_policy)\n",
    "    policy_loss_fn = torch.nn.CrossEntropyLoss()  # For policy (classification)\n",
    "    return policy_loss_fn(predicted_policy, true_policy)\n",
    "\n",
    "def compute_value_loss(predicted_value, true_value):\n",
    "    #return nn.MSELoss()(predicted_value, true_value)\n",
    "    value_loss_fn = torch.nn.MSELoss()  # For value (regression)\n",
    "    return value_loss_fn(predicted_value, true_value)\n",
    "\n",
    "# Print model summary\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c71d67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def board_to_array(state):\n",
    "    \"\"\"\n",
    "    Convert the Ultimate Tic-Tac-Toe board state into a 9x9 array, making sure it's hashable.\n",
    "    \n",
    "    Args:\n",
    "        state: The current game state (State object).\n",
    "        mini_board: The index of the mini-board where the next move should be made.\n",
    "        current_player: The player whose turn it is (1 or -1).\n",
    "    \n",
    "    Returns:\n",
    "        A NumPy array (2, 9, 9) representation of the board (with current player layer).\n",
    "    \"\"\"\n",
    "    player = 1 if state.fill_num==1 else -1\n",
    "    \n",
    "    # Get the board from the state\n",
    "    board = state.board  # This is a 3x3x3x3 ndarray\n",
    "\n",
    "    # Flatten the 3x3x3x3 board into a 9x9 representation\n",
    "    board_array = np.zeros((9, 9), dtype=np.float32)\n",
    "\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            for k in range(3):\n",
    "                for l in range(3):\n",
    "                    board_array[i * 3 + k][j * 3 + l] = board[i][j][k][l]\n",
    "\n",
    "    # Normalize the board values with flip\n",
    "    board_array[board_array == 1] = 1.0 * player\n",
    "    board_array[board_array == 2] = -1.0 * player\n",
    "    board_array[board_array == 0] = 0.0\n",
    "\n",
    "    return np.array(board_array)\n",
    "\n",
    "def action_to_index(action):\n",
    "    \"\"\"\n",
    "    Convert the action tuple (meta_row, meta_col, local_row, local_col) into an integer index for the 9x9 grid.\n",
    "\n",
    "    Args:\n",
    "        action: Tuple (meta_row, meta_col, local_row, local_col) representing the coordinates on the boards.\n",
    "    \n",
    "    Returns:\n",
    "        Integer index corresponding to the 9x9 grid.\n",
    "    \"\"\"\n",
    "    meta_row, meta_col, local_row, local_col = action\n",
    "    \n",
    "    # Map meta-board (meta_row, meta_col) to a flat index in the range [0, 8]\n",
    "    meta_index = meta_row * 3 + meta_col  # 3x3 meta-board\n",
    "    \n",
    "    # Map local-board (local_row, local_col) to a flat index in the range [0, 8]\n",
    "    local_index = local_row * 3 + local_col  # 3x3 local-board\n",
    "    \n",
    "    # Final index in the flattened 9x9 grid\n",
    "    return meta_index * 9 + local_index  # 9x9 flattened grid\n",
    "\n",
    "def index_to_action(index: int) -> Action:\n",
    "    \"\"\"\n",
    "    Convert an action index back to the action tuple (meta_row, meta_col, local_row, local_col).\n",
    "    \n",
    "    Args:\n",
    "        index (int): The action index.\n",
    "        \n",
    "    Returns:\n",
    "        Action: The corresponding action tuple (meta_row, meta_col, local_row, local_col).\n",
    "    \"\"\"\n",
    "    # Calculate the meta-row and meta-column from the index\n",
    "    meta_row = index // 27\n",
    "    meta_col = (index % 27) // 9\n",
    "    \n",
    "    # Calculate the local row and local column from the index\n",
    "    local_row = (index % 9) // 3\n",
    "    local_col = index % 3\n",
    "    \n",
    "    return (meta_row, meta_col, local_row, local_col)\n",
    "\n",
    "def normalize_policy(policy):\n",
    "    \"\"\"\n",
    "    Normalize the policy and ensure no NaN or infinite values.\n",
    "    \n",
    "    Args:\n",
    "        policy: A numpy array containing the policy probabilities for each action.\n",
    "        valid_mask: A mask array where valid actions are 1, invalid actions are 0.\n",
    "    \n",
    "    Returns:\n",
    "        A normalized policy.\n",
    "    \"\"\"    \n",
    "    # Check if any valid actions are left\n",
    "    if np.sum(policy) > 0:\n",
    "        policy = policy / np.sum(policy)  # Normalize\n",
    "    else:\n",
    "        # If no valid actions, reset to uniform distribution over valid actions\n",
    "        policy = np.ones_like(policy) / len(policy)\n",
    "    \n",
    "    # Check for NaN or infinite values in the policy and reset if needed\n",
    "    if np.any(np.isnan(policy)) or np.any(np.isinf(policy)):\n",
    "        policy = np.ones_like(policy) / len(policy)  # Reset to uniform distribution\n",
    "    \n",
    "    return policy\n",
    "\n",
    "def state_to_tensor(state):\n",
    "    return torch.tensor(board_to_array(state), dtype=torch.float32).unsqueeze(0).unsqueeze(1).to(device)  # Add batch and channel dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cb76a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    __slots__ = ('state', 'children', 'N', 'W', 'Q', 'P')\n",
    "    def __init__(self, state):\n",
    "        self.state = state\n",
    "        #self.parent = parent\n",
    "        #self.action = action\n",
    "        #self.action_probability = None\n",
    "        self.children = []\n",
    "        \n",
    "        self.N = 0\n",
    "        #self.visit_count = 0\n",
    "        \n",
    "        self.W = 0\n",
    "        #self.total_reward = 0 self.state_value_sum = 0.0\n",
    "        \n",
    "        self.Q = 0\n",
    "        #self.q_value = 0 self.state_value_mean = 0.0\n",
    "        \n",
    "        self.P = None\n",
    "        #self.prior_policy = None self.state_value = None\n",
    "\n",
    "    def is_leaf(self):\n",
    "        return len(self.children) == 0\n",
    "    \n",
    "    def is_terminal(self):\n",
    "        return is_terminal(self.state)\n",
    "    \n",
    "    def no_valid_actions(self):\n",
    "        return len(get_all_valid_actions(self.state)) == 0\n",
    "    \n",
    "    def best_child(self, cpuct): #cpuct=exploration_weight\n",
    "        #return max(self.children, key=lambda child: child.W / child.N + cpuct * child.P * math.sqrt(math.log(self.N) / (1 + child.N)))\n",
    "        #return max(self.children, key=lambda child: child.Q + cpuct * child.P * math.sqrt(self.N) / (1 + child.N))\n",
    "        #values = np.array([child.W / child.N + cpuct * child.P * np.sqrt(np.log(self.N) / (1 + child.N)) for child in self.children])\n",
    "        #values = np.array([child.Q + cpuct * child.P * np.sqrt(self.N) / (1 + child.N) for child in self.children])\n",
    "        values = np.array([-child.Q + cpuct * child.P * np.sqrt(self.N) / (1 + child.N) for child in self.children])\n",
    "        best_idx = np.argmax(values)\n",
    "        return self.children[best_idx], best_idx\n",
    "    \n",
    "    def best_action(self, cpuct):\n",
    "        return get_all_valid_actions(self.state)[self.best_child(cpuct)[1]]\n",
    "\n",
    "    \n",
    "class MCTS:\n",
    "    __slots__ = ('model', 'cpuct', 'tree')\n",
    "    def __init__(self, model, cpuct=2.0):\n",
    "        self.model = model\n",
    "        self.cpuct = cpuct\n",
    "        self.tree = {}\n",
    "    \n",
    "    def search(self, root_state, simulations=200):\n",
    "        root = self.get_or_create_node(root_state)\n",
    "        \n",
    "        if root.is_terminal() or root.no_valid_actions():\n",
    "            return\n",
    "        \n",
    "        for _ in range(simulations):\n",
    "            node = root\n",
    "            path = [node]\n",
    "            \n",
    "            # Selection\n",
    "            while not node.is_leaf():\n",
    "                node = node.best_child(self.cpuct)[0]\n",
    "                path.append(node)\n",
    "            \n",
    "            pi, v = self.model(self.get_state_tensor(node.state))\n",
    "            v = v.item()\n",
    "            \n",
    "            # Expansion\n",
    "            if not node.is_terminal() and not node.no_valid_actions():\n",
    "                valid_actions = get_all_valid_actions(node.state)\n",
    "                self.expand_node(node, valid_actions, pi)\n",
    "            \n",
    "            # Evaluation\n",
    "            v = self.evaluate(node, v)\n",
    "            \n",
    "            # Backpropagation\n",
    "            for node in reversed(path):\n",
    "                node.N += 1\n",
    "                node.W += v\n",
    "                node.Q = node.W / node.N\n",
    "                v *= -1\n",
    "            #print(path)\n",
    "        return root.best_action(self.cpuct)\n",
    "    \n",
    "    def expand_node(self, node, valid_actions, pi):\n",
    "        valid_mask = np.zeros(81)\n",
    "        action_idxs = [action_to_index(a) for a in valid_actions]\n",
    "        valid_mask[action_idxs] = 1\n",
    "        pi = pi.detach().cpu().numpy().reshape(81) * valid_mask  # Convert to numpy and apply valid mask\n",
    "        pi = pi / np.sum(pi)  # Normalize the policy to sum to 1\n",
    "        for action, action_idx in zip(valid_actions, action_idxs):\n",
    "            child_state = change_state(node.state, action)\n",
    "            child_node = Node(child_state)\n",
    "            child_node.P = pi[action_idx]\n",
    "            node.children.append(child_node)\n",
    "\n",
    "    def evaluate(self, node, v):\n",
    "        if is_terminal(node.state):\n",
    "            #return 2*terminal_utility(node.state)-1\n",
    "            #return 0 if 2*terminal_utility(node.state)-1==0 else 1\n",
    "            return 0 if 2*terminal_utility(node.state)-1==0 else -1\n",
    "            #remember v is utility to current player. so terminal state, current player to move loses so -1\n",
    "            #otherwise, model predicts v which is utiilty for current player\n",
    "            #then we need to use -child.Q since we are maximizing (from POV of current player)\n",
    "            #i.e. current player wants to find most -ve child.Q since that is worst for child -> best for current\n",
    "        return v\n",
    "    \n",
    "    def get_or_create_node(self, state):\n",
    "        state_tuple = tuple(map(tuple, board_to_array(state)))\n",
    "        if state_tuple not in self.tree:\n",
    "            self.tree[state_tuple] = Node(state)\n",
    "        return self.tree[state_tuple]\n",
    "    \n",
    "    #@lru_cache(maxsize=10000)\n",
    "    def get_state_tensor(self, state):\n",
    "        return torch.tensor(board_to_array(state), dtype=torch.float32).unsqueeze(0).unsqueeze(1).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9ce362d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "train_episodes = 100\n",
    "mcts_search = 200 #100 #400 #600\n",
    "n_pit_network = 50 #20\n",
    "threshold = 0.52 #0.50 #0.55\n",
    "temperature = 0.05 #lower is more deterministic\n",
    "playgames_before_training = 2 #4 #5 #25\n",
    "parallel_games = 8\n",
    "cpuct = 2\n",
    "training_epochs = 4\n",
    "learning_rate = 0.0001\n",
    "save_model_path = 'training'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef656512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action_probs(state, mcts, simulations=200):\n",
    "    \"\"\"\n",
    "    Get the action probabilities from the MCTS search for a given board state.\n",
    "    \n",
    "    Args:\n",
    "        state: The initial game state (State object).\n",
    "        mcts: The MCTS instance used for search.\n",
    "        simulations: Number of MCTS simulations to run.\n",
    "    \n",
    "    Returns:\n",
    "        action_probs: A numpy array of size 81 representing the action probabilities.\n",
    "    \"\"\"\n",
    "    # Perform MCTS search\n",
    "    #best_action = mcts.search(state, simulations)\n",
    "    mcts.search(state, simulations)\n",
    "    \n",
    "    print(\"Done one iteration of MCTS\")\n",
    "    \n",
    "    # Initialize action probabilities\n",
    "    action_probs = np.zeros(81)\n",
    "    \n",
    "    # Get visit counts for valid actions\n",
    "    root_node = mcts.get_or_create_node(state)\n",
    "    #child_Ns = {child.action: child.N for child in root_node.children}\n",
    "    child_Ns = {get_all_valid_actions(root_node.state)[idx]: child.N for idx, child in enumerate(root_node.children)}\n",
    "    \n",
    "    if root_node.N > 0:\n",
    "        for action, N in child_Ns.items():\n",
    "            action_probs[action_to_index(action)] = N / root_node.N\n",
    "    #print(state, action_probs)\n",
    "    return action_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29e20859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def playgame(mcts, simulations=200):\n",
    "    \"\"\"\n",
    "    Simulate one game of Ultimate Tic-Tac-Toe, utilizing MCTS for decision-making.\n",
    "    \n",
    "    Args:\n",
    "        mcts: The MCTS instance used for decision-making.\n",
    "        simulations: Number of MCTS simulations per move.\n",
    "    \n",
    "    Returns:\n",
    "        game_mem: A list of game memory (state, player, action probability, game result).\n",
    "    \"\"\"\n",
    "    game_mem = []\n",
    "    state = State()\n",
    "    \n",
    "    while True:\n",
    "        #print(state)\n",
    "        # Check if the game is over\n",
    "        if len(get_all_valid_actions(state)) == 0 or is_terminal(state):\n",
    "            #need to include terminal state? but what policy to put?\n",
    "            #remember model predicts utility for current player, so\n",
    "            #if result==1 (p1 win) and current player==1 then 1*1=1\n",
    "            #if result==1 (p1 win) and current player==2 then 1*-1=-1\n",
    "            #if result==-1 (p2 win) and current player==1 then -1*1=-1\n",
    "            #if result==-1 (p2 win) and current player==2 then -1*-1=1\n",
    "            result = 2*terminal_utility(state)-1\n",
    "            for mem in game_mem:\n",
    "                mem[3] = result * (1 if mem[1]==1 else -1)\n",
    "            return game_mem\n",
    "\n",
    "        # Get action probabilities using MCTS\n",
    "        policy = get_action_probs(state, mcts, simulations)\n",
    "        policy = policy / np.sum(policy)  # Normalize the policy\n",
    "        #game_mem.append([board_to_array(state), state.fill_num, policy, None])\n",
    "        game_mem.append([state, state.fill_num, policy, None])\n",
    "        \n",
    "        # Choose an action based on the policy\n",
    "        action_index = np.random.choice(len(policy), p=policy)\n",
    "        action = index_to_action(action_index)\n",
    "        \n",
    "        #print(\"Policy:\", policy)\n",
    "        #print(\"Chosen action:\", action)\n",
    "        \n",
    "        state = change_state(state, action)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6228325f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action_probs_batch(states, mcts, simulations):\n",
    "    \"\"\"\n",
    "    Get action probabilities from MCTS for a batch of states.\n",
    "    \n",
    "    Args:\n",
    "        states: List of `State` objects.\n",
    "        mcts: The MCTS instances used for search.\n",
    "        simulations: Number of MCTS simulations per move.\n",
    "    \n",
    "    Returns:\n",
    "        action_probs: A NumPy array of shape (num_games, 81).\n",
    "    \"\"\"\n",
    "    num_games = len(states)\n",
    "    action_probs = np.zeros((num_games, 81))\n",
    "\n",
    "    # Run MCTS searches in parallel\n",
    "    with Pool(processes=num_games) as pool:\n",
    "        best_actions = pool.starmap(mcts.search, [(state, simulations) for state in states])\n",
    "\n",
    "    print(\"Done one iteration of MCTS\")\n",
    "\n",
    "    # Compute visit counts for valid actions\n",
    "    for i, state in enumerate(states):\n",
    "        root_node = mcts.get_or_create_node(state)\n",
    "        child_Ns = {get_all_valid_actions(root_node.state)[idx]: child.N for idx, child in enumerate(root_node.children)}\n",
    "\n",
    "        if root_node.N > 0:\n",
    "            for action, N in child_Ns.items():\n",
    "                action_probs[i, action_to_index(action)] = N / root_node.N\n",
    "    \n",
    "    return action_probs\n",
    "\n",
    "\n",
    "def playgames(mctss, num_games=8, simulations=200):\n",
    "    \"\"\"\n",
    "    Run multiple games in parallel using batched MCTS.\n",
    "    \n",
    "    Args:\n",
    "        mctss: List of MCTS instances\n",
    "        num_games: Number of games to run in parallel.\n",
    "        simulations: Number of MCTS simulations per move.\n",
    "    \n",
    "    Returns:\n",
    "        games_mem: A list containing `num_games` game memory logs.\n",
    "    \"\"\"\n",
    "    games_mem = [[] for _ in range(num_games)]\n",
    "    states = [State() for _ in range(num_games)]\n",
    "    active_games = np.ones(num_games, dtype=bool)  # Track which games are still running\n",
    "\n",
    "    while active_games.any():\n",
    "        # Apply actions and check game termination\n",
    "        for i in range(num_games):\n",
    "            if active_games[i]:\n",
    "                if len(get_all_valid_actions(states[i])) == 0 or is_terminal(states[i]):\n",
    "                    #remember model predicts utility for current player, so\n",
    "                    #if result==1 (p1 win) and current player==1 then 1*1=1\n",
    "                    #if result==1 (p1 win) and current player==2 then 1*-1=-1\n",
    "                    #if result==-1 (p2 win) and current player==1 then -1*1=-1\n",
    "                    #if result==-1 (p2 win) and current player==2 then -1*-1=1\n",
    "                    result = 2*terminal_utility(states[i])-1\n",
    "                    for mem in games_mem[i]:\n",
    "                        mem[3] = result * (1 if mem[1]==1 else -1)\n",
    "                    active_games[i] = False  # Mark game as finished\n",
    "        \n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=num_games) as executor:\n",
    "            results = executor.map(lambda mcts,state: get_action_probs(state,mcts,simulations), mctss, states)\n",
    "        \n",
    "        policies = list(results)\n",
    "        \n",
    "        # Get action probabilities using batched MCTS\n",
    "        #policies = get_action_probs_batch(states, mctss, simulations)\n",
    "        #policies = np.nan_to_num([policy/np.sum(policy) for policy in policies], nan=1/81)\n",
    "        \n",
    "        # Sample actions using the policies\n",
    "        #action_indices = np.array([np.random.choice(81, p=policy) for policy in policies])\n",
    "        #actions = [index_to_action(int(idx)) for idx in action_indices]\n",
    "        \n",
    "        # Save state, player, policy in memory\n",
    "        for i in range(num_games):\n",
    "            if active_games[i]:\n",
    "                policy = policies[i] / np.sum(policies[i])  # Normalize policy\n",
    "                #games_mem[i].append([board_to_array(states[i]), states[i].fill_num, policies[i], None])\n",
    "                #games_mem[i].append([board_to_array(states[i]), states[i].fill_num, policy, None])\n",
    "                games_mem[i].append([states[i], states[i].fill_num, policy, None])\n",
    "                action_index = np.random.choice(len(policy), p=policy)\n",
    "                action = index_to_action(action_index)\n",
    "                #states[i] = change_state(states[i], actions[i])\n",
    "                states[i] = change_state(states[i], action)\n",
    "    \n",
    "    return games_mem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33ee01b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_playgame():\n",
    "    mcts = MCTS(model, cpuct)\n",
    "    start_time = time.time()\n",
    "    p=[]\n",
    "    for _ in range(parallel_games):\n",
    "        p.append(playgame(mcts))\n",
    "    end_time = time.time()\n",
    "    print(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80ae45ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_playgames():\n",
    "    mctss = [MCTS(model, cpuct) for _ in range(parallel_games)]\n",
    "    start_time=time.time()\n",
    "    ps=playgames(mctss,parallel_games)\n",
    "    end_time=time.time()\n",
    "    print(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2d5f8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, games_mem, epochs=4, batch_size=32, lr=0.0001):\n",
    "    \"\"\"\n",
    "    Train the neural network using the game memory (states, policies, and results).\n",
    "    \n",
    "    Args:\n",
    "        model: The neural network model to train.\n",
    "        games_mem: A list of list of game memories, each containing [state_array, current_player, policy, result].\n",
    "    \n",
    "    Returns:\n",
    "        model: The trained model.\n",
    "    \"\"\"\n",
    "    print(\"Training Network\")\n",
    "    sumlen =sum([len(game_mem) for game_mem in games_mem])\n",
    "    print(\"Length of game_mem:\", sumlen)\n",
    "    \n",
    "    states = []\n",
    "    policies = []\n",
    "    values = []\n",
    "\n",
    "    # Prepare the training data from game memory\n",
    "    for game_mem in games_mem:\n",
    "        for mem in game_mem:\n",
    "            # Extract state, policy, and result (value)\n",
    "            states.append(mem[0])  # mem[0] is the board state\n",
    "            policies.append(mem[2])  # mem[2] is the action policy\n",
    "            values.append(mem[3])   # mem[3] is the game result (1, 0, or -1)\n",
    "        \n",
    "    states = torch.stack([state_to_tensor(state) for state in states])\n",
    "    policies = torch.tensor(policies, dtype=torch.float32).to(device)\n",
    "    values = torch.tensor(values, dtype=torch.float32).to(device)\n",
    "    \n",
    "    #state = np.array(state)  # Convert the list of states to a numpy array\n",
    "    #policy = np.array(policy)  # Convert the list of policies to a numpy array\n",
    "    #value = np.array(value)  # Convert the list of values to a numpy array\n",
    "        \n",
    "    #states = torch.tensor(np.array(state), dtype=torch.float32).to(device)\n",
    "    #policies = torch.tensor(np.array(policy), dtype=torch.float32).to(device)\n",
    "    #values = torch.tensor(np.array(value), dtype=torch.float32).to(device)\n",
    "\n",
    "    # Train the neural network on the collected data\n",
    "    #states = states.unsqueeze(0)  # Add channel dimension, resulting shape: [batch_size, 1, 9, 9]\n",
    "    optimizer = get_optimizer(model,lr)\n",
    "    #Training loop\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "\n",
    "        # Shuffle the game memory for each epoch\n",
    "        indices = torch.randperm(sumlen)\n",
    "        states = states[indices]\n",
    "        policies = policies[indices]\n",
    "        values = values[indices]\n",
    "\n",
    "        # Mini-batch training\n",
    "        for i in range(0, sumlen, batch_size):\n",
    "            batch_states = states[i:i + batch_size]\n",
    "            batch_policies = policies[i:i + batch_size]\n",
    "            batch_values = values[i:i + batch_size]\n",
    "\n",
    "            # Zero the gradients\n",
    "            #optimizer.zero_grad()\n",
    "            for param in model.parameters:\n",
    "                param.grad=None\n",
    "            \n",
    "            total_loss = 0\n",
    "            \n",
    "            for j in range(batch_states.size(0)):\n",
    "                # Get the single state for the current iteration\n",
    "                #state_single = batch_states[j].unsqueeze(0).unsqueeze(1)  # Shape: [1, 1, 9, 9]\n",
    "                #policy_single = batch_policies[j].unsqueeze(0)  # Shape: [1, 81]\n",
    "                #value_single = batch_values[j]  # Shape: [1]\n",
    "                state_single = batch_states[j]\n",
    "                policy_single = batch_policies[j].unsqueeze(0)\n",
    "                value_single = batch_values[j].unsqueeze(0).unsqueeze(1)\n",
    "                \n",
    "                # Forward pass for the single state\n",
    "                predicted_policy, predicted_value = model(state_single)\n",
    "                \n",
    "                #print(predicted_policy.shape, policy_single.shape)\n",
    "                #print(predicted_value.shape, value_single.shape)\n",
    "\n",
    "                # Compute loss for the single state\n",
    "                policy_loss = compute_policy_loss(predicted_policy, policy_single)\n",
    "                value_loss = compute_value_loss(predicted_value, value_single)\n",
    "\n",
    "                # Accumulate the total loss\n",
    "                total_loss += (policy_loss + value_loss)\n",
    "\n",
    "            # Backpropagation\n",
    "            total_loss.backward()\n",
    "\n",
    "            # Optimizer step (update weights)\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1} completed.\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "facd529b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pit(old_model, new_model):\n",
    "    \"\"\"\n",
    "    Pits the old neural network (old_model) against the new one (new_model).\n",
    "    The new network must win at least 52% of games to be accepted.\n",
    "\n",
    "    Args:\n",
    "        old_model: The old neural network.\n",
    "        new_model: The newly trained neural network.\n",
    "\n",
    "    Returns:\n",
    "        True if the new network is better (win rate >= 52%), otherwise False.\n",
    "    \"\"\"\n",
    "    print(\"Pitting networks...\")\n",
    "\n",
    "    old_model_wins = 0\n",
    "    new_model_wins = 0\n",
    "    total_games = n_pit_network\n",
    "    nets = [None, old_model, new_model]\n",
    "\n",
    "    for game in range(total_games):\n",
    "        state = State()  # Start with an empty board\n",
    "        mover = 1 if game%2==0 else -1\n",
    "\n",
    "        while True:\n",
    "            # Select which network plays\n",
    "            net = nets[mover]\n",
    "            \n",
    "            # Get action probabilities from the network\n",
    "            pi, _ = net(state_to_tensor(state))\n",
    "\n",
    "            # Mask invalid actions\n",
    "            valid_actions = get_all_valid_actions(state)\n",
    "            if not valid_actions:\n",
    "                break  # No valid actions left, game is a tie\n",
    "   \n",
    "            valid_mask = np.zeros(81)\n",
    "            action_idxs = [action_to_index(a) for a in valid_actions]\n",
    "            valid_mask[action_idxs] = 1\n",
    "            pi = pi.detach().cpu().numpy().reshape(81) * valid_mask  # Convert to numpy and apply valid mask\n",
    "            pi = pi / np.sum(pi)  # Normalize the policy to sum to 1\n",
    "            \n",
    "            #the problem here is that in inference mode, you should take best move\n",
    "            #however, the normal alphazero method is to train the model to predict pi, v to improve MCTS\n",
    "            #then during gameplay to use the best move from the improved MCTS\n",
    "            #what is done here is instead to do MCTS and then use these to train the model to predict pi, v\n",
    "            #and to use the best move from the predicted policy\n",
    "            #since we need to train the model to predict v for use in minimax\n",
    "            #therefore we cannot use best move here since best move will be deterministic\n",
    "            # Choose the best move\n",
    "            #action_index = int(np.argmax(policy))\n",
    "            #action = torch.argmax(policy).item()\n",
    "            action_index = np.random.choice(len(pi), p=pi) #or add dirichlet noise and take max\n",
    "            \n",
    "            # Execute the move\n",
    "            #print(state, action_index)\n",
    "            state = change_state(state, index_to_action(action_index))\n",
    "            \n",
    "            if is_terminal(state):\n",
    "                #print(state)\n",
    "                if terminal_utility(state) == 1.0:  # Player 1 wins\n",
    "                    old_model_wins += 1 if game%2==0 else 0\n",
    "                    new_model_wins += 1 if game%2==1 else 0\n",
    "                if terminal_utility(state) == 0.0:  # Player 2 wins\n",
    "                    old_model_wins += 1 if game%2==1 else 0\n",
    "                    new_model_wins += 1 if game%2==0 else 0\n",
    "                break  # Game over\n",
    "\n",
    "            # Switch players            \n",
    "            mover *= -1\n",
    "\n",
    "    total_wins = old_model_wins + new_model_wins\n",
    "    \n",
    "    if total_wins == 0:\n",
    "        print(\"All games ended in a tie.\")\n",
    "        now = datetime.utcnow().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        filename = f'tictactoeTie{now}.pth'\n",
    "        model_path = os.path.join(save_model_path, filename)\n",
    "        torch.save(old_model.state_dict(), model_path)\n",
    "        return False\n",
    "\n",
    "    old_model_win_percent = old_model_wins / total_wins\n",
    "    new_model_win_percent = new_model_wins / total_wins\n",
    "    print(f\"Old NN win rate: {old_model_win_percent:.2%} ({old_model_wins} / {total_wins} wins)\")\n",
    "    print(f\"New NN win rate: {new_model_win_percent:.2%} ({new_model_wins} / {total_wins} wins)\")\n",
    "\n",
    "    if new_model_win_percent >= threshold:\n",
    "        print(\"The new network is better!\")\n",
    "        now = datetime.utcnow().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        filename = f'tictactoeWin{now}.pth'\n",
    "        model_path = os.path.join(save_model_path, filename)\n",
    "        torch.save(new_model.state_dict(), model_path)\n",
    "        return True\n",
    "    else:\n",
    "        print(\"The new network lost.\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c338a07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model = UTTT()\n",
    "#model.to(device)\n",
    "\n",
    "def train(episodes=100, num_games=8, simulations=200):\n",
    "    \"\"\"\n",
    "    Trains the neural network using self-play, MCTS, and reinforcement learning.\n",
    "    Saves the best model based on self-play evaluations.\n",
    "    \"\"\"\n",
    "    total_start_time = time.time()\n",
    "    \n",
    "    if os.path.isfile('temp.pth'):\n",
    "        print(\"Resuming training from last checkpoint\")\n",
    "        model.load_state_dict(torch.load('temp.pth', map_location=device))\n",
    "    else:\n",
    "        print(\"Starting training from scratch\")\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "\n",
    "    games_mem = []\n",
    "    \n",
    "    for episode in range(episodes):\n",
    "        print(f\"Episode {episode + 1}/{episodes}\")\n",
    "        start_time = time.time()\n",
    "        #print(start_time)\n",
    "        \n",
    "        # Save the current model as a temporary model\n",
    "        torch.save(model.state_dict(), 'temp.pth')\n",
    "        \n",
    "        # Load the saved model\n",
    "        #old_model = nn.__class__()  # Instantiate a new model of the same class\n",
    "        old_model = UTTT()\n",
    "        old_model.load_state_dict(torch.load('temp.pth'))\n",
    "        old_model.to(device)\n",
    "        \n",
    "        mctss = [MCTS(model, cpuct) for _ in range(parallel_games)]\n",
    "\n",
    "        # Self-play to generate training data\n",
    "        #for _ in range(playgames_before_training):\n",
    "            #games_mem += playgame()\n",
    "        games_mem += playgames(mctss, num_games=num_games, simulations=simulations)\n",
    "\n",
    "        # Train the network with collected data\n",
    "        train_model(model, games_mem)\n",
    "\n",
    "        # Clear memory after training\n",
    "        games_mem = []\n",
    "\n",
    "        # Compare old vs. new network through self-play\n",
    "        if pit(old_model, model):\n",
    "            del old_model\n",
    "        else:\n",
    "            # If new NN is worse, revert back to old NN\n",
    "            #model.load_state_dict(torch.load('temp.pth'))\n",
    "            model.load_state_dict(old_model.state_dict())\n",
    "            del old_model\n",
    "        \n",
    "        end_time = time.time()\n",
    "        #print(end_time)\n",
    "        \n",
    "        #print((end_time-start_time)/60)\n",
    "        print(f\"Episode {episode + 1} took {(end_time - start_time) / 60} minutes.\")\n",
    "\n",
    "    # Save the final trained model\n",
    "    now = datetime.utcnow().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    filename = f'tictactoe_MCTS{episodes}_{now}.pth'\n",
    "    model_path = os.path.join(save_model_path, filename)\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    torch.save(model.state_dict(), 'temp.pth')\n",
    "    print(f\"Training complete. Model saved as {filename}\")\n",
    "    \n",
    "    total_end_time = time.time()\n",
    "    print(f\"Training {episodes} took {(total_end_time - total_start_time) / 3600} hours.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "793557a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming training from last checkpoint\n",
      "Starting training...\n",
      "Episode 1/20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_288143/1684811105.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_288143/3625383239.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(episodes, num_games, simulations)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m#for _ in range(playgames_before_training):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m#games_mem += playgame()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mgames_mem\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mplaygames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmctss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_games\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_games\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimulations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msimulations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# Train the network with collected data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_288143/3366833925.py\u001b[0m in \u001b[0;36mplaygames\u001b[0;34m(mctss, num_games, simulations)\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0mactive_games\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# Mark game as finished\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mconcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThreadPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_games\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mmcts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_action_probs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmcts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msimulations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmctss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_threads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                 \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1117\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e8497c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UTTT(\n",
       "  (conv1): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.09, affine=True, track_running_stats=True)\n",
       "  (res2): ResidualBlock(\n",
       "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.09, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.09, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (res3): ResidualBlock(\n",
       "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.09, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.09, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (fc1): Linear(in_features=10368, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (pi): Linear(in_features=256, out_features=81, bias=True)\n",
       "  (v): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_model = UTTT()\n",
    "inference_model.load_state_dict(torch.load('temp.pth'))\n",
    "inference_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6ac56f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_move(state, model):\n",
    "    valid_actions = get_all_valid_actions(state)\n",
    "    ev,best_action = float('inf'),None\n",
    "    for action in valid_actions:\n",
    "        next_state=change_state(state,action)\n",
    "        _,v=model(state_to_tensor(next_state)) #this gives v from next player POV due to flip #v measures how good for the CURRENT PLAYER\n",
    "        if v<ev: ev,best_action = v,action\n",
    "    return best_action\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "88f55833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[9.4793e-06, 3.2631e-04, 3.0510e-05, 7.2048e-03, 5.4976e-05, 1.2403e-02,\n",
      "         6.2163e-05, 3.5673e-02, 6.2828e-02, 5.7124e-05, 3.9309e-06, 5.4976e-03,\n",
      "         1.7686e-04, 2.3642e-03, 6.4218e-03, 9.1988e-04, 6.8387e-06, 3.5382e-02,\n",
      "         3.2539e-05, 9.5501e-03, 3.5474e-05, 5.0363e-06, 1.6491e-03, 3.9291e-03,\n",
      "         5.5464e-04, 4.8744e-04, 3.0758e-02, 1.2322e-05, 2.8126e-04, 8.7949e-05,\n",
      "         7.6690e-05, 5.6819e-02, 1.8095e-04, 1.2417e-03, 2.1750e-02, 6.2042e-02,\n",
      "         4.2854e-03, 1.4375e-05, 2.0925e-05, 8.4585e-02, 5.8950e-02, 7.7374e-03,\n",
      "         1.6837e-03, 2.1506e-02, 1.0092e-04, 7.8711e-02, 3.1605e-04, 1.5606e-03,\n",
      "         5.4704e-02, 2.3885e-06, 4.3532e-04, 3.5001e-02, 1.0134e-04, 1.0264e-03,\n",
      "         2.7607e-05, 4.7374e-05, 1.3499e-02, 1.8256e-03, 2.3566e-02, 4.7220e-03,\n",
      "         1.7754e-03, 5.3280e-02, 1.4972e-04, 5.1974e-02, 8.0774e-04, 6.0268e-06,\n",
      "         1.5922e-02, 1.6171e-05, 1.7093e-03, 3.0057e-02, 7.0029e-04, 3.2271e-03,\n",
      "         2.3708e-04, 2.2771e-03, 1.4681e-02, 3.3146e-02, 5.4460e-05, 8.3950e-06,\n",
      "         3.7514e-03, 8.5712e-03, 2.4303e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.7447]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[5.4458e-06, 1.6274e-04, 1.2729e-05, 1.0878e-02, 4.0466e-05, 1.5436e-02,\n",
      "         5.3832e-05, 3.0768e-02, 7.8539e-02, 4.7396e-05, 2.2259e-06, 6.3851e-03,\n",
      "         7.8474e-05, 1.3996e-03, 8.1042e-03, 3.4950e-04, 4.0368e-06, 5.8049e-02,\n",
      "         1.5447e-05, 1.3423e-02, 1.9451e-05, 2.0912e-06, 1.2776e-03, 3.1997e-03,\n",
      "         4.5250e-04, 4.5841e-04, 2.9206e-02, 9.7645e-06, 1.7599e-04, 4.2997e-05,\n",
      "         3.9966e-05, 4.6993e-02, 1.0473e-04, 8.1318e-04, 2.0771e-02, 6.4138e-02,\n",
      "         5.2302e-03, 7.1691e-06, 8.3420e-06, 7.3763e-02, 6.7402e-02, 5.7201e-03,\n",
      "         8.8816e-04, 3.4793e-02, 8.9655e-05, 1.0612e-01, 2.5899e-04, 2.2793e-03,\n",
      "         3.4976e-02, 1.3503e-06, 2.7787e-04, 2.6080e-02, 7.2004e-05, 7.9258e-04,\n",
      "         2.3294e-05, 2.9627e-05, 1.2739e-02, 1.1181e-03, 2.5101e-02, 2.0104e-03,\n",
      "         1.9538e-03, 4.5359e-02, 6.3032e-05, 2.6641e-02, 8.7525e-04, 5.4115e-06,\n",
      "         1.0146e-02, 1.3425e-05, 1.3150e-03, 2.2181e-02, 3.9572e-04, 5.0250e-03,\n",
      "         1.4801e-04, 1.9104e-03, 1.7593e-02, 2.9716e-02, 3.0154e-05, 6.1804e-06,\n",
      "         3.4437e-03, 6.4581e-03, 3.5486e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9753]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[6.6744e-06, 1.0320e-04, 1.5386e-05, 4.6993e-03, 7.5829e-05, 1.2636e-02,\n",
      "         1.0633e-04, 2.0291e-02, 1.1029e-01, 2.2005e-05, 3.9356e-06, 5.4363e-03,\n",
      "         1.5324e-04, 4.0415e-03, 7.8303e-03, 6.4924e-04, 5.4117e-06, 4.2693e-02,\n",
      "         1.7198e-05, 2.1335e-02, 2.2156e-05, 1.8585e-06, 1.2473e-03, 5.0102e-03,\n",
      "         5.4689e-04, 4.7959e-04, 2.1717e-02, 1.7184e-05, 1.4375e-04, 5.7392e-05,\n",
      "         3.2872e-05, 3.3270e-02, 1.1702e-04, 1.5973e-03, 1.7828e-02, 3.3719e-02,\n",
      "         4.6334e-03, 4.6977e-06, 1.7915e-05, 1.1151e-01, 5.1509e-02, 5.5787e-03,\n",
      "         1.2313e-03, 2.8015e-02, 1.6485e-04, 1.0966e-01, 1.9854e-04, 1.8102e-03,\n",
      "         3.4579e-02, 2.1062e-06, 1.0832e-03, 3.5971e-02, 6.9914e-05, 9.1273e-04,\n",
      "         9.6548e-06, 3.6527e-05, 1.1575e-02, 9.2005e-04, 1.9955e-02, 4.8239e-03,\n",
      "         2.6168e-03, 4.2410e-02, 1.4735e-04, 6.3631e-02, 1.0409e-03, 8.1190e-06,\n",
      "         1.9657e-02, 1.0493e-05, 2.2637e-03, 2.2767e-02, 2.9751e-04, 5.3385e-03,\n",
      "         1.1141e-04, 1.9294e-03, 1.7927e-02, 2.5238e-02, 6.5508e-05, 6.7456e-06,\n",
      "         2.9016e-03, 8.7337e-03, 1.2409e-02]], grad_fn=<SoftmaxBackward0>), tensor([[0.9548]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[5.8513e-07, 4.6161e-05, 2.0596e-06, 9.2042e-03, 6.3564e-06, 9.5671e-03,\n",
      "         9.2967e-06, 3.0384e-02, 8.0825e-02, 1.0238e-05, 2.0139e-07, 4.2176e-03,\n",
      "         1.6326e-05, 5.1197e-04, 4.9421e-03, 1.2229e-04, 4.0621e-07, 5.5658e-02,\n",
      "         2.0648e-06, 8.3699e-03, 3.5090e-06, 2.5176e-07, 5.5547e-04, 1.7283e-03,\n",
      "         1.6497e-04, 1.6230e-04, 2.7869e-02, 1.3297e-06, 5.0897e-05, 9.3364e-06,\n",
      "         7.9924e-06, 5.4035e-02, 2.4040e-05, 2.6981e-04, 1.8084e-02, 7.6279e-02,\n",
      "         3.2345e-03, 1.0289e-06, 1.2096e-06, 8.5847e-02, 7.2247e-02, 3.1204e-03,\n",
      "         3.6126e-04, 3.0158e-02, 2.2578e-05, 1.3472e-01, 8.0276e-05, 9.5522e-04,\n",
      "         3.2381e-02, 1.1751e-07, 8.1996e-05, 2.5318e-02, 1.7337e-05, 3.0080e-04,\n",
      "         4.0354e-06, 5.6343e-06, 1.0529e-02, 4.7273e-04, 2.3005e-02, 9.5727e-04,\n",
      "         8.0165e-04, 5.7340e-02, 1.5867e-05, 2.0914e-02, 2.9221e-04, 5.3138e-07,\n",
      "         7.5224e-03, 2.0366e-06, 5.5691e-04, 1.7001e-02, 1.2577e-04, 2.3991e-03,\n",
      "         4.1580e-05, 9.5176e-04, 1.2763e-02, 3.0273e-02, 4.9808e-06, 6.6484e-07,\n",
      "         1.6716e-03, 3.6343e-03, 3.6723e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9922]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[2.5420e-06, 5.3309e-05, 6.5414e-06, 3.6113e-03, 4.3702e-05, 1.1684e-02,\n",
      "         5.1451e-05, 1.6094e-02, 1.2306e-01, 8.8928e-06, 1.5423e-06, 4.5706e-03,\n",
      "         8.6883e-05, 3.3611e-03, 6.0834e-03, 3.9023e-04, 2.1750e-06, 4.2557e-02,\n",
      "         7.1837e-06, 2.0027e-02, 9.0998e-06, 6.4213e-07, 9.2040e-04, 4.3223e-03,\n",
      "         3.4598e-04, 3.0505e-04, 1.8453e-02, 6.5879e-06, 8.7941e-05, 2.5673e-05,\n",
      "         1.6547e-05, 3.3996e-02, 5.9279e-05, 1.0683e-03, 1.5942e-02, 2.8543e-02,\n",
      "         3.4259e-03, 1.6860e-06, 7.7310e-06, 1.4412e-01, 5.2221e-02, 5.0301e-03,\n",
      "         9.3309e-04, 2.7468e-02, 9.1234e-05, 1.0790e-01, 1.1178e-04, 1.3141e-03,\n",
      "         3.1218e-02, 7.1688e-07, 6.8887e-04, 3.6802e-02, 3.3118e-05, 5.6971e-04,\n",
      "         3.9814e-06, 1.8434e-05, 9.8552e-03, 5.5614e-04, 1.6426e-02, 3.7773e-03,\n",
      "         1.9568e-03, 3.9492e-02, 7.1156e-05, 6.8824e-02, 7.3508e-04, 3.4611e-06,\n",
      "         1.8539e-02, 3.6654e-06, 1.8146e-03, 2.3919e-02, 1.7583e-04, 4.0460e-03,\n",
      "         5.5152e-05, 1.3026e-03, 1.6695e-02, 2.5116e-02, 3.4894e-05, 3.0398e-06,\n",
      "         2.0606e-03, 6.5875e-03, 1.0180e-02]], grad_fn=<SoftmaxBackward0>), tensor([[0.9781]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[1.8773e-07, 2.4915e-05, 7.5614e-07, 6.8450e-03, 2.7450e-06, 8.1734e-03,\n",
      "         3.7418e-06, 3.1594e-02, 9.2313e-02, 4.4195e-06, 5.5801e-08, 2.9478e-03,\n",
      "         7.2088e-06, 3.3943e-04, 3.8728e-03, 6.4176e-05, 1.2795e-07, 5.2571e-02,\n",
      "         8.0987e-07, 6.9042e-03, 1.3659e-06, 7.3190e-08, 3.7753e-04, 1.2044e-03,\n",
      "         9.9008e-05, 8.4085e-05, 2.5930e-02, 4.3240e-07, 2.6330e-05, 4.4877e-06,\n",
      "         3.4175e-06, 5.1038e-02, 1.1077e-05, 1.6599e-04, 1.6730e-02, 8.2471e-02,\n",
      "         2.5939e-03, 3.4190e-07, 4.1737e-07, 9.4978e-02, 8.1714e-02, 2.4592e-03,\n",
      "         2.2182e-04, 2.7717e-02, 1.0201e-05, 1.3761e-01, 3.8926e-05, 6.1360e-04,\n",
      "         3.0382e-02, 3.3203e-08, 4.4958e-05, 2.1654e-02, 8.0482e-06, 1.8969e-04,\n",
      "         1.5348e-06, 2.4052e-06, 9.4499e-03, 3.2127e-04, 1.9085e-02, 6.9445e-04,\n",
      "         5.8229e-04, 5.8713e-02, 7.8901e-06, 2.1284e-02, 1.7760e-04, 1.6797e-07,\n",
      "         6.8278e-03, 6.8713e-07, 3.5526e-04, 1.6093e-02, 7.8541e-05, 1.6618e-03,\n",
      "         1.9508e-05, 6.9073e-04, 1.0312e-02, 3.0727e-02, 1.9692e-06, 2.1905e-07,\n",
      "         1.2395e-03, 3.1402e-03, 3.4476e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9958]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[1.1666e-06, 3.6563e-05, 4.1443e-06, 3.3343e-03, 2.6910e-05, 9.5380e-03,\n",
      "         2.8755e-05, 1.7137e-02, 1.2848e-01, 5.6973e-06, 6.7826e-07, 4.2295e-03,\n",
      "         5.0180e-05, 2.5180e-03, 4.8210e-03, 2.9596e-04, 1.0871e-06, 4.0489e-02,\n",
      "         3.8767e-06, 1.7157e-02, 4.9905e-06, 3.4652e-07, 7.3343e-04, 3.3959e-03,\n",
      "         2.6983e-04, 2.2371e-04, 1.9076e-02, 3.7413e-06, 5.4938e-05, 1.6141e-05,\n",
      "         1.0474e-05, 3.3538e-02, 3.6521e-05, 8.1541e-04, 1.5413e-02, 3.0108e-02,\n",
      "         2.8824e-03, 7.8660e-07, 4.3055e-06, 1.5356e-01, 5.4003e-02, 4.9107e-03,\n",
      "         6.8716e-04, 2.6655e-02, 6.5191e-05, 1.1407e-01, 7.1036e-05, 8.9187e-04,\n",
      "         3.2333e-02, 3.2992e-07, 4.9279e-04, 3.4847e-02, 1.9918e-05, 3.8492e-04,\n",
      "         2.0609e-06, 1.0932e-05, 8.6974e-03, 4.0060e-04, 1.5396e-02, 3.1208e-03,\n",
      "         1.3949e-03, 3.8344e-02, 4.2341e-05, 7.1089e-02, 5.1927e-04, 1.8407e-06,\n",
      "         1.6654e-02, 1.8865e-06, 1.3933e-03, 2.3273e-02, 1.2699e-04, 3.4054e-03,\n",
      "         3.6785e-05, 1.0714e-03, 1.5939e-02, 2.5105e-02, 1.9291e-05, 1.3833e-06,\n",
      "         1.5930e-03, 5.9929e-03, 8.6340e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9832]], grad_fn=<TanhBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[1.3705e-07, 2.2298e-05, 5.9701e-07, 6.6502e-03, 2.2418e-06, 7.2853e-03,\n",
      "         2.8680e-06, 3.1006e-02, 9.3215e-02, 3.5768e-06, 4.0729e-08, 2.7073e-03,\n",
      "         5.9405e-06, 2.9994e-04, 3.5471e-03, 5.6607e-05, 9.4456e-08, 5.2030e-02,\n",
      "         6.1024e-07, 6.2822e-03, 1.0846e-06, 5.6613e-08, 3.3132e-04, 1.1459e-03,\n",
      "         8.3484e-05, 7.3528e-05, 2.7069e-02, 3.1828e-07, 2.1982e-05, 3.8426e-06,\n",
      "         2.6368e-06, 5.0909e-02, 9.2492e-06, 1.4531e-04, 1.6383e-02, 8.5444e-02,\n",
      "         2.4794e-03, 2.5898e-07, 3.2783e-07, 9.7356e-02, 8.3853e-02, 2.3615e-03,\n",
      "         2.1213e-04, 2.7746e-02, 8.5661e-06, 1.3462e-01, 3.5564e-05, 5.3804e-04,\n",
      "         3.0421e-02, 2.3058e-08, 3.6016e-05, 2.3047e-02, 6.1839e-06, 1.6647e-04,\n",
      "         1.2552e-06, 1.9623e-06, 9.0346e-03, 2.7838e-04, 1.8606e-02, 6.4127e-04,\n",
      "         4.8978e-04, 5.8440e-02, 6.4809e-06, 2.1101e-02, 1.5566e-04, 1.2385e-07,\n",
      "         6.6289e-03, 5.1969e-07, 3.1415e-04, 1.5309e-02, 6.6922e-05, 1.4611e-03,\n",
      "         1.6837e-05, 6.2330e-04, 9.7100e-03, 3.0875e-02, 1.5887e-06, 1.5892e-07,\n",
      "         1.1526e-03, 2.9003e-03, 3.4555e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9963]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[6.0337e-07, 1.8148e-05, 1.5389e-06, 2.0892e-03, 1.5115e-05, 6.4915e-03,\n",
      "         1.5489e-05, 1.2797e-02, 1.5192e-01, 2.6419e-06, 3.3113e-07, 3.7602e-03,\n",
      "         3.8343e-05, 2.1158e-03, 3.7093e-03, 1.8800e-04, 4.4655e-07, 3.5374e-02,\n",
      "         1.7128e-06, 1.5609e-02, 2.6160e-06, 9.6866e-08, 4.2129e-04, 2.8873e-03,\n",
      "         1.6422e-04, 1.2994e-04, 1.5763e-02, 1.7033e-06, 2.7878e-05, 8.1363e-06,\n",
      "         4.2883e-06, 2.7421e-02, 2.0153e-05, 5.9290e-04, 1.1405e-02, 2.1583e-02,\n",
      "         1.6805e-03, 2.8996e-07, 1.9388e-06, 2.0343e-01, 3.9568e-02, 4.4356e-03,\n",
      "         4.8280e-04, 2.3903e-02, 3.5555e-05, 1.2645e-01, 4.5131e-05, 6.5625e-04,\n",
      "         2.8011e-02, 1.2544e-07, 4.3702e-04, 3.1160e-02, 1.1071e-05, 2.5299e-04,\n",
      "         8.8148e-07, 5.5492e-06, 6.8193e-03, 2.5996e-04, 1.2248e-02, 2.3940e-03,\n",
      "         1.0348e-03, 3.4749e-02, 2.4717e-05, 7.7176e-02, 3.6005e-04, 7.6846e-07,\n",
      "         1.6368e-02, 8.9950e-07, 1.0632e-03, 2.3273e-02, 7.2714e-05, 2.5604e-03,\n",
      "         1.9421e-05, 7.8463e-04, 1.2044e-02, 2.1869e-02, 1.0902e-05, 7.0164e-07,\n",
      "         9.1158e-04, 5.1062e-03, 5.7046e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9962]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[4.4476e-08, 1.1641e-05, 2.4364e-07, 5.7153e-03, 8.7746e-07, 6.2495e-03,\n",
      "         1.0945e-06, 3.1106e-02, 8.8612e-02, 1.6186e-06, 1.2536e-08, 2.2288e-03,\n",
      "         2.6480e-06, 1.9036e-04, 2.4767e-03, 2.8335e-05, 3.1224e-08, 5.1477e-02,\n",
      "         2.4068e-07, 5.3683e-03, 3.7165e-07, 1.8079e-08, 2.1798e-04, 9.2679e-04,\n",
      "         4.5330e-05, 4.2523e-05, 2.6171e-02, 1.1294e-07, 1.1571e-05, 1.6572e-06,\n",
      "         1.1013e-06, 4.8404e-02, 4.8122e-06, 9.3239e-05, 1.5602e-02, 8.7063e-02,\n",
      "         2.0062e-03, 9.5449e-08, 1.0418e-07, 9.8833e-02, 8.9866e-02, 1.9103e-03,\n",
      "         1.3863e-04, 2.9970e-02, 3.8898e-06, 1.5477e-01, 2.0437e-05, 3.6131e-04,\n",
      "         2.6826e-02, 6.9186e-09, 1.7844e-05, 1.8167e-02, 2.6012e-06, 9.4668e-05,\n",
      "         4.8919e-07, 7.6198e-07, 7.2950e-03, 1.5876e-04, 1.8024e-02, 3.8113e-04,\n",
      "         3.5839e-04, 5.9818e-02, 2.6161e-06, 1.9645e-02, 1.0156e-04, 3.7893e-08,\n",
      "         5.3516e-03, 2.0336e-07, 2.0612e-04, 1.4016e-02, 4.0283e-05, 1.2182e-03,\n",
      "         8.3472e-06, 4.0978e-04, 9.1174e-03, 3.1132e-02, 6.3390e-07, 6.2608e-08,\n",
      "         7.9815e-04, 2.3517e-03, 3.4517e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9989]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[5.5730e-07, 1.5329e-05, 1.2611e-06, 1.8013e-03, 1.4079e-05, 6.1585e-03,\n",
      "         1.3948e-05, 1.1349e-02, 1.6297e-01, 2.3549e-06, 2.7977e-07, 3.4569e-03,\n",
      "         3.4717e-05, 2.0473e-03, 3.4302e-03, 1.6464e-04, 3.9645e-07, 3.2845e-02,\n",
      "         1.5552e-06, 1.6241e-02, 2.1330e-06, 7.8957e-08, 3.7724e-04, 2.7208e-03,\n",
      "         1.5180e-04, 1.1784e-04, 1.5951e-02, 1.4117e-06, 2.3329e-05, 7.1819e-06,\n",
      "         3.4766e-06, 2.5311e-02, 1.7774e-05, 5.5324e-04, 1.0821e-02, 2.0677e-02,\n",
      "         1.6005e-03, 2.2260e-07, 1.6621e-06, 2.0716e-01, 3.7778e-02, 4.0858e-03,\n",
      "         4.5202e-04, 2.2630e-02, 3.3101e-05, 1.2892e-01, 4.4152e-05, 6.1532e-04,\n",
      "         2.7323e-02, 1.0484e-07, 4.0952e-04, 2.9138e-02, 8.7501e-06, 2.0582e-04,\n",
      "         7.3466e-07, 5.2255e-06, 6.3213e-03, 2.2407e-04, 1.2241e-02, 2.1720e-03,\n",
      "         9.5915e-04, 3.2099e-02, 2.1548e-05, 8.2395e-02, 3.4158e-04, 6.5152e-07,\n",
      "         1.6122e-02, 7.6263e-07, 1.0121e-03, 2.2150e-02, 6.1464e-05, 2.4661e-03,\n",
      "         1.6804e-05, 7.3395e-04, 1.1432e-02, 2.0587e-02, 1.0065e-05, 5.8963e-07,\n",
      "         8.0203e-04, 4.9656e-03, 5.1748e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9975]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[4.4323e-08, 1.1325e-05, 2.4234e-07, 5.6199e-03, 8.3059e-07, 6.1598e-03,\n",
      "         1.0971e-06, 3.0739e-02, 8.0835e-02, 1.5562e-06, 1.3131e-08, 2.2920e-03,\n",
      "         2.8627e-06, 1.8765e-04, 2.4799e-03, 2.9816e-05, 3.1231e-08, 5.2494e-02,\n",
      "         2.3778e-07, 5.3857e-03, 3.8645e-07, 1.7340e-08, 2.1154e-04, 9.3501e-04,\n",
      "         4.6515e-05, 4.4310e-05, 2.6597e-02, 1.1604e-07, 1.2144e-05, 1.7561e-06,\n",
      "         1.1476e-06, 5.0570e-02, 4.9838e-06, 9.5097e-05, 1.5747e-02, 8.7113e-02,\n",
      "         2.0502e-03, 9.9431e-08, 1.0707e-07, 1.0232e-01, 8.9120e-02, 2.0318e-03,\n",
      "         1.4806e-04, 3.0830e-02, 3.9029e-06, 1.5058e-01, 2.0932e-05, 3.3968e-04,\n",
      "         2.7074e-02, 6.5218e-09, 1.8090e-05, 1.8908e-02, 2.6381e-06, 1.0458e-04,\n",
      "         4.8730e-07, 7.7650e-07, 7.7177e-03, 1.6740e-04, 1.7706e-02, 3.9232e-04,\n",
      "         3.6784e-04, 6.2162e-02, 2.8194e-06, 1.9575e-02, 1.0513e-04, 3.9840e-08,\n",
      "         5.2770e-03, 1.9750e-07, 2.1292e-04, 1.4567e-02, 4.2183e-05, 1.1933e-03,\n",
      "         8.6280e-06, 3.7842e-04, 9.2245e-03, 3.1686e-02, 6.2587e-07, 6.3222e-08,\n",
      "         7.7274e-04, 2.2633e-03, 3.5003e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9989]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[5.3273e-07, 1.3919e-05, 1.1003e-06, 1.5676e-03, 1.3235e-05, 6.8684e-03,\n",
      "         1.2431e-05, 9.5832e-03, 1.8354e-01, 1.9556e-06, 2.1913e-07, 3.0720e-03,\n",
      "         2.7553e-05, 2.0866e-03, 3.2501e-03, 1.3725e-04, 3.4525e-07, 3.2085e-02,\n",
      "         1.4254e-06, 1.6578e-02, 1.5520e-06, 6.5186e-08, 3.7682e-04, 2.5703e-03,\n",
      "         1.4506e-04, 1.1422e-04, 1.5412e-02, 1.1167e-06, 2.1449e-05, 6.1459e-06,\n",
      "         2.9583e-06, 2.6551e-02, 1.5356e-05, 5.1160e-04, 1.0457e-02, 1.9239e-02,\n",
      "         1.5523e-03, 1.7993e-07, 1.3588e-06, 1.9444e-01, 3.9941e-02, 3.3828e-03,\n",
      "         4.2047e-04, 2.2959e-02, 3.1718e-05, 1.2209e-01, 4.0003e-05, 6.6289e-04,\n",
      "         2.5181e-02, 8.9287e-08, 3.6083e-04, 2.9053e-02, 7.4513e-06, 1.7206e-04,\n",
      "         6.0719e-07, 4.6654e-06, 5.8659e-03, 1.8806e-04, 1.1546e-02, 2.0614e-03,\n",
      "         9.1549e-04, 2.6715e-02, 1.8087e-05, 9.5741e-02, 3.2143e-04, 5.7358e-07,\n",
      "         1.5742e-02, 6.0140e-07, 1.0117e-03, 2.1699e-02, 5.2743e-05, 2.4110e-03,\n",
      "         1.3569e-05, 6.5655e-04, 1.1728e-02, 1.8536e-02, 9.6039e-06, 4.8771e-07,\n",
      "         7.5776e-04, 4.4760e-03, 4.9603e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9981]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[4.1654e-08, 1.1637e-05, 2.4003e-07, 5.7837e-03, 8.0862e-07, 6.1225e-03,\n",
      "         1.0895e-06, 3.2148e-02, 7.6882e-02, 1.4894e-06, 1.2427e-08, 2.1926e-03,\n",
      "         2.7338e-06, 1.8671e-04, 2.5631e-03, 3.1610e-05, 3.0802e-08, 5.2286e-02,\n",
      "         2.3751e-07, 5.3543e-03, 4.0087e-07, 1.8269e-08, 2.0354e-04, 9.3687e-04,\n",
      "         4.6202e-05, 4.6071e-05, 2.8180e-02, 1.2075e-07, 1.1880e-05, 1.8475e-06,\n",
      "         1.1104e-06, 4.9183e-02, 4.9528e-06, 9.4096e-05, 1.5856e-02, 9.0365e-02,\n",
      "         2.0663e-03, 1.0041e-07, 1.1286e-07, 1.0023e-01, 8.9546e-02, 1.9977e-03,\n",
      "         1.5251e-04, 3.0290e-02, 3.6964e-06, 1.5101e-01, 2.0030e-05, 3.2539e-04,\n",
      "         2.7632e-02, 6.3347e-09, 1.7614e-05, 2.0235e-02, 2.6883e-06, 1.0011e-04,\n",
      "         5.0641e-07, 7.8618e-07, 7.6238e-03, 1.6989e-04, 1.7775e-02, 4.0768e-04,\n",
      "         3.4752e-04, 6.3203e-02, 2.6865e-06, 1.8757e-02, 9.9225e-05, 3.7759e-08,\n",
      "         5.3364e-03, 1.9622e-07, 2.0481e-04, 1.3497e-02, 4.0486e-05, 1.2263e-03,\n",
      "         8.2744e-06, 3.8106e-04, 9.3213e-03, 3.1413e-02, 6.2751e-07, 5.9412e-08,\n",
      "         7.6906e-04, 2.1712e-03, 3.5107e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9990]], grad_fn=<TanhBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[5.4943e-07, 1.4166e-05, 1.1206e-06, 1.5631e-03, 1.2977e-05, 6.4233e-03,\n",
      "         1.2474e-05, 9.5695e-03, 1.8055e-01, 2.1042e-06, 2.3686e-07, 3.2661e-03,\n",
      "         3.0154e-05, 1.9625e-03, 3.2956e-03, 1.3939e-04, 3.5477e-07, 3.2080e-02,\n",
      "         1.4461e-06, 1.6143e-02, 1.6182e-06, 6.7382e-08, 3.7785e-04, 2.6791e-03,\n",
      "         1.4945e-04, 1.1786e-04, 1.5263e-02, 1.2254e-06, 2.2752e-05, 6.3550e-06,\n",
      "         2.9669e-06, 2.6657e-02, 1.6393e-05, 5.2627e-04, 1.0050e-02, 1.9268e-02,\n",
      "         1.4795e-03, 1.8093e-07, 1.3842e-06, 1.9663e-01, 3.7487e-02, 3.4976e-03,\n",
      "         4.2445e-04, 2.2297e-02, 3.3875e-05, 1.2792e-01, 4.2079e-05, 6.1559e-04,\n",
      "         2.4862e-02, 9.0260e-08, 3.8493e-04, 2.8675e-02, 7.6108e-06, 1.7594e-04,\n",
      "         6.2905e-07, 4.7474e-06, 5.8980e-03, 1.8998e-04, 1.1845e-02, 2.1314e-03,\n",
      "         9.2285e-04, 2.7705e-02, 1.9664e-05, 9.3245e-02, 3.3245e-04, 6.0005e-07,\n",
      "         1.5557e-02, 6.3960e-07, 1.0639e-03, 2.3089e-02, 5.3937e-05, 2.3465e-03,\n",
      "         1.4607e-05, 6.7315e-04, 1.1648e-02, 1.8201e-02, 9.9412e-06, 5.0413e-07,\n",
      "         7.3700e-04, 4.7796e-03, 4.7865e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9982]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[3.3099e-08, 9.7953e-06, 2.0103e-07, 5.5708e-03, 6.8989e-07, 5.9254e-03,\n",
      "         9.1517e-07, 3.2342e-02, 7.7374e-02, 1.2583e-06, 1.0029e-08, 2.1815e-03,\n",
      "         2.4295e-06, 1.6792e-04, 2.4736e-03, 2.8778e-05, 2.4690e-08, 5.2331e-02,\n",
      "         2.0561e-07, 5.4488e-03, 3.1391e-07, 1.3903e-08, 1.8430e-04, 9.2648e-04,\n",
      "         4.0284e-05, 4.1125e-05, 2.7755e-02, 9.5654e-08, 1.0260e-05, 1.5524e-06,\n",
      "         9.4032e-07, 4.6289e-02, 4.3258e-06, 9.1744e-05, 1.5695e-02, 9.0813e-02,\n",
      "         2.0268e-03, 8.7974e-08, 8.8744e-08, 9.7709e-02, 9.1092e-02, 1.9365e-03,\n",
      "         1.4211e-04, 3.2456e-02, 2.9503e-06, 1.5586e-01, 1.6687e-05, 3.0166e-04,\n",
      "         2.5525e-02, 5.2490e-09, 1.6556e-05, 1.8766e-02, 2.3217e-06, 9.5217e-05,\n",
      "         4.2729e-07, 6.5303e-07, 7.3904e-03, 1.5723e-04, 1.7118e-02, 3.4751e-04,\n",
      "         3.4377e-04, 6.5320e-02, 2.0776e-06, 1.8126e-02, 9.7007e-05, 3.0812e-08,\n",
      "         5.3268e-03, 1.7015e-07, 1.8060e-04, 1.3650e-02, 3.6334e-05, 1.2606e-03,\n",
      "         7.0713e-06, 3.4450e-04, 9.1911e-03, 3.1784e-02, 5.1070e-07, 5.1957e-08,\n",
      "         7.1488e-04, 2.1200e-03, 3.4818e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9993]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[5.7329e-07, 1.5069e-05, 1.1667e-06, 1.5863e-03, 1.3732e-05, 6.8276e-03,\n",
      "         1.3276e-05, 9.3396e-03, 1.8375e-01, 2.1511e-06, 2.4997e-07, 3.1943e-03,\n",
      "         3.0545e-05, 2.0715e-03, 3.2638e-03, 1.4013e-04, 3.6825e-07, 3.3185e-02,\n",
      "         1.5062e-06, 1.5822e-02, 1.6789e-06, 7.1651e-08, 3.9299e-04, 2.7295e-03,\n",
      "         1.5728e-04, 1.2644e-04, 1.5363e-02, 1.2708e-06, 2.4260e-05, 6.4024e-06,\n",
      "         3.0182e-06, 2.7074e-02, 1.7071e-05, 5.4877e-04, 1.0459e-02, 1.9091e-02,\n",
      "         1.5375e-03, 1.9246e-07, 1.4341e-06, 1.9038e-01, 3.8264e-02, 3.3814e-03,\n",
      "         4.2185e-04, 2.3212e-02, 3.5652e-05, 1.2635e-01, 4.3955e-05, 6.4242e-04,\n",
      "         2.4136e-02, 9.6800e-08, 3.8480e-04, 2.9059e-02, 7.7691e-06, 1.7756e-04,\n",
      "         6.8568e-07, 4.8785e-06, 6.0971e-03, 1.8869e-04, 1.2154e-02, 2.1926e-03,\n",
      "         9.4655e-04, 2.5090e-02, 1.9488e-05, 9.6610e-02, 3.3389e-04, 6.6562e-07,\n",
      "         1.5702e-02, 6.8014e-07, 1.1116e-03, 2.3307e-02, 5.3181e-05, 2.4036e-03,\n",
      "         1.4727e-05, 6.8296e-04, 1.1586e-02, 1.7700e-02, 1.0935e-05, 5.4195e-07,\n",
      "         7.7281e-04, 4.6555e-03, 5.0734e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9981]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[3.0860e-08, 9.4501e-06, 1.8587e-07, 5.6410e-03, 6.7021e-07, 5.9909e-03,\n",
      "         8.7097e-07, 3.2030e-02, 8.0642e-02, 1.1942e-06, 9.2872e-09, 2.0843e-03,\n",
      "         2.2540e-06, 1.6548e-04, 2.4239e-03, 2.6996e-05, 2.3152e-08, 5.1653e-02,\n",
      "         1.9299e-07, 5.4933e-03, 2.9689e-07, 1.2897e-08, 1.8056e-04, 9.1513e-04,\n",
      "         3.9042e-05, 3.9162e-05, 2.7098e-02, 8.7428e-08, 9.6749e-06, 1.4503e-06,\n",
      "         8.7412e-07, 4.4173e-02, 4.0214e-06, 8.7218e-05, 1.5266e-02, 9.0083e-02,\n",
      "         1.9965e-03, 8.1023e-08, 8.0518e-08, 1.0084e-01, 8.8512e-02, 1.8914e-03,\n",
      "         1.3743e-04, 3.2699e-02, 2.7734e-06, 1.5729e-01, 1.5846e-05, 3.0151e-04,\n",
      "         2.5540e-02, 4.8801e-09, 1.6260e-05, 1.8358e-02, 2.1688e-06, 9.0234e-05,\n",
      "         4.0554e-07, 6.1906e-07, 7.3709e-03, 1.4962e-04, 1.7257e-02, 3.3176e-04,\n",
      "         3.3636e-04, 6.5089e-02, 1.9397e-06, 1.8138e-02, 9.3577e-05, 2.7183e-08,\n",
      "         5.2344e-03, 1.6273e-07, 1.7301e-04, 1.3287e-02, 3.4498e-05, 1.2141e-03,\n",
      "         6.7688e-06, 3.4136e-04, 9.1735e-03, 3.2456e-02, 4.8586e-07, 4.8555e-08,\n",
      "         6.9921e-04, 2.0996e-03, 3.4750e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9994]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[4.1743e-07, 1.1963e-05, 8.6115e-07, 1.4234e-03, 1.0777e-05, 6.0064e-03,\n",
      "         1.0491e-05, 8.7147e-03, 1.7951e-01, 1.6438e-06, 1.8468e-07, 3.0744e-03,\n",
      "         2.6505e-05, 1.9300e-03, 3.1139e-03, 1.2483e-04, 2.7347e-07, 3.3495e-02,\n",
      "         1.1075e-06, 1.5521e-02, 1.2840e-06, 4.9446e-08, 3.4861e-04, 2.5463e-03,\n",
      "         1.3296e-04, 1.0574e-04, 1.4419e-02, 1.0269e-06, 1.9561e-05, 4.9813e-06,\n",
      "         2.2951e-06, 2.6721e-02, 1.3974e-05, 4.8342e-04, 9.5242e-03, 1.8572e-02,\n",
      "         1.3807e-03, 1.3480e-07, 1.0816e-06, 2.0024e-01, 3.7106e-02, 3.2622e-03,\n",
      "         3.9814e-04, 2.1700e-02, 2.9217e-05, 1.3313e-01, 3.7285e-05, 5.6642e-04,\n",
      "         2.5540e-02, 6.5225e-08, 3.5643e-04, 2.9257e-02, 5.8147e-06, 1.5587e-04,\n",
      "         5.3039e-07, 3.8387e-06, 5.7318e-03, 1.5836e-04, 1.1732e-02, 2.0440e-03,\n",
      "         8.2517e-04, 2.6259e-02, 1.6738e-05, 9.5194e-02, 2.8740e-04, 4.9049e-07,\n",
      "         1.5740e-02, 5.1761e-07, 1.0447e-03, 2.1784e-02, 4.4628e-05, 2.1734e-03,\n",
      "         1.2284e-05, 6.2065e-04, 1.0793e-02, 1.6499e-02, 8.6653e-06, 3.9138e-07,\n",
      "         6.3647e-04, 4.4596e-03, 4.8888e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9986]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[2.2112e-08, 7.7988e-06, 1.3698e-07, 5.4985e-03, 5.0833e-07, 5.6851e-03,\n",
      "         6.6328e-07, 3.2341e-02, 8.2118e-02, 9.3898e-07, 6.2381e-09, 1.9441e-03,\n",
      "         1.7444e-06, 1.4150e-04, 2.2199e-03, 2.2396e-05, 1.5918e-08, 5.1387e-02,\n",
      "         1.4325e-07, 5.2398e-03, 2.2135e-07, 9.0168e-09, 1.5760e-04, 8.0915e-04,\n",
      "         3.2700e-05, 3.2796e-05, 2.6188e-02, 6.3741e-08, 7.8139e-06, 1.1115e-06,\n",
      "         6.5960e-07, 4.3214e-02, 3.1641e-06, 7.2058e-05, 1.4708e-02, 8.9749e-02,\n",
      "         1.8515e-03, 5.9932e-08, 5.7174e-08, 1.0166e-01, 8.6922e-02, 1.7492e-03,\n",
      "         1.1865e-04, 3.1422e-02, 2.1425e-06, 1.6588e-01, 1.2829e-05, 2.7285e-04,\n",
      "         2.4738e-02, 3.3874e-09, 1.3325e-05, 1.8031e-02, 1.7216e-06, 7.7281e-05,\n",
      "         3.0789e-07, 4.7797e-07, 7.0010e-03, 1.3260e-04, 1.7572e-02, 2.8426e-04,\n",
      "         2.8376e-04, 6.5349e-02, 1.4640e-06, 1.7598e-02, 8.0133e-05, 1.8616e-08,\n",
      "         4.9109e-03, 1.2654e-07, 1.5278e-04, 1.2919e-02, 2.8163e-05, 1.1177e-03,\n",
      "         5.3761e-06, 3.0376e-04, 8.9709e-03, 3.1573e-02, 3.7815e-07, 3.4675e-08,\n",
      "         6.3086e-04, 1.9756e-03, 3.4768e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9995]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[3.8505e-07, 1.1618e-05, 8.1357e-07, 1.3681e-03, 1.0192e-05, 6.0292e-03,\n",
      "         1.0308e-05, 8.4019e-03, 1.8024e-01, 1.5157e-06, 1.7380e-07, 3.0494e-03,\n",
      "         2.5501e-05, 1.8762e-03, 2.9865e-03, 1.2408e-04, 2.6095e-07, 3.4351e-02,\n",
      "         1.0461e-06, 1.5882e-02, 1.1988e-06, 4.3529e-08, 3.4770e-04, 2.4268e-03,\n",
      "         1.2956e-04, 1.0759e-04, 1.4276e-02, 9.5310e-07, 1.8804e-05, 4.5990e-06,\n",
      "         2.1852e-06, 2.8004e-02, 1.3583e-05, 4.7219e-04, 9.3546e-03, 1.8478e-02,\n",
      "         1.3701e-03, 1.2574e-07, 1.0264e-06, 1.9708e-01, 3.7664e-02, 3.1773e-03,\n",
      "         4.0302e-04, 2.1481e-02, 2.8727e-05, 1.3026e-01, 3.6001e-05, 5.7745e-04,\n",
      "         2.6231e-02, 5.9666e-08, 3.4908e-04, 2.8778e-02, 5.5603e-06, 1.4913e-04,\n",
      "         4.8782e-07, 3.6131e-06, 5.7569e-03, 1.5555e-04, 1.1815e-02, 2.0011e-03,\n",
      "         8.0518e-04, 2.6005e-02, 1.5549e-05, 9.8917e-02, 2.8577e-04, 4.6368e-07,\n",
      "         1.6309e-02, 4.8885e-07, 1.0497e-03, 2.1546e-02, 4.2463e-05, 2.1430e-03,\n",
      "         1.1807e-05, 5.7646e-04, 1.0734e-02, 1.6321e-02, 8.1865e-06, 3.6769e-07,\n",
      "         6.2195e-04, 4.3687e-03, 4.9028e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9987]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[2.0845e-08, 7.7035e-06, 1.3250e-07, 5.1914e-03, 4.7530e-07, 5.4070e-03,\n",
      "         6.3533e-07, 3.3267e-02, 8.2420e-02, 9.1173e-07, 5.7402e-09, 1.8720e-03,\n",
      "         1.6890e-06, 1.3455e-04, 2.1606e-03, 2.1974e-05, 1.3574e-08, 4.9401e-02,\n",
      "         1.3452e-07, 4.9902e-03, 2.1078e-07, 8.6805e-09, 1.4763e-04, 7.9146e-04,\n",
      "         3.0362e-05, 2.9805e-05, 2.6255e-02, 5.9782e-08, 7.3033e-06, 1.0454e-06,\n",
      "         6.4061e-07, 4.2211e-02, 3.0243e-06, 6.7697e-05, 1.4687e-02, 9.2449e-02,\n",
      "         1.7951e-03, 5.7731e-08, 5.6653e-08, 1.0435e-01, 8.7229e-02, 1.7040e-03,\n",
      "         1.1580e-04, 2.9749e-02, 1.9241e-06, 1.6690e-01, 1.1916e-05, 2.5145e-04,\n",
      "         2.4098e-02, 3.1295e-09, 1.2382e-05, 1.8317e-02, 1.6880e-06, 7.4094e-05,\n",
      "         2.8034e-07, 4.5853e-07, 6.8587e-03, 1.3243e-04, 1.6822e-02, 2.7834e-04,\n",
      "         2.6924e-04, 6.5964e-02, 1.4209e-06, 1.7487e-02, 7.6096e-05, 1.6646e-08,\n",
      "         5.0795e-03, 1.1438e-07, 1.4954e-04, 1.2638e-02, 2.7215e-05, 1.0835e-03,\n",
      "         4.9078e-06, 2.9660e-04, 8.5484e-03, 3.1387e-02, 3.4432e-07, 3.1859e-08,\n",
      "         6.2518e-04, 1.9605e-03, 3.4135e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9995]], grad_fn=<TanhBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[3.2732e-07, 1.0149e-05, 6.9700e-07, 1.2734e-03, 8.8505e-06, 5.5716e-03,\n",
      "         8.5533e-06, 8.3866e-03, 1.8203e-01, 1.2963e-06, 1.4302e-07, 2.9640e-03,\n",
      "         2.3655e-05, 1.8017e-03, 2.8216e-03, 1.1179e-04, 2.0959e-07, 3.4044e-02,\n",
      "         8.7547e-07, 1.5152e-02, 1.0210e-06, 3.5531e-08, 3.1569e-04, 2.3720e-03,\n",
      "         1.1199e-04, 9.5848e-05, 1.3889e-02, 8.1597e-07, 1.6497e-05, 3.9292e-06,\n",
      "         1.8560e-06, 2.7134e-02, 1.1939e-05, 4.3699e-04, 9.0919e-03, 1.8172e-02,\n",
      "         1.2607e-03, 1.0348e-07, 8.8453e-07, 2.0444e-01, 3.6758e-02, 3.0942e-03,\n",
      "         3.7694e-04, 2.1176e-02, 2.5106e-05, 1.3079e-01, 3.2629e-05, 5.3443e-04,\n",
      "         2.6647e-02, 4.7312e-08, 3.1878e-04, 2.8262e-02, 4.7880e-06, 1.3937e-04,\n",
      "         4.1675e-07, 3.1624e-06, 5.4001e-03, 1.3821e-04, 1.1288e-02, 1.8499e-03,\n",
      "         7.2577e-04, 2.5942e-02, 1.3969e-05, 9.7989e-02, 2.6197e-04, 3.8247e-07,\n",
      "         1.5817e-02, 4.1235e-07, 9.6710e-04, 2.0995e-02, 3.7922e-05, 2.0653e-03,\n",
      "         1.0582e-05, 5.4725e-04, 1.0230e-02, 1.6328e-02, 7.1271e-06, 3.0731e-07,\n",
      "         5.5472e-04, 4.3537e-03, 4.7491e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9988]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[1.8049e-08, 6.8741e-06, 1.2104e-07, 5.0703e-03, 4.2963e-07, 5.2945e-03,\n",
      "         5.6746e-07, 3.2070e-02, 8.4558e-02, 8.2608e-07, 4.8092e-09, 1.8395e-03,\n",
      "         1.5417e-06, 1.2495e-04, 2.0649e-03, 2.0037e-05, 1.2099e-08, 4.8889e-02,\n",
      "         1.2107e-07, 4.8301e-03, 1.8170e-07, 7.4651e-09, 1.4201e-04, 7.4191e-04,\n",
      "         2.8811e-05, 2.6656e-05, 2.5545e-02, 5.1304e-08, 6.6366e-06, 9.1976e-07,\n",
      "         5.7428e-07, 4.0430e-02, 2.7111e-06, 6.2889e-05, 1.4369e-02, 9.5204e-02,\n",
      "         1.7363e-03, 4.9938e-08, 4.6290e-08, 1.0591e-01, 8.7393e-02, 1.6391e-03,\n",
      "         1.0827e-04, 2.9530e-02, 1.8094e-06, 1.6957e-01, 1.1111e-05, 2.4748e-04,\n",
      "         2.4335e-02, 2.7174e-09, 1.1531e-05, 1.6834e-02, 1.4487e-06, 6.8731e-05,\n",
      "         2.4439e-07, 3.9741e-07, 6.6689e-03, 1.2182e-04, 1.7457e-02, 2.6535e-04,\n",
      "         2.5939e-04, 6.4376e-02, 1.2700e-06, 1.7846e-02, 7.2872e-05, 1.4449e-08,\n",
      "         4.9382e-03, 1.0345e-07, 1.4221e-04, 1.2774e-02, 2.5428e-05, 1.0318e-03,\n",
      "         4.5909e-06, 2.8680e-04, 8.4348e-03, 3.0493e-02, 3.0559e-07, 2.8841e-08,\n",
      "         6.0177e-04, 1.9852e-03, 3.3485e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9996]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[2.8450e-07, 9.2107e-06, 6.3228e-07, 1.2339e-03, 7.6561e-06, 5.2271e-03,\n",
      "         7.7700e-06, 8.6939e-03, 1.7847e-01, 1.1709e-06, 1.2739e-07, 2.9004e-03,\n",
      "         2.3048e-05, 1.7678e-03, 2.7469e-03, 1.0310e-04, 1.8477e-07, 3.3974e-02,\n",
      "         7.8661e-07, 1.5369e-02, 9.5540e-07, 3.1129e-08, 2.9075e-04, 2.2687e-03,\n",
      "         1.0441e-04, 8.8725e-05, 1.3848e-02, 7.5444e-07, 1.5293e-05, 3.6720e-06,\n",
      "         1.6278e-06, 2.6799e-02, 1.0988e-05, 4.1629e-04, 8.9706e-03, 1.8265e-02,\n",
      "         1.2437e-03, 8.9843e-08, 7.9876e-07, 2.0777e-01, 3.7121e-02, 2.9934e-03,\n",
      "         3.5150e-04, 2.0677e-02, 2.3387e-05, 1.3416e-01, 3.0171e-05, 5.1414e-04,\n",
      "         2.8061e-02, 4.0812e-08, 3.0068e-04, 2.7040e-02, 4.4718e-06, 1.3547e-04,\n",
      "         3.7339e-07, 2.8511e-06, 5.2538e-03, 1.3491e-04, 1.1490e-02, 1.7745e-03,\n",
      "         7.0696e-04, 2.7623e-02, 1.3599e-05, 9.5268e-02, 2.4764e-04, 3.3037e-07,\n",
      "         1.5165e-02, 3.8479e-07, 9.0997e-04, 2.0469e-02, 3.5793e-05, 1.9625e-03,\n",
      "         1.0088e-05, 5.2505e-04, 1.0024e-02, 1.6588e-02, 6.3462e-06, 2.6795e-07,\n",
      "         5.2588e-04, 4.4479e-03, 4.7663e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9989]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[1.9069e-08, 7.2237e-06, 1.2569e-07, 4.9211e-03, 4.3863e-07, 5.1796e-03,\n",
      "         5.7924e-07, 3.2926e-02, 8.3401e-02, 8.6817e-07, 5.0138e-09, 1.8474e-03,\n",
      "         1.6437e-06, 1.2640e-04, 2.0522e-03, 2.0613e-05, 1.1984e-08, 5.0130e-02,\n",
      "         1.2361e-07, 4.7460e-03, 1.9130e-07, 7.8875e-09, 1.4151e-04, 7.7630e-04,\n",
      "         2.8555e-05, 2.7012e-05, 2.5352e-02, 5.3702e-08, 6.9455e-06, 9.4702e-07,\n",
      "         5.8891e-07, 4.1311e-02, 2.8788e-06, 6.3957e-05, 1.4557e-02, 9.3041e-02,\n",
      "         1.7410e-03, 5.3743e-08, 5.0328e-08, 1.0524e-01, 8.6240e-02, 1.6073e-03,\n",
      "         1.0788e-04, 2.9451e-02, 1.7936e-06, 1.7089e-01, 1.1510e-05, 2.5156e-04,\n",
      "         2.4276e-02, 2.8364e-09, 1.1869e-05, 1.6641e-02, 1.5963e-06, 7.1549e-05,\n",
      "         2.5502e-07, 4.1578e-07, 6.6450e-03, 1.2872e-04, 1.7123e-02, 2.6313e-04,\n",
      "         2.5585e-04, 6.4760e-02, 1.3488e-06, 1.7846e-02, 7.3377e-05, 1.5482e-08,\n",
      "         5.0139e-03, 1.0652e-07, 1.4232e-04, 1.3035e-02, 2.5551e-05, 1.0423e-03,\n",
      "         4.6497e-06, 2.8981e-04, 8.1258e-03, 3.0742e-02, 3.2019e-07, 2.9894e-08,\n",
      "         6.2797e-04, 2.0293e-03, 3.4604e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9995]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[2.9448e-07, 9.6451e-06, 6.7460e-07, 1.2541e-03, 8.1903e-06, 5.4587e-03,\n",
      "         7.8208e-06, 8.9243e-03, 1.7659e-01, 1.2424e-06, 1.3177e-07, 2.9584e-03,\n",
      "         2.2842e-05, 1.8004e-03, 2.6972e-03, 1.0682e-04, 2.0467e-07, 3.3025e-02,\n",
      "         8.3362e-07, 1.5617e-02, 9.8572e-07, 3.3031e-08, 3.1494e-04, 2.1787e-03,\n",
      "         1.0899e-04, 9.6975e-05, 1.3977e-02, 7.9931e-07, 1.5495e-05, 3.7504e-06,\n",
      "         1.7435e-06, 2.6623e-02, 1.0438e-05, 4.1329e-04, 9.2131e-03, 1.8379e-02,\n",
      "         1.2667e-03, 9.3641e-08, 8.4699e-07, 2.0679e-01, 3.5960e-02, 3.2476e-03,\n",
      "         3.5934e-04, 2.0239e-02, 2.4259e-05, 1.3382e-01, 3.0395e-05, 5.0361e-04,\n",
      "         2.8949e-02, 4.2908e-08, 2.9782e-04, 2.6684e-02, 4.6114e-06, 1.3742e-04,\n",
      "         4.0946e-07, 3.0981e-06, 5.1947e-03, 1.3755e-04, 1.1951e-02, 1.7935e-03,\n",
      "         6.9451e-04, 2.7319e-02, 1.3449e-05, 9.9650e-02, 2.4227e-04, 3.6979e-07,\n",
      "         1.4309e-02, 4.0050e-07, 9.0853e-04, 1.9938e-02, 3.7564e-05, 1.9999e-03,\n",
      "         1.0572e-05, 5.6558e-04, 1.0577e-02, 1.6785e-02, 6.8850e-06, 2.7283e-07,\n",
      "         5.2904e-04, 4.5190e-03, 4.6776e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9989]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[1.8852e-08, 6.8721e-06, 1.2437e-07, 4.8648e-03, 4.3144e-07, 5.2110e-03,\n",
      "         5.7757e-07, 3.2965e-02, 8.1107e-02, 8.6200e-07, 4.8910e-09, 1.8256e-03,\n",
      "         1.6476e-06, 1.2457e-04, 2.0903e-03, 2.0617e-05, 1.1419e-08, 4.9599e-02,\n",
      "         1.2059e-07, 4.5905e-03, 1.8855e-07, 7.8975e-09, 1.4156e-04, 7.8267e-04,\n",
      "         2.8460e-05, 2.6797e-05, 2.5090e-02, 5.2090e-08, 7.0922e-06, 9.4128e-07,\n",
      "         5.9567e-07, 4.2850e-02, 2.8627e-06, 6.4063e-05, 1.4560e-02, 9.4504e-02,\n",
      "         1.7108e-03, 5.2433e-08, 5.0105e-08, 1.0656e-01, 8.5598e-02, 1.5702e-03,\n",
      "         1.0465e-04, 2.8783e-02, 1.7799e-06, 1.7082e-01, 1.1423e-05, 2.4600e-04,\n",
      "         2.5021e-02, 2.7415e-09, 1.1594e-05, 1.6765e-02, 1.6100e-06, 7.1787e-05,\n",
      "         2.4716e-07, 4.1831e-07, 6.7140e-03, 1.2787e-04, 1.6332e-02, 2.6789e-04,\n",
      "         2.5292e-04, 6.4841e-02, 1.3899e-06, 1.7820e-02, 7.2000e-05, 1.5415e-08,\n",
      "         5.0255e-03, 1.0295e-07, 1.4136e-04, 1.3212e-02, 2.5289e-05, 1.0403e-03,\n",
      "         4.6610e-06, 2.8789e-04, 8.1284e-03, 3.1291e-02, 3.1438e-07, 2.8620e-08,\n",
      "         6.3687e-04, 1.9757e-03, 3.4056e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9995]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[2.1860e-07, 7.7856e-06, 5.1239e-07, 1.1080e-03, 6.8697e-06, 4.8781e-03,\n",
      "         6.3067e-06, 8.0062e-03, 1.7843e-01, 9.7534e-07, 9.7415e-08, 2.8872e-03,\n",
      "         1.8381e-05, 1.6969e-03, 2.3900e-03, 9.5101e-05, 1.5907e-07, 3.1383e-02,\n",
      "         6.2903e-07, 1.5441e-02, 7.3316e-07, 2.3000e-08, 2.9066e-04, 1.9998e-03,\n",
      "         9.4122e-05, 8.3962e-05, 1.3268e-02, 6.2150e-07, 1.2500e-05, 2.7638e-06,\n",
      "         1.3496e-06, 2.5912e-02, 8.4023e-06, 3.6362e-04, 8.4982e-03, 1.7029e-02,\n",
      "         1.1327e-03, 6.6333e-08, 6.4900e-07, 2.1238e-01, 3.4949e-02, 3.1595e-03,\n",
      "         3.3997e-04, 1.8795e-02, 2.1220e-05, 1.3839e-01, 2.5782e-05, 4.3611e-04,\n",
      "         2.9571e-02, 3.0371e-08, 2.7137e-04, 2.5864e-02, 3.5522e-06, 1.1661e-04,\n",
      "         3.1804e-07, 2.4677e-06, 4.8217e-03, 1.1266e-04, 1.1563e-02, 1.6150e-03,\n",
      "         5.9879e-04, 2.7672e-02, 1.0678e-05, 1.0372e-01, 2.0744e-04, 2.8410e-07,\n",
      "         1.4313e-02, 3.0894e-07, 8.4554e-04, 1.8309e-02, 3.1343e-05, 1.8345e-03,\n",
      "         8.4039e-06, 5.2188e-04, 9.6602e-03, 1.5704e-02, 5.7436e-06, 2.0243e-07,\n",
      "         4.3159e-04, 4.3391e-03, 4.2915e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9992]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[1.2818e-08, 5.2834e-06, 8.7205e-08, 4.4534e-03, 3.0914e-07, 4.7928e-03,\n",
      "         4.2461e-07, 3.2292e-02, 8.1632e-02, 6.3827e-07, 3.0819e-09, 1.6651e-03,\n",
      "         1.2443e-06, 1.0328e-04, 1.9147e-03, 1.6476e-05, 7.2565e-09, 4.9751e-02,\n",
      "         8.4523e-08, 4.2841e-03, 1.3110e-07, 5.2732e-09, 1.1666e-04, 7.1265e-04,\n",
      "         2.2596e-05, 2.0458e-05, 2.4010e-02, 3.5393e-08, 5.3595e-06, 6.9995e-07,\n",
      "         4.4231e-07, 4.0204e-02, 2.2105e-06, 5.2326e-05, 1.3949e-02, 9.5934e-02,\n",
      "         1.5401e-03, 3.6513e-08, 3.4566e-08, 1.0922e-01, 8.4277e-02, 1.4168e-03,\n",
      "         8.7837e-05, 2.8391e-02, 1.2585e-06, 1.8009e-01, 9.0300e-06, 2.0573e-04,\n",
      "         2.4694e-02, 1.7399e-09, 9.4167e-06, 1.6024e-02, 1.2010e-06, 6.2122e-05,\n",
      "         1.7574e-07, 3.0149e-07, 6.3403e-03, 1.0932e-04, 1.5515e-02, 2.2629e-04,\n",
      "         2.1409e-04, 6.5773e-02, 1.0166e-06, 1.7219e-02, 5.9321e-05, 9.9115e-09,\n",
      "         4.7883e-03, 7.1936e-08, 1.1693e-04, 1.2392e-02, 1.9884e-05, 9.3065e-04,\n",
      "         3.5454e-06, 2.4837e-04, 7.5745e-03, 3.0331e-02, 2.2118e-07, 1.9327e-08,\n",
      "         5.5503e-04, 1.8551e-03, 3.3752e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9996]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[1.9972e-07, 7.4659e-06, 4.6454e-07, 1.0594e-03, 6.4152e-06, 4.8201e-03,\n",
      "         5.7306e-06, 7.2653e-03, 1.8294e-01, 8.8772e-07, 8.7021e-08, 2.8492e-03,\n",
      "         1.6446e-05, 1.5969e-03, 2.2665e-03, 9.2850e-05, 1.4897e-07, 2.9442e-02,\n",
      "         5.7559e-07, 1.4682e-02, 6.6743e-07, 2.0492e-08, 2.8219e-04, 1.8578e-03,\n",
      "         8.8003e-05, 7.8687e-05, 1.2630e-02, 5.4608e-07, 1.1742e-05, 2.4440e-06,\n",
      "         1.2992e-06, 2.4979e-02, 7.4862e-06, 3.5046e-04, 8.2244e-03, 1.6234e-02,\n",
      "         1.0540e-03, 6.0233e-08, 5.8495e-07, 2.1776e-01, 3.4034e-02, 3.0945e-03,\n",
      "         3.4180e-04, 1.7650e-02, 1.9480e-05, 1.3621e-01, 2.4423e-05, 4.1692e-04,\n",
      "         2.8850e-02, 2.7372e-08, 2.6522e-04, 2.5917e-02, 3.2481e-06, 1.0829e-04,\n",
      "         2.8910e-07, 2.2618e-06, 4.6973e-03, 1.0474e-04, 1.1600e-02, 1.5508e-03,\n",
      "         5.6031e-04, 2.6744e-02, 9.8034e-06, 1.0781e-01, 1.9710e-04, 2.6109e-07,\n",
      "         1.4383e-02, 2.7553e-07, 8.1673e-04, 1.8033e-02, 3.0397e-05, 1.8092e-03,\n",
      "         7.7363e-06, 5.1107e-04, 9.2908e-03, 1.5372e-02, 5.4544e-06, 1.8502e-07,\n",
      "         3.9431e-04, 4.3357e-03, 4.1895e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9993]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[1.0093e-08, 4.5889e-06, 6.8690e-08, 4.1843e-03, 2.5792e-07, 4.7408e-03,\n",
      "         3.5453e-07, 3.1258e-02, 8.5025e-02, 5.2398e-07, 2.4078e-09, 1.6364e-03,\n",
      "         1.1217e-06, 9.8530e-05, 1.7784e-03, 1.4323e-05, 5.8983e-09, 5.2052e-02,\n",
      "         7.0294e-08, 4.1833e-03, 1.0342e-07, 3.8454e-09, 1.0587e-04, 6.6621e-04,\n",
      "         1.9854e-05, 1.8181e-05, 2.4070e-02, 2.8007e-08, 4.5660e-06, 5.6691e-07,\n",
      "         3.5284e-07, 3.9856e-02, 1.9372e-06, 4.8370e-05, 1.3567e-02, 9.1185e-02,\n",
      "         1.4340e-03, 2.8647e-08, 2.6623e-08, 1.0578e-01, 8.6592e-02, 1.3673e-03,\n",
      "         7.8127e-05, 2.8907e-02, 1.0836e-06, 1.8789e-01, 7.9462e-06, 1.9795e-04,\n",
      "         2.3372e-02, 1.3672e-09, 8.4414e-06, 1.5174e-02, 9.6666e-07, 5.3830e-05,\n",
      "         1.4130e-07, 2.4022e-07, 6.0432e-03, 9.6483e-05, 1.6031e-02, 2.0091e-04,\n",
      "         2.0321e-04, 6.4601e-02, 8.0465e-07, 1.7028e-02, 5.4715e-05, 7.8878e-09,\n",
      "         4.5609e-03, 5.9840e-08, 1.0690e-04, 1.2479e-02, 1.7214e-05, 8.8845e-04,\n",
      "         3.0436e-06, 2.2051e-04, 7.4967e-03, 2.9157e-02, 1.8834e-07, 1.6243e-08,\n",
      "         5.2508e-04, 1.8084e-03, 3.3095e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9997]], grad_fn=<TanhBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[1.7146e-07, 6.9741e-06, 4.1849e-07, 1.0303e-03, 5.7473e-06, 4.3842e-03,\n",
      "         5.2569e-06, 7.3733e-03, 1.7793e-01, 8.0494e-07, 7.6111e-08, 2.7988e-03,\n",
      "         1.6100e-05, 1.6084e-03, 2.2401e-03, 8.6352e-05, 1.3121e-07, 2.9934e-02,\n",
      "         5.2043e-07, 1.3932e-02, 6.1331e-07, 1.7994e-08, 2.5743e-04, 1.8214e-03,\n",
      "         7.9778e-05, 7.1744e-05, 1.2746e-02, 5.1447e-07, 1.0588e-05, 2.2730e-06,\n",
      "         1.1186e-06, 2.4381e-02, 7.0756e-06, 3.2641e-04, 7.7602e-03, 1.5964e-02,\n",
      "         9.9820e-04, 5.0428e-08, 5.2991e-07, 2.2610e-01, 3.3086e-02, 2.9798e-03,\n",
      "         3.2568e-04, 1.7443e-02, 1.7806e-05, 1.4166e-01, 2.2545e-05, 3.8610e-04,\n",
      "         2.9209e-02, 2.2768e-08, 2.5156e-04, 2.6892e-02, 2.8615e-06, 9.9760e-05,\n",
      "         2.5300e-07, 2.0183e-06, 4.5569e-03, 9.9232e-05, 1.1595e-02, 1.4991e-03,\n",
      "         5.3751e-04, 2.8394e-02, 9.3248e-06, 1.0177e-01, 1.8712e-04, 2.2207e-07,\n",
      "         1.4018e-02, 2.4541e-07, 7.8018e-04, 1.7221e-02, 2.8913e-05, 1.7155e-03,\n",
      "         7.1006e-06, 4.8832e-04, 8.9926e-03, 1.4959e-02, 4.8344e-06, 1.5801e-07,\n",
      "         3.8104e-04, 4.3397e-03, 4.1501e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9994]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[1.1031e-08, 4.7656e-06, 7.3841e-08, 4.2823e-03, 2.7772e-07, 4.9309e-03,\n",
      "         3.7029e-07, 3.1283e-02, 8.5685e-02, 5.5850e-07, 2.6704e-09, 1.6851e-03,\n",
      "         1.1800e-06, 1.0204e-04, 1.8055e-03, 1.5225e-05, 6.4596e-09, 5.2046e-02,\n",
      "         7.4585e-08, 4.1824e-03, 1.1096e-07, 4.1163e-09, 1.1184e-04, 6.9069e-04,\n",
      "         2.0718e-05, 1.8919e-05, 2.4303e-02, 3.0077e-08, 4.9078e-06, 6.0090e-07,\n",
      "         3.7923e-07, 4.0977e-02, 2.0599e-06, 5.1059e-05, 1.3657e-02, 9.0150e-02,\n",
      "         1.4413e-03, 3.0931e-08, 2.8327e-08, 1.0638e-01, 8.6896e-02, 1.4406e-03,\n",
      "         8.2999e-05, 2.9403e-02, 1.1766e-06, 1.8570e-01, 8.3868e-06, 2.0386e-04,\n",
      "         2.3438e-02, 1.4962e-09, 8.8325e-06, 1.5216e-02, 1.0002e-06, 5.4610e-05,\n",
      "         1.4868e-07, 2.5291e-07, 6.1013e-03, 9.9097e-05, 1.5820e-02, 2.1250e-04,\n",
      "         2.1061e-04, 6.2748e-02, 8.4709e-07, 1.7517e-02, 5.6521e-05, 8.6634e-09,\n",
      "         4.7119e-03, 6.2916e-08, 1.1103e-04, 1.3063e-02, 1.8749e-05, 9.1499e-04,\n",
      "         3.2253e-06, 2.2458e-04, 7.6901e-03, 2.9611e-02, 2.0235e-07, 1.7836e-08,\n",
      "         5.4129e-04, 1.8265e-03, 3.2223e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9997]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[1.7528e-07, 7.0564e-06, 4.2595e-07, 1.0490e-03, 5.8851e-06, 4.4754e-03,\n",
      "         5.3691e-06, 7.5683e-03, 1.7324e-01, 8.3079e-07, 7.4582e-08, 2.8086e-03,\n",
      "         1.6143e-05, 1.6726e-03, 2.2743e-03, 8.9451e-05, 1.3459e-07, 3.0123e-02,\n",
      "         5.5215e-07, 1.4120e-02, 6.2626e-07, 1.8811e-08, 2.4788e-04, 1.8034e-03,\n",
      "         7.9702e-05, 6.8986e-05, 1.3301e-02, 5.2096e-07, 1.0225e-05, 2.4531e-06,\n",
      "         1.1508e-06, 2.3966e-02, 7.4220e-06, 3.2371e-04, 7.6570e-03, 1.6506e-02,\n",
      "         1.0477e-03, 5.2665e-08, 5.3857e-07, 2.2601e-01, 3.3826e-02, 2.8866e-03,\n",
      "         3.2832e-04, 1.8041e-02, 1.7476e-05, 1.4283e-01, 2.3429e-05, 3.9940e-04,\n",
      "         3.0144e-02, 2.3972e-08, 2.5295e-04, 2.6823e-02, 2.8518e-06, 9.8181e-05,\n",
      "         2.4752e-07, 1.9870e-06, 4.5135e-03, 1.0404e-04, 1.1889e-02, 1.5384e-03,\n",
      "         5.4387e-04, 2.9026e-02, 9.6931e-06, 1.0086e-01, 1.9375e-04, 2.1077e-07,\n",
      "         1.3957e-02, 2.4840e-07, 7.5648e-04, 1.6936e-02, 3.0023e-05, 1.7389e-03,\n",
      "         7.2297e-06, 4.8603e-04, 9.1342e-03, 1.5212e-02, 4.6272e-06, 1.5860e-07,\n",
      "         4.0047e-04, 4.2758e-03, 4.2110e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9993]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[9.7902e-09, 4.5632e-06, 6.7276e-08, 4.2131e-03, 2.3928e-07, 4.7113e-03,\n",
      "         3.4052e-07, 3.0678e-02, 8.1479e-02, 5.3094e-07, 2.5127e-09, 1.6761e-03,\n",
      "         1.1112e-06, 9.3285e-05, 1.7524e-03, 1.5315e-05, 5.5771e-09, 4.9542e-02,\n",
      "         6.9682e-08, 4.0273e-03, 1.0394e-07, 3.7832e-09, 1.0484e-04, 6.6651e-04,\n",
      "         2.0040e-05, 1.8989e-05, 2.4704e-02, 2.6775e-08, 4.8959e-06, 5.7631e-07,\n",
      "         3.5498e-07, 4.1551e-02, 1.9538e-06, 5.0194e-05, 1.3427e-02, 9.0745e-02,\n",
      "         1.4078e-03, 2.9820e-08, 2.5526e-08, 1.0396e-01, 8.5703e-02, 1.4304e-03,\n",
      "         8.0959e-05, 2.9293e-02, 1.1087e-06, 1.8922e-01, 8.1757e-06, 1.8769e-04,\n",
      "         2.3464e-02, 1.3367e-09, 8.2995e-06, 1.6244e-02, 9.9318e-07, 5.5353e-05,\n",
      "         1.4426e-07, 2.3132e-07, 6.2174e-03, 9.9142e-05, 1.5914e-02, 2.0591e-04,\n",
      "         1.9416e-04, 6.5315e-02, 8.1206e-07, 1.7743e-02, 5.4413e-05, 7.7005e-09,\n",
      "         4.5617e-03, 5.6569e-08, 1.0845e-04, 1.3197e-02, 1.8355e-05, 8.9737e-04,\n",
      "         3.1221e-06, 2.0857e-04, 7.7239e-03, 3.0303e-02, 1.8608e-07, 1.6368e-08,\n",
      "         4.9698e-04, 1.7278e-03, 3.4456e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9997]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[1.8185e-07, 6.9600e-06, 4.0080e-07, 1.0024e-03, 6.0384e-06, 4.5943e-03,\n",
      "         5.4739e-06, 6.9082e-03, 1.8223e-01, 7.8860e-07, 7.3718e-08, 2.6841e-03,\n",
      "         1.5626e-05, 1.6598e-03, 2.2656e-03, 8.4412e-05, 1.3167e-07, 3.0215e-02,\n",
      "         5.4109e-07, 1.4429e-02, 5.8913e-07, 1.7731e-08, 2.5363e-04, 1.8145e-03,\n",
      "         7.9984e-05, 6.8543e-05, 1.2892e-02, 4.9424e-07, 1.0322e-05, 2.3128e-06,\n",
      "         1.1219e-06, 2.4467e-02, 7.2352e-06, 3.1626e-04, 7.7567e-03, 1.5992e-02,\n",
      "         1.0160e-03, 5.1612e-08, 5.2167e-07, 2.2251e-01, 3.4420e-02, 2.6558e-03,\n",
      "         3.2910e-04, 1.7870e-02, 1.7433e-05, 1.4318e-01, 2.3228e-05, 4.0936e-04,\n",
      "         2.7965e-02, 2.4123e-08, 2.5348e-04, 2.6432e-02, 2.7166e-06, 9.7578e-05,\n",
      "         2.4678e-07, 2.0075e-06, 4.4861e-03, 9.8705e-05, 1.1246e-02, 1.5207e-03,\n",
      "         5.5456e-04, 2.7373e-02, 9.5800e-06, 1.0105e-01, 1.9712e-04, 2.1480e-07,\n",
      "         1.4358e-02, 2.3474e-07, 7.9315e-04, 1.7218e-02, 2.8404e-05, 1.6937e-03,\n",
      "         6.7990e-06, 4.6900e-04, 8.7729e-03, 1.4469e-02, 4.7422e-06, 1.6268e-07,\n",
      "         3.9916e-04, 4.0597e-03, 4.2372e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9994]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[8.0325e-09, 4.1691e-06, 5.6800e-08, 4.1111e-03, 2.0281e-07, 4.4046e-03,\n",
      "         2.8653e-07, 2.9970e-02, 8.0703e-02, 4.6573e-07, 2.0197e-09, 1.5981e-03,\n",
      "         9.5319e-07, 8.2195e-05, 1.6589e-03, 1.3951e-05, 4.5846e-09, 4.8433e-02,\n",
      "         5.7340e-08, 3.8700e-03, 8.7792e-08, 3.1708e-09, 9.7114e-05, 6.3106e-04,\n",
      "         1.8246e-05, 1.7039e-05, 2.4248e-02, 2.2496e-08, 4.3814e-06, 5.0569e-07,\n",
      "         3.0933e-07, 4.1039e-02, 1.7234e-06, 4.5840e-05, 1.3245e-02, 9.1176e-02,\n",
      "         1.3523e-03, 2.5403e-08, 2.1110e-08, 1.0341e-01, 8.6334e-02, 1.3622e-03,\n",
      "         7.6408e-05, 2.8934e-02, 9.6527e-07, 1.9378e-01, 7.2778e-06, 1.6902e-04,\n",
      "         2.3374e-02, 1.0593e-09, 7.3150e-06, 1.6477e-02, 8.6850e-07, 5.1964e-05,\n",
      "         1.2534e-07, 1.9971e-07, 6.1778e-03, 9.1240e-05, 1.5149e-02, 1.8646e-04,\n",
      "         1.7490e-04, 6.7451e-02, 6.9197e-07, 1.7148e-02, 4.9734e-05, 6.2254e-09,\n",
      "         4.4557e-03, 4.7889e-08, 9.9471e-05, 1.2713e-02, 1.6271e-05, 8.4155e-04,\n",
      "         2.7980e-06, 1.9946e-04, 7.4791e-03, 2.9974e-02, 1.5770e-07, 1.3149e-08,\n",
      "         4.6093e-04, 1.6524e-03, 3.4959e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9998]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[1.5673e-07, 6.4262e-06, 3.5466e-07, 9.6294e-04, 5.3361e-06, 4.3226e-03,\n",
      "         4.9416e-06, 6.9168e-03, 1.7916e-01, 7.0803e-07, 6.4375e-08, 2.7201e-03,\n",
      "         1.5198e-05, 1.6569e-03, 2.2491e-03, 8.0679e-05, 1.1613e-07, 3.1048e-02,\n",
      "         4.8739e-07, 1.4326e-02, 5.3350e-07, 1.5455e-08, 2.3766e-04, 1.7713e-03,\n",
      "         7.2541e-05, 6.3634e-05, 1.2818e-02, 4.5195e-07, 9.3977e-06, 2.1130e-06,\n",
      "         9.8573e-07, 2.4043e-02, 6.7463e-06, 3.0208e-04, 7.5572e-03, 1.6139e-02,\n",
      "         9.8289e-04, 4.4990e-08, 4.7236e-07, 2.2747e-01, 3.4420e-02, 2.5888e-03,\n",
      "         3.1379e-04, 1.7570e-02, 1.5856e-05, 1.4509e-01, 2.2051e-05, 3.9181e-04,\n",
      "         2.8808e-02, 2.0696e-08, 2.4197e-04, 2.6143e-02, 2.4094e-06, 9.0877e-05,\n",
      "         2.2200e-07, 1.7946e-06, 4.3398e-03, 9.2348e-05, 1.1371e-02, 1.4836e-03,\n",
      "         5.4102e-04, 2.7132e-02, 9.1399e-06, 9.9488e-02, 1.8935e-04, 1.8571e-07,\n",
      "         1.4130e-02, 2.1173e-07, 7.6548e-04, 1.6553e-02, 2.6445e-05, 1.6088e-03,\n",
      "         6.2647e-06, 4.5271e-04, 8.4827e-03, 1.3995e-02, 4.2912e-06, 1.4273e-07,\n",
      "         3.7897e-04, 4.0939e-03, 4.1957e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9994]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[1.0703e-08, 4.8545e-06, 7.0324e-08, 4.1598e-03, 2.4971e-07, 4.5771e-03,\n",
      "         3.4860e-07, 3.0582e-02, 7.9858e-02, 5.6442e-07, 2.6589e-09, 1.6574e-03,\n",
      "         1.1557e-06, 9.0602e-05, 1.8131e-03, 1.6215e-05, 5.7436e-09, 4.8562e-02,\n",
      "         7.0011e-08, 4.0778e-03, 1.1276e-07, 4.1998e-09, 1.0842e-04, 7.1173e-04,\n",
      "         2.0664e-05, 1.8902e-05, 2.4247e-02, 2.8023e-08, 5.3347e-06, 6.2635e-07,\n",
      "         3.8781e-07, 4.1940e-02, 2.0880e-06, 5.0732e-05, 1.3748e-02, 8.8545e-02,\n",
      "         1.3626e-03, 3.3508e-08, 2.8686e-08, 1.0576e-01, 8.3674e-02, 1.3958e-03,\n",
      "         8.5249e-05, 2.8891e-02, 1.0795e-06, 1.8958e-01, 8.4030e-06, 1.7391e-04,\n",
      "         2.4499e-02, 1.3683e-09, 8.6911e-06, 1.6777e-02, 1.1095e-06, 6.1346e-05,\n",
      "         1.5774e-07, 2.5615e-07, 6.5310e-03, 1.0794e-04, 1.4027e-02, 2.0497e-04,\n",
      "         1.8590e-04, 6.9011e-02, 8.6207e-07, 1.7380e-02, 5.3425e-05, 8.0634e-09,\n",
      "         4.6859e-03, 5.7107e-08, 1.0589e-04, 1.2988e-02, 1.8103e-05, 8.7178e-04,\n",
      "         3.3174e-06, 2.2039e-04, 7.5514e-03, 3.1050e-02, 1.9220e-07, 1.6103e-08,\n",
      "         5.0479e-04, 1.7711e-03, 3.5645e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9997]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[1.5205e-07, 5.9168e-06, 3.1743e-07, 8.6166e-04, 5.2625e-06, 4.7714e-03,\n",
      "         4.6311e-06, 5.9676e-03, 1.9472e-01, 6.3069e-07, 5.6099e-08, 2.5375e-03,\n",
      "         1.2804e-05, 1.5451e-03, 2.1099e-03, 7.4290e-05, 1.0540e-07, 2.8873e-02,\n",
      "         4.4117e-07, 1.3948e-02, 4.2115e-07, 1.3253e-08, 2.4128e-04, 1.6508e-03,\n",
      "         7.2051e-05, 6.3502e-05, 1.2805e-02, 3.6363e-07, 8.7250e-06, 1.7661e-06,\n",
      "         9.4457e-07, 2.4131e-02, 5.6362e-06, 2.8379e-04, 7.5699e-03, 1.5261e-02,\n",
      "         9.3379e-04, 3.9985e-08, 4.0528e-07, 2.2217e-01, 3.3680e-02, 2.4168e-03,\n",
      "         2.9912e-04, 1.7057e-02, 1.4737e-05, 1.4069e-01, 2.0108e-05, 3.9054e-04,\n",
      "         2.6064e-02, 1.9028e-08, 2.2076e-04, 2.4968e-02, 2.1110e-06, 7.9639e-05,\n",
      "         2.0052e-07, 1.6958e-06, 4.1252e-03, 7.9721e-05, 1.0991e-02, 1.3900e-03,\n",
      "         5.0242e-04, 2.3022e-02, 7.6495e-06, 1.1038e-01, 1.7971e-04, 1.7931e-07,\n",
      "         1.4157e-02, 1.8162e-07, 7.5516e-04, 1.6380e-02, 2.3798e-05, 1.6387e-03,\n",
      "         5.4825e-06, 4.1422e-04, 8.2567e-03, 1.3207e-02, 4.2921e-06, 1.3026e-07,\n",
      "         3.5525e-04, 3.6753e-03, 3.9139e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9995]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[1.0350e-08, 4.7487e-06, 6.8440e-08, 4.1136e-03, 2.4065e-07, 4.4817e-03,\n",
      "         3.3999e-07, 3.0329e-02, 7.9344e-02, 5.4480e-07, 2.5424e-09, 1.6191e-03,\n",
      "         1.1310e-06, 8.9296e-05, 1.7981e-03, 1.5691e-05, 5.5090e-09, 4.9122e-02,\n",
      "         6.7056e-08, 4.1155e-03, 1.0973e-07, 4.1057e-09, 1.0442e-04, 7.2557e-04,\n",
      "         2.0342e-05, 1.8564e-05, 2.4446e-02, 2.7695e-08, 5.1541e-06, 6.1174e-07,\n",
      "         3.7600e-07, 4.1340e-02, 2.0740e-06, 4.9561e-05, 1.3748e-02, 8.8496e-02,\n",
      "         1.3537e-03, 3.2448e-08, 2.8685e-08, 1.0837e-01, 8.1980e-02, 1.3501e-03,\n",
      "         8.3606e-05, 2.9482e-02, 1.0285e-06, 1.9012e-01, 8.1453e-06, 1.6785e-04,\n",
      "         2.4419e-02, 1.2975e-09, 8.6435e-06, 1.6442e-02, 1.0879e-06, 6.0437e-05,\n",
      "         1.5363e-07, 2.5295e-07, 6.4737e-03, 1.0647e-04, 1.3576e-02, 2.0231e-04,\n",
      "         1.8271e-04, 6.9910e-02, 8.4680e-07, 1.6907e-02, 5.1650e-05, 7.6743e-09,\n",
      "         4.6874e-03, 5.4493e-08, 1.0242e-04, 1.2568e-02, 1.7607e-05, 8.4133e-04,\n",
      "         3.2655e-06, 2.1793e-04, 7.3104e-03, 3.1579e-02, 1.8360e-07, 1.5437e-08,\n",
      "         4.9503e-04, 1.7425e-03, 3.5186e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9997]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[1.8668e-07, 7.3523e-06, 4.3716e-07, 1.0294e-03, 6.4879e-06, 4.8768e-03,\n",
      "         5.7628e-06, 7.2319e-03, 1.7997e-01, 8.3091e-07, 7.7313e-08, 2.7726e-03,\n",
      "         1.5846e-05, 1.7545e-03, 2.3211e-03, 8.8578e-05, 1.4041e-07, 3.1486e-02,\n",
      "         5.9217e-07, 1.4852e-02, 6.2469e-07, 2.0018e-08, 2.7403e-04, 1.8557e-03,\n",
      "         8.4529e-05, 7.3533e-05, 1.3235e-02, 5.2003e-07, 1.0941e-05, 2.4659e-06,\n",
      "         1.2145e-06, 2.5094e-02, 7.4226e-06, 3.2185e-04, 8.1381e-03, 1.7228e-02,\n",
      "         1.0724e-03, 5.5689e-08, 5.6285e-07, 2.1578e-01, 3.4684e-02, 2.7194e-03,\n",
      "         3.2455e-04, 1.8148e-02, 1.8362e-05, 1.4341e-01, 2.4642e-05, 4.2665e-04,\n",
      "         2.7844e-02, 2.6458e-08, 2.5546e-04, 2.6254e-02, 2.8371e-06, 9.9347e-05,\n",
      "         2.6253e-07, 2.1731e-06, 4.5409e-03, 1.0137e-04, 1.1069e-02, 1.6146e-03,\n",
      "         5.7414e-04, 2.7617e-02, 9.8781e-06, 1.0293e-01, 2.0291e-04, 2.2749e-07,\n",
      "         1.4236e-02, 2.4283e-07, 8.1247e-04, 1.7688e-02, 3.0141e-05, 1.7140e-03,\n",
      "         6.9867e-06, 4.8674e-04, 9.0960e-03, 1.4727e-02, 4.9480e-06, 1.7871e-07,\n",
      "         4.2350e-04, 3.9617e-03, 4.3378e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9993]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[1.2616e-08, 5.2197e-06, 8.0359e-08, 4.1647e-03, 2.8623e-07, 4.8074e-03,\n",
      "         3.9147e-07, 3.0095e-02, 8.2121e-02, 6.2303e-07, 3.2023e-09, 1.7073e-03,\n",
      "         1.3179e-06, 9.9402e-05, 1.8911e-03, 1.6845e-05, 7.0027e-09, 4.9614e-02,\n",
      "         8.1037e-08, 4.3164e-03, 1.2869e-07, 4.9236e-09, 1.1847e-04, 7.6761e-04,\n",
      "         2.2357e-05, 2.0367e-05, 2.4769e-02, 3.2127e-08, 5.9698e-06, 6.6223e-07,\n",
      "         4.3489e-07, 4.1996e-02, 2.3724e-06, 5.6314e-05, 1.4043e-02, 8.8269e-02,\n",
      "         1.3667e-03, 3.8898e-08, 3.3356e-08, 1.0558e-01, 8.2691e-02, 1.3721e-03,\n",
      "         8.7041e-05, 2.9792e-02, 1.2214e-06, 1.8669e-01, 9.0996e-06, 1.8368e-04,\n",
      "         2.4719e-02, 1.6601e-09, 9.7292e-06, 1.6091e-02, 1.2481e-06, 6.3885e-05,\n",
      "         1.8082e-07, 2.8568e-07, 6.5525e-03, 1.1274e-04, 1.3696e-02, 2.2383e-04,\n",
      "         1.9997e-04, 6.7875e-02, 9.5521e-07, 1.7405e-02, 5.6445e-05, 9.5703e-09,\n",
      "         4.8722e-03, 6.3524e-08, 1.0655e-04, 1.3812e-02, 1.9549e-05, 8.8295e-04,\n",
      "         3.7096e-06, 2.3397e-04, 7.4252e-03, 3.1762e-02, 2.1199e-07, 1.9349e-08,\n",
      "         5.2122e-04, 1.8395e-03, 3.4824e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9997]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[2.0593e-07, 8.1017e-06, 5.0453e-07, 1.1241e-03, 7.2677e-06, 5.0161e-03,\n",
      "         6.2936e-06, 7.7734e-03, 1.7692e-01, 9.4651e-07, 8.8190e-08, 2.8436e-03,\n",
      "         1.7353e-05, 1.8398e-03, 2.3794e-03, 9.5612e-05, 1.5982e-07, 3.2268e-02,\n",
      "         6.8896e-07, 1.4972e-02, 7.3326e-07, 2.4455e-08, 2.9231e-04, 1.9474e-03,\n",
      "         8.9487e-05, 8.0019e-05, 1.3671e-02, 6.0207e-07, 1.2002e-05, 2.8689e-06,\n",
      "         1.3901e-06, 2.5139e-02, 8.3474e-06, 3.4601e-04, 8.3444e-03, 1.8050e-02,\n",
      "         1.1505e-03, 6.5531e-08, 6.5990e-07, 2.1422e-01, 3.5119e-02, 2.8027e-03,\n",
      "         3.3905e-04, 1.9009e-02, 1.9875e-05, 1.4128e-01, 2.6693e-05, 4.4019e-04,\n",
      "         2.8166e-02, 3.0574e-08, 2.6815e-04, 2.6624e-02, 3.2048e-06, 1.0577e-04,\n",
      "         2.9596e-07, 2.4378e-06, 4.7471e-03, 1.1204e-04, 1.1155e-02, 1.7230e-03,\n",
      "         6.1018e-04, 2.9119e-02, 1.1036e-05, 9.9702e-02, 2.1626e-04, 2.5059e-07,\n",
      "         1.4463e-02, 2.7402e-07, 8.4623e-04, 1.7987e-02, 3.3481e-05, 1.8001e-03,\n",
      "         7.8496e-06, 5.3434e-04, 9.4789e-03, 1.5527e-02, 5.2930e-06, 2.0339e-07,\n",
      "         4.5752e-04, 4.1831e-03, 4.4298e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9992]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[1.1229e-08, 4.8020e-06, 7.0217e-08, 4.1281e-03, 2.6086e-07, 4.8703e-03,\n",
      "         3.5673e-07, 2.9841e-02, 8.3879e-02, 5.6259e-07, 2.6894e-09, 1.6364e-03,\n",
      "         1.1757e-06, 9.5490e-05, 1.8689e-03, 1.5646e-05, 6.3562e-09, 4.9700e-02,\n",
      "         7.1812e-08, 4.2948e-03, 1.1376e-07, 4.3186e-09, 1.1481e-04, 7.2344e-04,\n",
      "         2.1320e-05, 1.9083e-05, 2.4409e-02, 2.8560e-08, 5.4618e-06, 5.9797e-07,\n",
      "         3.8084e-07, 4.2072e-02, 2.1334e-06, 5.2224e-05, 1.3963e-02, 8.7013e-02,\n",
      "         1.3197e-03, 3.2703e-08, 2.8689e-08, 1.0371e-01, 8.3244e-02, 1.3233e-03,\n",
      "         7.9107e-05, 2.9111e-02, 1.1492e-06, 1.9075e-01, 8.4431e-06, 1.8260e-04,\n",
      "         2.4890e-02, 1.4399e-09, 9.0000e-06, 1.6020e-02, 1.1198e-06, 5.8026e-05,\n",
      "         1.6005e-07, 2.5986e-07, 6.3932e-03, 1.0424e-04, 1.4060e-02, 2.1405e-04,\n",
      "         1.8844e-04, 6.7273e-02, 8.6857e-07, 1.7317e-02, 5.2875e-05, 8.3731e-09,\n",
      "         4.6740e-03, 5.7151e-08, 1.0310e-04, 1.3387e-02, 1.8226e-05, 8.3966e-04,\n",
      "         3.3870e-06, 2.2278e-04, 7.5588e-03, 3.1275e-02, 1.9992e-07, 1.6721e-08,\n",
      "         5.0674e-04, 1.7753e-03, 3.4588e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9997]], grad_fn=<TanhBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[1.8491e-07, 7.1640e-06, 4.2636e-07, 1.0102e-03, 6.2812e-06, 4.8380e-03,\n",
      "         5.7500e-06, 7.2116e-03, 1.7967e-01, 8.0329e-07, 7.5377e-08, 2.7540e-03,\n",
      "         1.5759e-05, 1.7291e-03, 2.3249e-03, 8.7205e-05, 1.3685e-07, 3.2671e-02,\n",
      "         5.8623e-07, 1.4786e-02, 6.0227e-07, 1.9547e-08, 2.7262e-04, 1.8523e-03,\n",
      "         8.3420e-05, 7.6199e-05, 1.3381e-02, 5.2080e-07, 1.0771e-05, 2.3997e-06,\n",
      "         1.1716e-06, 2.5153e-02, 7.3204e-06, 3.2142e-04, 7.9796e-03, 1.7700e-02,\n",
      "         1.0727e-03, 5.5628e-08, 5.6333e-07, 2.1450e-01, 3.5281e-02, 2.6432e-03,\n",
      "         3.1940e-04, 1.8078e-02, 1.8036e-05, 1.4534e-01, 2.4735e-05, 4.3366e-04,\n",
      "         2.7644e-02, 2.5164e-08, 2.4566e-04, 2.5880e-02, 2.7676e-06, 9.5815e-05,\n",
      "         2.5624e-07, 2.1358e-06, 4.4239e-03, 9.9486e-05, 1.1075e-02, 1.6343e-03,\n",
      "         5.6799e-04, 2.6842e-02, 9.7504e-06, 1.0210e-01, 2.0510e-04, 2.2142e-07,\n",
      "         1.4203e-02, 2.3801e-07, 8.1514e-04, 1.7679e-02, 2.8970e-05, 1.7211e-03,\n",
      "         7.1219e-06, 4.7024e-04, 9.1357e-03, 1.4786e-02, 4.9334e-06, 1.7621e-07,\n",
      "         4.2410e-04, 3.9600e-03, 4.2741e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9993]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[1.1295e-08, 4.8223e-06, 7.0430e-08, 4.0457e-03, 2.6334e-07, 4.7899e-03,\n",
      "         3.5271e-07, 2.9874e-02, 8.3072e-02, 5.6058e-07, 2.6645e-09, 1.6128e-03,\n",
      "         1.1893e-06, 9.5552e-05, 1.8593e-03, 1.5409e-05, 6.4058e-09, 4.9594e-02,\n",
      "         7.0459e-08, 4.2493e-03, 1.1372e-07, 4.4009e-09, 1.1364e-04, 7.4146e-04,\n",
      "         2.1361e-05, 1.8498e-05, 2.4477e-02, 2.8442e-08, 5.4059e-06, 6.1084e-07,\n",
      "         3.8363e-07, 4.1890e-02, 2.1405e-06, 5.2121e-05, 1.4207e-02, 8.9070e-02,\n",
      "         1.3257e-03, 3.2158e-08, 2.9241e-08, 1.0507e-01, 8.4433e-02, 1.3014e-03,\n",
      "         7.7533e-05, 2.8874e-02, 1.1363e-06, 1.8980e-01, 8.4670e-06, 1.7974e-04,\n",
      "         2.4936e-02, 1.4171e-09, 8.8855e-06, 1.5763e-02, 1.1069e-06, 5.8605e-05,\n",
      "         1.5759e-07, 2.6498e-07, 6.4058e-03, 1.0335e-04, 1.3392e-02, 2.1722e-04,\n",
      "         1.8819e-04, 6.7191e-02, 8.7817e-07, 1.7085e-02, 5.1472e-05, 8.3648e-09,\n",
      "         4.7768e-03, 5.5832e-08, 1.0158e-04, 1.3101e-02, 1.8056e-05, 8.2930e-04,\n",
      "         3.4376e-06, 2.2939e-04, 7.3735e-03, 3.0983e-02, 1.9633e-07, 1.6481e-08,\n",
      "         5.0568e-04, 1.7793e-03, 3.4008e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9997]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[1.9665e-07, 7.7560e-06, 4.7637e-07, 1.0773e-03, 6.8110e-06, 5.0332e-03,\n",
      "         6.3070e-06, 7.7215e-03, 1.7550e-01, 8.7666e-07, 8.3111e-08, 2.8115e-03,\n",
      "         1.6062e-05, 1.7786e-03, 2.3424e-03, 9.1850e-05, 1.4990e-07, 3.3244e-02,\n",
      "         6.3120e-07, 1.4884e-02, 6.7829e-07, 2.2667e-08, 2.8946e-04, 1.8929e-03,\n",
      "         9.0571e-05, 8.1693e-05, 1.3675e-02, 5.8499e-07, 1.1664e-05, 2.6160e-06,\n",
      "         1.2866e-06, 2.5364e-02, 7.7084e-06, 3.3563e-04, 8.3028e-03, 1.8163e-02,\n",
      "         1.1173e-03, 6.2765e-08, 6.2301e-07, 2.1010e-01, 3.6054e-02, 2.7803e-03,\n",
      "         3.2479e-04, 1.8197e-02, 1.9259e-05, 1.4767e-01, 2.5855e-05, 4.3823e-04,\n",
      "         2.7578e-02, 2.8742e-08, 2.5569e-04, 2.5838e-02, 3.0752e-06, 1.0190e-04,\n",
      "         2.8367e-07, 2.3139e-06, 4.5659e-03, 1.0668e-04, 1.1268e-02, 1.7059e-03,\n",
      "         5.8815e-04, 2.7274e-02, 1.0142e-05, 1.0195e-01, 2.0882e-04, 2.4955e-07,\n",
      "         1.4226e-02, 2.6506e-07, 8.4275e-04, 1.8134e-02, 3.0834e-05, 1.7745e-03,\n",
      "         7.6878e-06, 4.9848e-04, 9.5040e-03, 1.5251e-02, 5.4097e-06, 2.0004e-07,\n",
      "         4.4878e-04, 3.9303e-03, 4.4119e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9993]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[1.2037e-08, 5.2651e-06, 7.5856e-08, 4.1180e-03, 2.7030e-07, 4.6845e-03,\n",
      "         3.7751e-07, 2.9922e-02, 8.0677e-02, 6.0488e-07, 2.8966e-09, 1.6231e-03,\n",
      "         1.2637e-06, 9.6912e-05, 1.8969e-03, 1.6702e-05, 6.7790e-09, 4.8660e-02,\n",
      "         7.5497e-08, 4.2503e-03, 1.2574e-07, 4.8899e-09, 1.1396e-04, 7.4471e-04,\n",
      "         2.2163e-05, 1.9998e-05, 2.5018e-02, 3.1120e-08, 5.7178e-06, 6.6005e-07,\n",
      "         4.1236e-07, 4.3048e-02, 2.2875e-06, 5.3150e-05, 1.4219e-02, 8.8472e-02,\n",
      "         1.3220e-03, 3.5859e-08, 3.2677e-08, 1.0487e-01, 8.2407e-02, 1.2966e-03,\n",
      "         8.1764e-05, 2.8341e-02, 1.1808e-06, 1.8902e-01, 8.9338e-06, 1.7698e-04,\n",
      "         2.5455e-02, 1.4989e-09, 9.2541e-06, 1.6691e-02, 1.2246e-06, 6.1331e-05,\n",
      "         1.7476e-07, 2.8463e-07, 6.6114e-03, 1.1036e-04, 1.3515e-02, 2.2342e-04,\n",
      "         1.8793e-04, 6.9212e-02, 9.6100e-07, 1.7004e-02, 5.3316e-05, 8.9322e-09,\n",
      "         4.8232e-03, 5.9750e-08, 1.0571e-04, 1.2722e-02, 1.8711e-05, 8.2510e-04,\n",
      "         3.6593e-06, 2.3647e-04, 7.2874e-03, 3.1573e-02, 2.1021e-07, 1.7195e-08,\n",
      "         5.1501e-04, 1.7901e-03, 3.5770e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9997]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[1.7942e-07, 6.8992e-06, 3.9983e-07, 9.8274e-04, 6.1247e-06, 5.0444e-03,\n",
      "         5.5212e-06, 6.9475e-03, 1.8726e-01, 7.4043e-07, 6.9488e-08, 2.6147e-03,\n",
      "         1.4207e-05, 1.6755e-03, 2.2573e-03, 7.9969e-05, 1.2689e-07, 3.2282e-02,\n",
      "         5.3020e-07, 1.4715e-02, 5.3454e-07, 1.8124e-08, 2.7725e-04, 1.8475e-03,\n",
      "         8.2131e-05, 7.4231e-05, 1.2951e-02, 4.7843e-07, 1.0504e-05, 2.1829e-06,\n",
      "         1.1248e-06, 2.5739e-02, 6.7235e-06, 3.1057e-04, 7.9634e-03, 1.7015e-02,\n",
      "         1.0157e-03, 5.1881e-08, 5.2658e-07, 2.1324e-01, 3.6176e-02, 2.5843e-03,\n",
      "         3.0625e-04, 1.8209e-02, 1.7120e-05, 1.4264e-01, 2.3089e-05, 4.3034e-04,\n",
      "         2.6241e-02, 2.3878e-08, 2.3236e-04, 2.5134e-02, 2.6318e-06, 9.1075e-05,\n",
      "         2.4263e-07, 2.0591e-06, 4.2290e-03, 9.2361e-05, 1.0538e-02, 1.5670e-03,\n",
      "         5.5468e-04, 2.4835e-02, 8.7327e-06, 1.0473e-01, 1.9682e-04, 2.1645e-07,\n",
      "         1.4339e-02, 2.1738e-07, 8.2511e-04, 1.7724e-02, 2.6703e-05, 1.7082e-03,\n",
      "         6.5213e-06, 4.4831e-04, 9.0609e-03, 1.4338e-02, 4.8996e-06, 1.7118e-07,\n",
      "         4.0821e-04, 3.6904e-03, 4.1462e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9994]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[1.0074e-08, 4.8057e-06, 6.4550e-08, 3.9815e-03, 2.3615e-07, 4.5409e-03,\n",
      "         3.2740e-07, 2.9685e-02, 8.1238e-02, 5.3534e-07, 2.3856e-09, 1.5787e-03,\n",
      "         1.1191e-06, 8.9487e-05, 1.8011e-03, 1.5310e-05, 5.5184e-09, 4.8222e-02,\n",
      "         6.4690e-08, 4.1680e-03, 1.0752e-07, 4.0280e-09, 1.0520e-04, 7.0672e-04,\n",
      "         2.0005e-05, 1.7967e-05, 2.4635e-02, 2.5878e-08, 5.1256e-06, 5.7687e-07,\n",
      "         3.5809e-07, 4.1881e-02, 2.0325e-06, 4.8358e-05, 1.3893e-02, 8.8935e-02,\n",
      "         1.2704e-03, 3.0395e-08, 2.7347e-08, 1.0523e-01, 8.1342e-02, 1.2584e-03,\n",
      "         7.6317e-05, 2.7923e-02, 1.0203e-06, 1.9358e-01, 7.9909e-06, 1.6794e-04,\n",
      "         2.4959e-02, 1.2195e-09, 8.3999e-06, 1.6519e-02, 1.0890e-06, 5.7140e-05,\n",
      "         1.5095e-07, 2.4734e-07, 6.5049e-03, 1.0282e-04, 1.3351e-02, 2.0215e-04,\n",
      "         1.7302e-04, 6.9688e-02, 8.4185e-07, 1.6901e-02, 4.9646e-05, 7.3064e-09,\n",
      "         4.6905e-03, 5.2177e-08, 9.8915e-05, 1.2554e-02, 1.6736e-05, 7.9287e-04,\n",
      "         3.2338e-06, 2.2090e-04, 7.1956e-03, 3.1206e-02, 1.8178e-07, 1.4490e-08,\n",
      "         4.8541e-04, 1.7390e-03, 3.6042e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9997]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[1.6509e-07, 6.3482e-06, 3.8539e-07, 9.6670e-04, 5.6759e-06, 4.7155e-03,\n",
      "         5.1003e-06, 6.8588e-03, 1.8698e-01, 7.2086e-07, 6.4211e-08, 2.6869e-03,\n",
      "         1.3771e-05, 1.6271e-03, 2.2282e-03, 7.9954e-05, 1.1888e-07, 3.1237e-02,\n",
      "         5.0166e-07, 1.4330e-02, 5.0259e-07, 1.7304e-08, 2.6330e-04, 1.8189e-03,\n",
      "         7.8549e-05, 7.1238e-05, 1.3300e-02, 4.5176e-07, 9.7250e-06, 2.1041e-06,\n",
      "         1.0664e-06, 2.5278e-02, 6.3494e-06, 3.0958e-04, 7.7109e-03, 1.6972e-02,\n",
      "         9.8879e-04, 4.8281e-08, 5.0500e-07, 2.1738e-01, 3.5258e-02, 2.6040e-03,\n",
      "         2.9948e-04, 1.8013e-02, 1.6568e-05, 1.4441e-01, 2.2060e-05, 4.0318e-04,\n",
      "         2.6754e-02, 2.1930e-08, 2.2795e-04, 2.4801e-02, 2.4824e-06, 8.5648e-05,\n",
      "         2.2439e-07, 1.9030e-06, 4.1650e-03, 9.0313e-05, 1.0548e-02, 1.5379e-03,\n",
      "         5.3715e-04, 2.4956e-02, 8.4282e-06, 1.0372e-01, 1.8678e-04, 1.9910e-07,\n",
      "         1.4014e-02, 2.0391e-07, 7.8737e-04, 1.7189e-02, 2.6600e-05, 1.6669e-03,\n",
      "         6.3548e-06, 4.4291e-04, 8.7971e-03, 1.4355e-02, 4.4354e-06, 1.5461e-07,\n",
      "         3.8070e-04, 3.7768e-03, 3.9654e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9994]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[1.0370e-08, 4.6975e-06, 6.4470e-08, 4.0056e-03, 2.3626e-07, 4.5698e-03,\n",
      "         3.3737e-07, 2.9862e-02, 8.0261e-02, 5.3314e-07, 2.4045e-09, 1.5824e-03,\n",
      "         1.1474e-06, 9.1190e-05, 1.8405e-03, 1.5794e-05, 5.4883e-09, 4.8976e-02,\n",
      "         6.5074e-08, 4.1791e-03, 1.1279e-07, 4.0294e-09, 1.0502e-04, 7.1616e-04,\n",
      "         2.0318e-05, 1.8190e-05, 2.4322e-02, 2.6665e-08, 5.1817e-06, 5.8377e-07,\n",
      "         3.6164e-07, 4.2900e-02, 2.0850e-06, 4.7994e-05, 1.3887e-02, 8.7146e-02,\n",
      "         1.2369e-03, 3.0951e-08, 2.8620e-08, 1.0587e-01, 7.9011e-02, 1.2485e-03,\n",
      "         7.5305e-05, 2.7671e-02, 1.0209e-06, 1.9674e-01, 8.1390e-06, 1.6634e-04,\n",
      "         2.5053e-02, 1.2318e-09, 8.7301e-06, 1.6461e-02, 1.1556e-06, 5.9259e-05,\n",
      "         1.5337e-07, 2.5328e-07, 6.5769e-03, 1.0609e-04, 1.3101e-02, 2.1294e-04,\n",
      "         1.7235e-04, 6.9725e-02, 8.8860e-07, 1.6902e-02, 4.8285e-05, 7.6047e-09,\n",
      "         4.6660e-03, 5.1649e-08, 1.0019e-04, 1.2612e-02, 1.7014e-05, 7.8361e-04,\n",
      "         3.3192e-06, 2.2342e-04, 7.0881e-03, 3.0850e-02, 1.8727e-07, 1.4848e-08,\n",
      "         4.8752e-04, 1.7443e-03, 3.6404e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9997]], grad_fn=<TanhBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[1.8203e-07, 7.1129e-06, 4.3999e-07, 1.0065e-03, 6.1767e-06, 5.0504e-03,\n",
      "         5.6011e-06, 7.2050e-03, 1.8759e-01, 7.9983e-07, 7.0854e-08, 2.7158e-03,\n",
      "         1.4581e-05, 1.6715e-03, 2.2907e-03, 8.5192e-05, 1.3219e-07, 3.1405e-02,\n",
      "         5.6747e-07, 1.4539e-02, 5.6164e-07, 1.9770e-08, 2.7560e-04, 1.8180e-03,\n",
      "         8.3618e-05, 7.7132e-05, 1.3850e-02, 4.8899e-07, 1.0487e-05, 2.3168e-06,\n",
      "         1.1750e-06, 2.5689e-02, 6.7920e-06, 3.2659e-04, 8.0642e-03, 1.7517e-02,\n",
      "         1.0357e-03, 5.4443e-08, 5.6330e-07, 2.1084e-01, 3.5247e-02, 2.6916e-03,\n",
      "         3.0268e-04, 1.8377e-02, 1.7863e-05, 1.4283e-01, 2.3086e-05, 4.2260e-04,\n",
      "         2.6970e-02, 2.4876e-08, 2.2744e-04, 2.5114e-02, 2.7231e-06, 8.9399e-05,\n",
      "         2.4899e-07, 2.0934e-06, 4.2550e-03, 9.7890e-05, 1.0904e-02, 1.5916e-03,\n",
      "         5.6413e-04, 2.5347e-02, 8.8388e-06, 1.0472e-01, 1.9591e-04, 2.2242e-07,\n",
      "         1.3937e-02, 2.2108e-07, 7.9917e-04, 1.7695e-02, 2.8425e-05, 1.7273e-03,\n",
      "         6.7147e-06, 4.5304e-04, 9.1266e-03, 1.4853e-02, 4.8739e-06, 1.6965e-07,\n",
      "         4.1335e-04, 3.7042e-03, 4.0534e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9993]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[1.1315e-08, 4.7832e-06, 6.9742e-08, 4.0444e-03, 2.5425e-07, 4.5707e-03,\n",
      "         3.5608e-07, 2.9764e-02, 8.0343e-02, 5.7126e-07, 2.6657e-09, 1.6143e-03,\n",
      "         1.2112e-06, 9.3285e-05, 1.8927e-03, 1.6181e-05, 6.1142e-09, 4.9470e-02,\n",
      "         7.0420e-08, 4.1578e-03, 1.2015e-07, 4.4294e-09, 1.0918e-04, 7.4290e-04,\n",
      "         2.1444e-05, 1.8843e-05, 2.4640e-02, 2.8601e-08, 5.4070e-06, 6.2122e-07,\n",
      "         3.8977e-07, 4.1934e-02, 2.2051e-06, 5.0950e-05, 1.3944e-02, 8.9966e-02,\n",
      "         1.2845e-03, 3.3287e-08, 3.0633e-08, 1.0828e-01, 7.9461e-02, 1.2960e-03,\n",
      "         7.8916e-05, 2.8942e-02, 1.0952e-06, 1.9106e-01, 8.6632e-06, 1.6862e-04,\n",
      "         2.5341e-02, 1.3652e-09, 9.1206e-06, 1.5982e-02, 1.1572e-06, 6.1712e-05,\n",
      "         1.6283e-07, 2.6728e-07, 6.6106e-03, 1.0799e-04, 1.3036e-02, 2.2381e-04,\n",
      "         1.8109e-04, 6.8349e-02, 9.3731e-07, 1.6971e-02, 5.0932e-05, 8.3746e-09,\n",
      "         4.7743e-03, 5.4368e-08, 1.0228e-04, 1.3058e-02, 1.7979e-05, 8.0144e-04,\n",
      "         3.5204e-06, 2.2849e-04, 7.0875e-03, 3.1089e-02, 1.9176e-07, 1.6213e-08,\n",
      "         4.9877e-04, 1.7527e-03, 3.5673e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9997]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[1.7964e-07, 7.1706e-06, 4.5753e-07, 1.0691e-03, 6.1497e-06, 4.9034e-03,\n",
      "         5.6867e-06, 7.6859e-03, 1.7641e-01, 8.6192e-07, 7.3504e-08, 2.8326e-03,\n",
      "         1.5214e-05, 1.7173e-03, 2.3574e-03, 9.1434e-05, 1.3833e-07, 3.1704e-02,\n",
      "         6.0110e-07, 1.4895e-02, 6.3387e-07, 2.1261e-08, 2.7246e-04, 1.8082e-03,\n",
      "         8.6084e-05, 7.7501e-05, 1.4147e-02, 5.3036e-07, 1.0615e-05, 2.5753e-06,\n",
      "         1.2151e-06, 2.4941e-02, 7.2094e-06, 3.3784e-04, 8.0097e-03, 1.8529e-02,\n",
      "         1.0976e-03, 5.7371e-08, 5.9192e-07, 2.1278e-01, 3.5560e-02, 2.8260e-03,\n",
      "         3.1123e-04, 1.8778e-02, 1.8225e-05, 1.4379e-01, 2.3919e-05, 4.1756e-04,\n",
      "         2.9026e-02, 2.5898e-08, 2.3844e-04, 2.5235e-02, 2.8466e-06, 9.3880e-05,\n",
      "         2.5982e-07, 2.1252e-06, 4.3902e-03, 1.0462e-04, 1.1261e-02, 1.6681e-03,\n",
      "         5.7463e-04, 2.7431e-02, 9.6257e-06, 1.0427e-01, 1.9842e-04, 2.2142e-07,\n",
      "         1.3821e-02, 2.4007e-07, 7.8962e-04, 1.7533e-02, 2.9918e-05, 1.7433e-03,\n",
      "         7.1971e-06, 4.7734e-04, 9.4831e-03, 1.5629e-02, 4.7861e-06, 1.6950e-07,\n",
      "         4.1663e-04, 3.9294e-03, 4.0985e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9993]], grad_fn=<TanhBackward0>))\n",
      "== StudentAgent (1) vs RandomStudentAgent (2) - First Player: 1 ==\n",
      "You win!\n",
      "your_agent statistics:\n",
      "Timeout count: 0\n",
      "Invalid count: 0\n",
      "opponent_agent statistics:\n",
      "Timeout count: 0\n",
      "Invalid count: 0\n",
      "Turn count: 57\n",
      "\n",
      "(tensor([[9.4793e-06, 3.2631e-04, 3.0510e-05, 7.2048e-03, 5.4976e-05, 1.2403e-02,\n",
      "         6.2163e-05, 3.5673e-02, 6.2828e-02, 5.7124e-05, 3.9309e-06, 5.4976e-03,\n",
      "         1.7686e-04, 2.3642e-03, 6.4218e-03, 9.1988e-04, 6.8387e-06, 3.5382e-02,\n",
      "         3.2539e-05, 9.5501e-03, 3.5474e-05, 5.0363e-06, 1.6491e-03, 3.9291e-03,\n",
      "         5.5464e-04, 4.8744e-04, 3.0758e-02, 1.2322e-05, 2.8126e-04, 8.7949e-05,\n",
      "         7.6690e-05, 5.6819e-02, 1.8095e-04, 1.2417e-03, 2.1750e-02, 6.2042e-02,\n",
      "         4.2854e-03, 1.4375e-05, 2.0925e-05, 8.4585e-02, 5.8950e-02, 7.7374e-03,\n",
      "         1.6837e-03, 2.1506e-02, 1.0092e-04, 7.8711e-02, 3.1605e-04, 1.5606e-03,\n",
      "         5.4704e-02, 2.3885e-06, 4.3532e-04, 3.5001e-02, 1.0134e-04, 1.0264e-03,\n",
      "         2.7607e-05, 4.7374e-05, 1.3499e-02, 1.8256e-03, 2.3566e-02, 4.7220e-03,\n",
      "         1.7754e-03, 5.3280e-02, 1.4972e-04, 5.1974e-02, 8.0774e-04, 6.0268e-06,\n",
      "         1.5922e-02, 1.6171e-05, 1.7093e-03, 3.0057e-02, 7.0029e-04, 3.2271e-03,\n",
      "         2.3708e-04, 2.2771e-03, 1.4681e-02, 3.3146e-02, 5.4460e-05, 8.3950e-06,\n",
      "         3.7514e-03, 8.5712e-03, 2.4303e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.7447]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[5.3195e-06, 1.7136e-04, 1.6537e-05, 9.3870e-03, 4.6059e-05, 1.0662e-02,\n",
      "         7.3365e-05, 2.8478e-02, 8.7753e-02, 4.4465e-05, 3.0016e-06, 5.7200e-03,\n",
      "         1.0722e-04, 1.8909e-03, 7.3279e-03, 5.0595e-04, 4.4188e-06, 4.9384e-02,\n",
      "         1.8296e-05, 1.1684e-02, 2.6605e-05, 2.8867e-06, 1.1523e-03, 3.5175e-03,\n",
      "         6.0081e-04, 5.9117e-04, 3.1421e-02, 1.3178e-05, 1.9471e-04, 7.2324e-05,\n",
      "         4.1014e-05, 4.0656e-02, 1.2298e-04, 1.0768e-03, 2.0598e-02, 6.2409e-02,\n",
      "         5.1235e-03, 7.3734e-06, 1.3706e-05, 9.7037e-02, 4.9172e-02, 5.6053e-03,\n",
      "         1.0092e-03, 2.9641e-02, 1.4961e-04, 1.0059e-01, 3.3384e-04, 1.6546e-03,\n",
      "         3.2616e-02, 1.6263e-06, 5.4298e-04, 3.9439e-02, 8.3949e-05, 8.6323e-04,\n",
      "         1.9298e-05, 3.9540e-05, 1.3011e-02, 1.1026e-03, 2.8085e-02, 3.2455e-03,\n",
      "         2.0671e-03, 4.7825e-02, 1.1641e-04, 3.5165e-02, 8.6874e-04, 6.2584e-06,\n",
      "         1.2398e-02, 1.4206e-05, 1.6076e-03, 2.2872e-02, 4.2198e-04, 4.5505e-03,\n",
      "         1.6975e-04, 2.0185e-03, 1.8853e-02, 3.0288e-02, 4.2071e-05, 5.5411e-06,\n",
      "         3.0364e-03, 6.4515e-03, 2.6052e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.5564]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[5.8439e-06, 1.4586e-04, 1.5791e-05, 7.2748e-03, 6.3248e-05, 1.6654e-02,\n",
      "         8.3672e-05, 2.3193e-02, 1.1393e-01, 3.3371e-05, 3.0594e-06, 4.8696e-03,\n",
      "         1.0105e-04, 2.5847e-03, 7.2274e-03, 3.8388e-04, 5.5059e-06, 5.5723e-02,\n",
      "         1.6524e-05, 1.4062e-02, 2.0831e-05, 2.4225e-06, 1.3963e-03, 3.9627e-03,\n",
      "         5.1966e-04, 4.5676e-04, 2.6348e-02, 1.1889e-05, 1.7345e-04, 5.7117e-05,\n",
      "         3.8083e-05, 3.9453e-02, 8.8800e-05, 1.2127e-03, 2.2476e-02, 5.1070e-02,\n",
      "         4.5339e-03, 5.0937e-06, 1.3260e-05, 1.0682e-01, 6.0662e-02, 5.3200e-03,\n",
      "         9.3327e-04, 3.3207e-02, 1.2810e-04, 9.4635e-02, 2.3106e-04, 2.0643e-03,\n",
      "         2.8347e-02, 1.7525e-06, 5.4040e-04, 2.7582e-02, 5.5049e-05, 6.0562e-04,\n",
      "         1.1641e-05, 4.1111e-05, 1.1832e-02, 8.6734e-04, 2.0008e-02, 3.6510e-03,\n",
      "         2.8591e-03, 3.1480e-02, 9.4194e-05, 4.5976e-02, 1.0091e-03, 8.1796e-06,\n",
      "         1.4352e-02, 9.2826e-06, 2.0359e-03, 2.7032e-02, 3.8279e-04, 3.9227e-03,\n",
      "         1.1231e-04, 1.7847e-03, 2.0388e-02, 2.4961e-02, 4.6362e-05, 7.9254e-06,\n",
      "         3.4665e-03, 5.4742e-03, 1.8836e-02]], grad_fn=<SoftmaxBackward0>), tensor([[0.0527]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[3.7233e-06, 1.2182e-04, 1.1368e-05, 7.0678e-03, 3.2384e-05, 1.1413e-02,\n",
      "         4.2517e-05, 2.9600e-02, 9.4636e-02, 2.5250e-05, 1.6786e-06, 5.2719e-03,\n",
      "         8.9919e-05, 1.8937e-03, 7.0819e-03, 3.8896e-04, 2.6423e-06, 5.1852e-02,\n",
      "         1.2135e-05, 1.2195e-02, 1.5106e-05, 1.4454e-06, 1.0100e-03, 3.4658e-03,\n",
      "         4.3549e-04, 3.5865e-04, 2.7489e-02, 7.4581e-06, 1.4989e-04, 4.6714e-05,\n",
      "         3.2294e-05, 4.2148e-02, 9.5061e-05, 8.4649e-04, 2.1488e-02, 5.3791e-02,\n",
      "         3.9227e-03, 4.0361e-06, 9.1577e-06, 1.1336e-01, 5.7838e-02, 5.8153e-03,\n",
      "         9.6582e-04, 2.9277e-02, 8.9977e-05, 9.0932e-02, 1.9560e-04, 1.3615e-03,\n",
      "         3.4685e-02, 8.7589e-07, 4.5614e-04, 3.6975e-02, 5.0223e-05, 7.3076e-04,\n",
      "         9.6131e-06, 2.6270e-05, 1.1529e-02, 8.9406e-04, 2.0709e-02, 3.2229e-03,\n",
      "         1.8223e-03, 4.2900e-02, 8.4579e-05, 4.4321e-02, 7.2264e-04, 4.1046e-06,\n",
      "         1.5068e-02, 6.8373e-06, 1.2913e-03, 2.5804e-02, 3.3221e-04, 3.6314e-03,\n",
      "         1.0358e-04, 1.4739e-03, 1.8274e-02, 3.0311e-02, 2.9638e-05, 3.2232e-06,\n",
      "         2.8457e-03, 6.7537e-03, 1.8031e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.1896]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[9.1987e-07, 5.0804e-05, 3.9412e-06, 6.9931e-03, 1.4628e-05, 9.0304e-03,\n",
      "         2.0075e-05, 2.5127e-02, 1.1060e-01, 1.0529e-05, 4.2762e-07, 3.6642e-03,\n",
      "         2.8291e-05, 1.1237e-03, 5.1179e-03, 1.7771e-04, 7.8982e-07, 5.8102e-02,\n",
      "         3.5134e-06, 1.0131e-02, 5.6118e-06, 4.6795e-07, 6.8130e-04, 2.3285e-03,\n",
      "         2.3694e-04, 1.8184e-04, 2.6421e-02, 2.4842e-06, 6.0677e-05, 1.5703e-05,\n",
      "         1.1027e-05, 3.7436e-02, 3.2199e-05, 5.1130e-04, 1.8796e-02, 6.7949e-02,\n",
      "         3.3280e-03, 1.1709e-06, 3.0681e-06, 1.1694e-01, 6.6093e-02, 3.6887e-03,\n",
      "         4.5450e-04, 3.0899e-02, 4.1213e-05, 1.2021e-01, 9.4787e-05, 9.3037e-04,\n",
      "         2.9624e-02, 2.2793e-07, 2.1494e-04, 2.6056e-02, 1.8790e-05, 3.5859e-04,\n",
      "         3.3411e-06, 1.1451e-05, 9.5182e-03, 5.0579e-04, 1.8727e-02, 2.0175e-03,\n",
      "         1.2210e-03, 4.7658e-02, 2.7434e-05, 3.3236e-02, 3.8738e-04, 1.2274e-06,\n",
      "         1.1921e-02, 2.2682e-06, 8.1543e-04, 1.9905e-02, 1.7075e-04, 2.3528e-03,\n",
      "         4.8533e-05, 1.1846e-03, 1.4605e-02, 2.7080e-02, 9.0970e-06, 1.2240e-06,\n",
      "         1.8079e-03, 4.0734e-03, 1.8890e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.6105]], grad_fn=<TanhBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[1.8441e-06, 6.0181e-05, 7.0787e-06, 4.9053e-03, 2.7891e-05, 1.0298e-02,\n",
      "         3.4567e-05, 2.1742e-02, 9.4709e-02, 1.1017e-05, 9.6297e-07, 4.8633e-03,\n",
      "         6.2557e-05, 2.3093e-03, 5.5804e-03, 3.7153e-04, 1.7107e-06, 4.3531e-02,\n",
      "         6.2283e-06, 1.3310e-02, 8.2327e-06, 7.3103e-07, 8.4438e-04, 3.2849e-03,\n",
      "         3.2369e-04, 2.8010e-04, 2.2606e-02, 5.3322e-06, 8.3343e-05, 2.7104e-05,\n",
      "         1.8725e-05, 3.9190e-02, 5.6793e-05, 8.4537e-04, 1.6353e-02, 4.0199e-02,\n",
      "         3.5844e-03, 1.5577e-06, 6.1715e-06, 1.4081e-01, 5.4549e-02, 5.1229e-03,\n",
      "         8.5187e-04, 2.4638e-02, 7.8763e-05, 1.0639e-01, 1.1252e-04, 1.0799e-03,\n",
      "         3.7970e-02, 5.1982e-07, 5.2052e-04, 4.0160e-02, 2.8515e-05, 4.6332e-04,\n",
      "         3.5256e-06, 1.5872e-05, 1.0225e-02, 6.1494e-04, 1.9897e-02, 3.3100e-03,\n",
      "         1.4999e-03, 4.4439e-02, 6.1772e-05, 6.1468e-02, 6.3683e-04, 2.4568e-06,\n",
      "         1.6056e-02, 3.4609e-06, 1.4652e-03, 2.3883e-02, 2.1987e-04, 3.3197e-03,\n",
      "         6.3808e-05, 1.1235e-03, 1.8379e-02, 2.9796e-02, 2.1611e-05, 1.7936e-06,\n",
      "         2.2233e-03, 6.5958e-03, 1.2345e-02]], grad_fn=<SoftmaxBackward0>), tensor([[0.9025]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[3.7149e-07, 3.1483e-05, 1.5408e-06, 7.5927e-03, 5.4229e-06, 8.5754e-03,\n",
      "         7.6739e-06, 2.7960e-02, 9.7954e-02, 6.7854e-06, 1.2859e-07, 3.2390e-03,\n",
      "         1.2838e-05, 5.2812e-04, 4.6775e-03, 9.6457e-05, 2.7282e-07, 5.8896e-02,\n",
      "         1.4328e-06, 7.8833e-03, 2.4907e-06, 1.5973e-07, 4.5530e-04, 1.4780e-03,\n",
      "         1.3728e-04, 1.1549e-04, 2.6615e-02, 9.0579e-07, 3.5524e-05, 6.9770e-06,\n",
      "         5.7675e-06, 4.4716e-02, 1.6931e-05, 2.5020e-04, 1.6992e-02, 8.5193e-02,\n",
      "         2.9006e-03, 5.9698e-07, 9.2867e-07, 1.0912e-01, 7.1828e-02, 2.9306e-03,\n",
      "         3.1955e-04, 2.9630e-02, 1.7425e-05, 1.2678e-01, 6.0027e-05, 7.8547e-04,\n",
      "         3.2379e-02, 7.2061e-08, 7.8573e-05, 2.2551e-02, 1.0192e-05, 2.4068e-04,\n",
      "         2.1317e-06, 4.6253e-06, 9.4436e-03, 3.8511e-04, 2.0906e-02, 1.0631e-03,\n",
      "         7.5028e-04, 5.0049e-02, 1.2205e-05, 2.3149e-02, 2.5236e-04, 3.9707e-07,\n",
      "         8.0024e-03, 1.2301e-06, 5.0154e-04, 1.7510e-02, 1.0443e-04, 1.9423e-03,\n",
      "         3.0689e-05, 8.1170e-04, 1.2324e-02, 2.8974e-02, 3.6450e-06, 4.3288e-07,\n",
      "         1.4722e-03, 3.2209e-03, 2.5964e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9748]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[1.4775e-06, 4.4092e-05, 5.3229e-06, 4.0590e-03, 2.6698e-05, 9.4776e-03,\n",
      "         3.0881e-05, 2.0827e-02, 1.0251e-01, 8.1764e-06, 7.2554e-07, 4.1771e-03,\n",
      "         5.5945e-05, 2.4494e-03, 5.5734e-03, 3.4499e-04, 1.3094e-06, 4.4655e-02,\n",
      "         4.8012e-06, 1.3983e-02, 6.6362e-06, 5.1077e-07, 6.8319e-04, 3.2243e-03,\n",
      "         2.7119e-04, 2.2243e-04, 2.1584e-02, 4.5800e-06, 5.9240e-05, 2.1925e-05,\n",
      "         1.3302e-05, 3.3662e-02, 4.7400e-05, 8.2421e-04, 1.5700e-02, 3.6676e-02,\n",
      "         3.2669e-03, 1.0873e-06, 5.1434e-06, 1.4549e-01, 5.4436e-02, 4.3270e-03,\n",
      "         7.3398e-04, 2.5178e-02, 6.3409e-05, 1.2307e-01, 8.2466e-05, 9.5576e-04,\n",
      "         3.7424e-02, 3.8768e-07, 5.2499e-04, 3.7237e-02, 2.1754e-05, 4.2154e-04,\n",
      "         2.3723e-06, 1.2956e-05, 9.8919e-03, 5.2626e-04, 1.7705e-02, 3.3091e-03,\n",
      "         1.4353e-03, 4.5572e-02, 5.2867e-05, 5.9762e-02, 5.5469e-04, 1.8554e-06,\n",
      "         1.6424e-02, 2.5301e-06, 1.3417e-03, 2.1753e-02, 1.7173e-04, 3.3395e-03,\n",
      "         4.8022e-05, 1.0975e-03, 1.6406e-02, 2.7296e-02, 1.8158e-05, 1.3425e-06,\n",
      "         1.9787e-03, 6.3517e-03, 1.0462e-02]], grad_fn=<SoftmaxBackward0>), tensor([[0.9515]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[3.1726e-07, 3.0613e-05, 1.2843e-06, 7.4227e-03, 4.6654e-06, 9.3579e-03,\n",
      "         6.0821e-06, 2.8143e-02, 9.2857e-02, 5.9792e-06, 1.0546e-07, 3.4171e-03,\n",
      "         1.0230e-05, 4.5227e-04, 4.6589e-03, 8.4008e-05, 2.4777e-07, 5.7970e-02,\n",
      "         1.2319e-06, 7.7846e-03, 2.1272e-06, 1.2449e-07, 4.5393e-04, 1.3540e-03,\n",
      "         1.3211e-04, 1.0842e-04, 2.6235e-02, 7.5905e-07, 3.3887e-05, 5.9071e-06,\n",
      "         5.0315e-06, 4.6593e-02, 1.5238e-05, 2.3385e-04, 1.7457e-02, 8.7055e-02,\n",
      "         2.7559e-03, 4.7932e-07, 6.9399e-07, 1.0378e-01, 8.1231e-02, 3.1565e-03,\n",
      "         3.0258e-04, 3.1567e-02, 1.5626e-05, 1.2655e-01, 5.5057e-05, 7.4398e-04,\n",
      "         3.1006e-02, 5.6844e-08, 6.4651e-05, 2.2378e-02, 8.2487e-06, 2.1533e-04,\n",
      "         2.0240e-06, 3.5185e-06, 9.3962e-03, 3.3033e-04, 1.9163e-02, 9.6802e-04,\n",
      "         7.3046e-04, 4.6747e-02, 9.9227e-06, 2.3639e-02, 2.3459e-04, 3.3202e-07,\n",
      "         7.7569e-03, 9.6257e-07, 4.6382e-04, 1.9522e-02, 1.0045e-04, 1.8662e-03,\n",
      "         2.6407e-05, 7.3738e-04, 1.2448e-02, 2.9060e-02, 2.9983e-06, 3.8933e-07,\n",
      "         1.3686e-03, 2.8208e-03, 2.6875e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9856]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[1.1262e-06, 3.6012e-05, 3.9441e-06, 3.4660e-03, 2.1549e-05, 8.3114e-03,\n",
      "         2.4551e-05, 1.9451e-02, 1.0456e-01, 5.9279e-06, 5.8531e-07, 4.1475e-03,\n",
      "         5.2673e-05, 2.2428e-03, 4.7774e-03, 3.1820e-04, 9.2639e-07, 3.8952e-02,\n",
      "         3.7646e-06, 1.3749e-02, 5.2620e-06, 3.2202e-07, 5.8986e-04, 3.0699e-03,\n",
      "         2.3126e-04, 1.9841e-04, 1.9858e-02, 3.4513e-06, 5.2593e-05, 1.7290e-05,\n",
      "         1.0000e-05, 3.3623e-02, 3.9758e-05, 7.5689e-04, 1.4310e-02, 3.1348e-02,\n",
      "         2.6130e-03, 8.0500e-07, 3.7798e-06, 1.6356e-01, 4.8418e-02, 4.2816e-03,\n",
      "         6.8075e-04, 2.2973e-02, 5.2429e-05, 1.3393e-01, 7.1455e-05, 8.0185e-04,\n",
      "         3.5864e-02, 2.8248e-07, 5.0815e-04, 3.5188e-02, 1.9018e-05, 3.6571e-04,\n",
      "         1.7467e-06, 1.0062e-05, 9.0548e-03, 4.5022e-04, 1.5831e-02, 3.2458e-03,\n",
      "         1.2753e-03, 4.5680e-02, 4.6819e-05, 6.4098e-02, 5.0688e-04, 1.3749e-06,\n",
      "         1.6059e-02, 1.8592e-06, 1.2623e-03, 2.4745e-02, 1.4460e-04, 3.1270e-03,\n",
      "         4.0215e-05, 9.6612e-04, 1.5874e-02, 2.7049e-02, 1.5674e-05, 1.0850e-06,\n",
      "         1.6759e-03, 6.2931e-03, 8.9702e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9756]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[2.8620e-07, 3.0397e-05, 1.2377e-06, 7.2622e-03, 4.4859e-06, 8.6909e-03,\n",
      "         5.6606e-06, 2.8472e-02, 9.1597e-02, 5.5444e-06, 1.0222e-07, 3.3174e-03,\n",
      "         1.0235e-05, 4.5889e-04, 4.4505e-03, 8.4732e-05, 2.2402e-07, 5.7340e-02,\n",
      "         1.1843e-06, 7.4544e-03, 2.0705e-06, 1.1756e-07, 4.3922e-04, 1.3699e-03,\n",
      "         1.2323e-04, 1.0450e-04, 2.7249e-02, 7.1798e-07, 3.2737e-05, 5.9611e-06,\n",
      "         4.7970e-06, 4.5633e-02, 1.5322e-05, 2.2937e-04, 1.7414e-02, 8.7959e-02,\n",
      "         2.7447e-03, 4.6161e-07, 7.0939e-07, 1.0825e-01, 7.9888e-02, 3.1683e-03,\n",
      "         3.2104e-04, 3.0521e-02, 1.4928e-05, 1.2500e-01, 5.4480e-05, 6.6483e-04,\n",
      "         3.0810e-02, 5.0731e-08, 6.2329e-05, 2.3834e-02, 7.9468e-06, 2.1526e-04,\n",
      "         1.8618e-06, 3.4704e-06, 9.3295e-03, 3.3307e-04, 1.8748e-02, 1.0004e-03,\n",
      "         7.0332e-04, 4.8326e-02, 1.0332e-05, 2.3633e-02, 2.2398e-04, 3.0879e-07,\n",
      "         7.8534e-03, 8.6261e-07, 4.5451e-04, 1.8613e-02, 9.8334e-05, 1.7560e-03,\n",
      "         2.6460e-05, 7.1829e-04, 1.2321e-02, 2.9333e-02, 2.8894e-06, 3.5152e-07,\n",
      "         1.3356e-03, 2.8840e-03, 2.6954e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9834]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[1.1005e-06, 3.4320e-05, 3.7240e-06, 3.1367e-03, 2.1473e-05, 8.1622e-03,\n",
      "         2.3324e-05, 1.7122e-02, 1.1316e-01, 5.2652e-06, 6.1428e-07, 4.1950e-03,\n",
      "         5.1815e-05, 2.1993e-03, 4.5746e-03, 2.9276e-04, 9.0841e-07, 3.7241e-02,\n",
      "         3.4045e-06, 1.4238e-02, 4.7314e-06, 2.7850e-07, 5.8535e-04, 3.1367e-03,\n",
      "         2.3799e-04, 1.9398e-04, 1.8464e-02, 3.2571e-06, 5.0831e-05, 1.5665e-05,\n",
      "         9.8221e-06, 3.2356e-02, 3.7055e-05, 7.2741e-04, 1.4157e-02, 2.6811e-02,\n",
      "         2.3733e-03, 7.2356e-07, 3.5444e-06, 1.7374e-01, 4.6950e-02, 4.6019e-03,\n",
      "         6.9670e-04, 2.3210e-02, 5.3164e-05, 1.2873e-01, 6.5286e-05, 7.5304e-04,\n",
      "         3.4531e-02, 2.7075e-07, 5.1567e-04, 3.4009e-02, 1.8112e-05, 3.7737e-04,\n",
      "         1.6484e-06, 9.5293e-06, 8.4725e-03, 4.1064e-04, 1.4462e-02, 2.9445e-03,\n",
      "         1.2657e-03, 4.5572e-02, 4.3053e-05, 6.8145e-02, 5.0942e-04, 1.3988e-06,\n",
      "         1.6598e-02, 1.6441e-06, 1.2684e-03, 2.5175e-02, 1.3747e-04, 3.0563e-03,\n",
      "         3.7240e-05, 9.2793e-04, 1.5647e-02, 2.7321e-02, 1.5380e-05, 1.1182e-06,\n",
      "         1.4882e-03, 6.3752e-03, 8.2241e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9843]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[3.0388e-07, 3.3224e-05, 1.3568e-06, 7.1524e-03, 4.7346e-06, 8.7884e-03,\n",
      "         6.1312e-06, 2.9114e-02, 8.9166e-02, 5.9139e-06, 1.0986e-07, 3.3926e-03,\n",
      "         1.1338e-05, 4.8341e-04, 4.3724e-03, 9.3633e-05, 2.3904e-07, 5.5852e-02,\n",
      "         1.3155e-06, 7.1302e-03, 2.1472e-06, 1.3143e-07, 4.5194e-04, 1.3440e-03,\n",
      "         1.2895e-04, 1.0923e-04, 2.7997e-02, 7.8018e-07, 3.3733e-05, 6.5512e-06,\n",
      "         5.3050e-06, 4.7779e-02, 1.6064e-05, 2.3115e-04, 1.7603e-02, 8.9575e-02,\n",
      "         2.8016e-03, 5.0374e-07, 7.7450e-07, 1.0737e-01, 7.9204e-02, 3.2832e-03,\n",
      "         3.3467e-04, 2.8962e-02, 1.5890e-05, 1.2077e-01, 5.6771e-05, 6.6986e-04,\n",
      "         3.3302e-02, 5.6436e-08, 6.3659e-05, 2.4808e-02, 8.3607e-06, 2.1884e-04,\n",
      "         1.9423e-06, 3.6789e-06, 9.4254e-03, 3.5057e-04, 2.0077e-02, 1.0814e-03,\n",
      "         7.1758e-04, 4.9200e-02, 1.1644e-05, 2.4618e-02, 2.3529e-04, 3.2308e-07,\n",
      "         8.2617e-03, 9.5689e-07, 4.9131e-04, 1.7979e-02, 1.0164e-04, 1.7650e-03,\n",
      "         2.8958e-05, 7.1878e-04, 1.2282e-02, 2.8647e-02, 3.1412e-06, 3.5715e-07,\n",
      "         1.4309e-03, 2.9980e-03, 2.6798e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9801]], grad_fn=<TanhBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[1.1175e-06, 3.6544e-05, 3.7083e-06, 3.1671e-03, 2.0980e-05, 9.3233e-03,\n",
      "         2.4268e-05, 1.7304e-02, 1.1187e-01, 5.2013e-06, 6.1797e-07, 4.1337e-03,\n",
      "         5.0879e-05, 2.1830e-03, 4.7398e-03, 2.9945e-04, 9.1990e-07, 3.8223e-02,\n",
      "         3.3223e-06, 1.4035e-02, 4.8362e-06, 2.8034e-07, 6.1713e-04, 3.0579e-03,\n",
      "         2.3763e-04, 1.9297e-04, 1.7584e-02, 3.1568e-06, 5.3493e-05, 1.4844e-05,\n",
      "         1.0393e-05, 3.4082e-02, 3.7007e-05, 7.4952e-04, 1.4944e-02, 2.7328e-02,\n",
      "         2.4304e-03, 7.8999e-07, 3.5064e-06, 1.6917e-01, 5.0022e-02, 4.7598e-03,\n",
      "         7.0757e-04, 2.2769e-02, 5.0471e-05, 1.2192e-01, 6.7214e-05, 7.8983e-04,\n",
      "         3.4821e-02, 2.8073e-07, 4.8265e-04, 3.5095e-02, 1.8046e-05, 3.9798e-04,\n",
      "         1.6986e-06, 9.4195e-06, 8.5169e-03, 4.2816e-04, 1.5731e-02, 2.8862e-03,\n",
      "         1.3028e-03, 4.2763e-02, 4.2428e-05, 7.1683e-02, 5.2316e-04, 1.4762e-06,\n",
      "         1.6900e-02, 1.6807e-06, 1.2776e-03, 2.5805e-02, 1.3871e-04, 2.9715e-03,\n",
      "         3.6999e-05, 8.9844e-04, 1.5683e-02, 2.8010e-02, 1.6460e-05, 1.2215e-06,\n",
      "         1.6007e-03, 6.1179e-03, 8.8059e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9775]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[2.2512e-07, 2.9077e-05, 1.0603e-06, 6.6057e-03, 3.8821e-06, 7.9958e-03,\n",
      "         4.9079e-06, 2.9563e-02, 8.8406e-02, 4.8270e-06, 8.5781e-08, 3.1391e-03,\n",
      "         9.6410e-06, 4.2944e-04, 3.9294e-03, 8.2359e-05, 1.7672e-07, 5.6570e-02,\n",
      "         1.0787e-06, 6.6612e-03, 1.6950e-06, 9.9232e-08, 4.2065e-04, 1.2806e-03,\n",
      "         1.1162e-04, 1.0453e-04, 2.8635e-02, 6.0838e-07, 3.0167e-05, 5.6808e-06,\n",
      "         4.1395e-06, 4.9278e-02, 1.4523e-05, 2.2238e-04, 1.7429e-02, 8.9668e-02,\n",
      "         2.7520e-03, 4.1843e-07, 6.2848e-07, 1.0759e-01, 7.9216e-02, 2.9911e-03,\n",
      "         2.9620e-04, 3.0122e-02, 1.2782e-05, 1.2590e-01, 5.0007e-05, 5.8473e-04,\n",
      "         3.1125e-02, 4.3261e-08, 5.5896e-05, 2.3855e-02, 7.2546e-06, 1.8915e-04,\n",
      "         1.5963e-06, 2.9183e-06, 9.1161e-03, 3.2345e-04, 1.9088e-02, 9.8784e-04,\n",
      "         6.6035e-04, 5.0098e-02, 9.5990e-06, 2.3266e-02, 2.0443e-04, 2.3907e-07,\n",
      "         7.9286e-03, 7.3470e-07, 4.4574e-04, 1.8786e-02, 9.0936e-05, 1.6470e-03,\n",
      "         2.4960e-05, 6.6160e-04, 1.1591e-02, 2.8889e-02, 2.4149e-06, 2.8949e-07,\n",
      "         1.3059e-03, 2.7470e-03, 2.6733e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9852]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[7.9791e-07, 2.7287e-05, 2.6266e-06, 2.8789e-03, 1.6388e-05, 7.9853e-03,\n",
      "         1.8013e-05, 1.6652e-02, 1.1726e-01, 3.9550e-06, 3.8205e-07, 3.8899e-03,\n",
      "         3.9835e-05, 2.0376e-03, 4.3188e-03, 2.5802e-04, 6.0094e-07, 3.6363e-02,\n",
      "         2.4504e-06, 1.3131e-02, 3.5806e-06, 1.8106e-07, 5.0250e-04, 2.7315e-03,\n",
      "         1.8308e-04, 1.4607e-04, 1.6662e-02, 2.2480e-06, 3.9908e-05, 1.2102e-05,\n",
      "         6.9108e-06, 3.1489e-02, 3.0262e-05, 6.5077e-04, 1.2703e-02, 2.6876e-02,\n",
      "         2.1689e-03, 5.0787e-07, 2.4621e-06, 1.7774e-01, 4.6536e-02, 4.1122e-03,\n",
      "         6.0725e-04, 2.2190e-02, 4.0946e-05, 1.2865e-01, 5.4612e-05, 7.0030e-04,\n",
      "         3.6986e-02, 1.6937e-07, 4.3358e-04, 3.5317e-02, 1.3406e-05, 3.3093e-04,\n",
      "         1.1170e-06, 6.8990e-06, 7.9859e-03, 3.5471e-04, 1.4698e-02, 2.6103e-03,\n",
      "         1.1239e-03, 4.3517e-02, 3.6240e-05, 7.4492e-02, 4.2669e-04, 9.2137e-07,\n",
      "         1.6075e-02, 1.1992e-06, 1.0770e-03, 2.5183e-02, 1.0898e-04, 2.6510e-03,\n",
      "         2.9201e-05, 7.7254e-04, 1.3987e-02, 2.6597e-02, 1.1711e-05, 7.3768e-07,\n",
      "         1.3944e-03, 5.9659e-03, 8.0851e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9826]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[1.2047e-07, 2.0730e-05, 6.2683e-07, 6.2926e-03, 2.1499e-06, 6.7488e-03,\n",
      "         2.8155e-06, 3.1047e-02, 7.8593e-02, 2.9582e-06, 4.3417e-08, 2.7041e-03,\n",
      "         6.2462e-06, 3.1678e-04, 3.3419e-03, 6.1649e-05, 9.0266e-08, 5.3130e-02,\n",
      "         6.3404e-07, 6.0752e-03, 1.0730e-06, 5.8197e-08, 3.2752e-04, 1.1489e-03,\n",
      "         8.0955e-05, 8.5198e-05, 2.8827e-02, 3.4187e-07, 2.2684e-05, 3.8588e-06,\n",
      "         2.6025e-06, 5.2589e-02, 9.8652e-06, 1.6156e-04, 1.6765e-02, 9.2044e-02,\n",
      "         2.4300e-03, 2.6690e-07, 3.7203e-07, 1.0570e-01, 8.3770e-02, 2.5167e-03,\n",
      "         2.3189e-04, 2.8216e-02, 8.3522e-06, 1.3678e-01, 3.8130e-05, 4.2786e-04,\n",
      "         2.9559e-02, 2.1297e-08, 3.6956e-05, 2.4785e-02, 5.6230e-06, 1.5918e-04,\n",
      "         1.1356e-06, 1.8552e-06, 8.6673e-03, 2.7403e-04, 1.7564e-02, 8.0989e-04,\n",
      "         5.3239e-04, 5.7597e-02, 6.9308e-06, 1.9590e-02, 1.5529e-04, 1.1495e-07,\n",
      "         6.8704e-03, 4.2999e-07, 3.3765e-04, 1.6349e-02, 7.0373e-05, 1.4254e-03,\n",
      "         1.7332e-05, 5.5928e-04, 1.0167e-02, 3.1472e-02, 1.4512e-06, 1.5675e-07,\n",
      "         1.0437e-03, 2.4647e-03, 2.8944e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9939]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[6.2475e-07, 2.2594e-05, 2.0502e-06, 2.4254e-03, 1.4889e-05, 7.7688e-03,\n",
      "         1.5613e-05, 1.2849e-02, 1.4569e-01, 3.0245e-06, 2.9556e-07, 3.7563e-03,\n",
      "         3.1866e-05, 1.8382e-03, 3.5261e-03, 2.1907e-04, 5.0430e-07, 3.2977e-02,\n",
      "         1.8638e-06, 1.3637e-02, 2.3906e-06, 1.2904e-07, 4.7363e-04, 2.3573e-03,\n",
      "         1.8532e-04, 1.3577e-04, 1.6927e-02, 1.6546e-06, 3.0425e-05, 8.7579e-06,\n",
      "         5.3343e-06, 3.0072e-02, 2.1751e-05, 6.1083e-04, 1.1699e-02, 2.4243e-02,\n",
      "         2.0582e-03, 3.3055e-07, 1.8711e-06, 1.8176e-01, 4.2263e-02, 4.0094e-03,\n",
      "         5.2277e-04, 2.3120e-02, 3.9821e-05, 1.2202e-01, 4.5582e-05, 6.6867e-04,\n",
      "         3.5317e-02, 1.3597e-07, 4.0499e-04, 3.1193e-02, 9.7783e-06, 2.4219e-04,\n",
      "         8.4764e-07, 5.5795e-06, 7.1311e-03, 2.6768e-04, 1.5443e-02, 2.2561e-03,\n",
      "         9.7449e-04, 3.2379e-02, 2.5789e-05, 9.0956e-02, 3.7852e-04, 8.0777e-07,\n",
      "         1.5652e-02, 9.1807e-07, 1.0450e-03, 2.4495e-02, 8.3224e-05, 2.7453e-03,\n",
      "         2.4509e-05, 7.2666e-04, 1.2849e-02, 2.3609e-02, 1.0121e-05, 5.8278e-07,\n",
      "         1.1004e-03, 5.6330e-03, 6.9729e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9919]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[8.2190e-08, 1.6228e-05, 4.2679e-07, 6.2756e-03, 1.4997e-06, 6.7373e-03,\n",
      "         1.9359e-06, 3.1464e-02, 7.9962e-02, 2.2446e-06, 2.6641e-08, 2.6231e-03,\n",
      "         4.5358e-06, 2.5323e-04, 3.1023e-03, 4.7739e-05, 5.9732e-08, 5.2122e-02,\n",
      "         4.3401e-07, 6.1224e-03, 7.6715e-07, 3.5986e-08, 2.8344e-04, 1.0319e-03,\n",
      "         6.8742e-05, 6.6371e-05, 2.7977e-02, 2.2544e-07, 1.8460e-05, 2.7811e-06,\n",
      "         1.8562e-06, 5.1199e-02, 7.4599e-06, 1.2770e-04, 1.6512e-02, 9.3124e-02,\n",
      "         2.2291e-03, 1.8131e-07, 2.3081e-07, 1.0417e-01, 8.4867e-02, 2.2817e-03,\n",
      "         1.9153e-04, 2.9704e-02, 6.0821e-06, 1.3992e-01, 2.9629e-05, 3.9620e-04,\n",
      "         2.8224e-02, 1.3139e-08, 2.8422e-05, 2.2111e-02, 4.3540e-06, 1.3876e-04,\n",
      "         8.5396e-07, 1.3393e-06, 8.4210e-03, 2.3263e-04, 1.7479e-02, 6.0571e-04,\n",
      "         4.4681e-04, 5.8545e-02, 4.7876e-06, 1.9556e-02, 1.3051e-04, 7.6878e-08,\n",
      "         6.3380e-03, 3.1922e-07, 2.7420e-04, 1.6521e-02, 5.6481e-05, 1.2989e-03,\n",
      "         1.2806e-05, 4.7607e-04, 9.7697e-03, 3.2029e-02, 1.0508e-06, 1.1008e-07,\n",
      "         9.5230e-04, 2.3385e-03, 3.1045e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9968]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[5.8093e-07, 2.1912e-05, 2.0094e-06, 2.4500e-03, 1.3236e-05, 7.1562e-03,\n",
      "         1.4227e-05, 1.4033e-02, 1.3613e-01, 3.0868e-06, 2.9637e-07, 3.8916e-03,\n",
      "         3.6329e-05, 1.8517e-03, 3.7603e-03, 2.2652e-04, 4.8519e-07, 3.4297e-02,\n",
      "         1.8723e-06, 1.2473e-02, 2.5859e-06, 1.2742e-07, 4.3130e-04, 2.3395e-03,\n",
      "         1.7014e-04, 1.3511e-04, 1.7850e-02, 1.6830e-06, 2.9281e-05, 9.2592e-06,\n",
      "         5.4990e-06, 2.9481e-02, 2.1510e-05, 6.1329e-04, 1.2292e-02, 2.5868e-02,\n",
      "         1.9674e-03, 3.3496e-07, 1.8592e-06, 1.8310e-01, 4.3894e-02, 4.0699e-03,\n",
      "         5.0343e-04, 2.1533e-02, 3.6193e-05, 1.2763e-01, 4.5851e-05, 6.2122e-04,\n",
      "         3.9239e-02, 1.2471e-07, 3.8555e-04, 3.1823e-02, 9.8521e-06, 2.4839e-04,\n",
      "         8.7967e-07, 5.2503e-06, 7.0988e-03, 2.8848e-04, 1.5556e-02, 2.3402e-03,\n",
      "         1.0174e-03, 3.5279e-02, 2.8808e-05, 8.1615e-02, 3.7173e-04, 7.4060e-07,\n",
      "         1.5287e-02, 9.4044e-07, 9.9648e-04, 2.3998e-02, 9.0443e-05, 2.5513e-03,\n",
      "         2.5063e-05, 7.3327e-04, 1.3255e-02, 2.4506e-02, 9.3799e-06, 5.4596e-07,\n",
      "         1.1125e-03, 5.9478e-03, 7.1688e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9897]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[8.7945e-08, 1.6120e-05, 4.3849e-07, 6.0308e-03, 1.6365e-06, 7.3382e-03,\n",
      "         2.0618e-06, 3.0872e-02, 8.6299e-02, 2.2929e-06, 2.7529e-08, 2.5814e-03,\n",
      "         4.4627e-06, 2.6242e-04, 3.2323e-03, 4.5447e-05, 6.4258e-08, 5.3432e-02,\n",
      "         4.4914e-07, 6.4863e-03, 7.4934e-07, 3.4254e-08, 3.0037e-04, 1.0242e-03,\n",
      "         7.2653e-05, 6.2147e-05, 2.6763e-02, 2.2244e-07, 1.8640e-05, 2.7042e-06,\n",
      "         1.8970e-06, 5.0235e-02, 7.6907e-06, 1.3417e-04, 1.6825e-02, 9.1984e-02,\n",
      "         2.2414e-03, 1.7641e-07, 2.2658e-07, 1.0457e-01, 8.6903e-02, 2.3473e-03,\n",
      "         1.8825e-04, 3.0416e-02, 6.1856e-06, 1.3727e-01, 2.8753e-05, 4.1119e-04,\n",
      "         2.7646e-02, 1.4026e-08, 2.9181e-05, 2.0295e-02, 4.1361e-06, 1.3751e-04,\n",
      "         8.2741e-07, 1.3558e-06, 8.3185e-03, 2.2731e-04, 1.6857e-02, 6.0136e-04,\n",
      "         4.7376e-04, 5.4403e-02, 4.4969e-06, 2.1139e-02, 1.3219e-04, 8.1416e-08,\n",
      "         6.4027e-03, 3.1469e-07, 2.6479e-04, 1.7891e-02, 5.6800e-05, 1.3041e-03,\n",
      "         1.2716e-05, 4.7513e-04, 1.0050e-02, 3.2006e-02, 1.0710e-06, 1.1764e-07,\n",
      "         9.8875e-04, 2.3590e-03, 2.9494e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9965]], grad_fn=<TanhBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[5.3025e-07, 2.1537e-05, 1.9442e-06, 2.6360e-03, 1.1903e-05, 5.9657e-03,\n",
      "         1.3212e-05, 1.6191e-02, 1.2154e-01, 3.1253e-06, 2.8106e-07, 4.0691e-03,\n",
      "         4.2553e-05, 1.9673e-03, 3.7752e-03, 2.3467e-04, 4.2643e-07, 3.4654e-02,\n",
      "         1.8994e-06, 1.1357e-02, 2.9078e-06, 1.2212e-07, 3.8606e-04, 2.4654e-03,\n",
      "         1.4707e-04, 1.2792e-04, 1.9018e-02, 1.7376e-06, 3.0264e-05, 9.9168e-06,\n",
      "         5.1021e-06, 2.9886e-02, 2.2643e-05, 6.2735e-04, 1.1012e-02, 2.7142e-02,\n",
      "         1.9119e-03, 3.4222e-07, 1.8714e-06, 1.9379e-01, 4.1168e-02, 3.8966e-03,\n",
      "         4.9675e-04, 2.0944e-02, 3.1652e-05, 1.3762e-01, 4.7151e-05, 5.7540e-04,\n",
      "         4.1050e-02, 1.1295e-07, 3.9154e-04, 3.2895e-02, 1.0333e-05, 2.4765e-04,\n",
      "         9.1917e-07, 5.0383e-06, 7.2026e-03, 3.1084e-04, 1.5152e-02, 2.5229e-03,\n",
      "         9.9453e-04, 4.1101e-02, 3.3125e-05, 6.9101e-02, 3.5519e-04, 6.2863e-07,\n",
      "         1.5031e-02, 1.0178e-06, 9.7981e-04, 2.3906e-02, 9.6615e-05, 2.5776e-03,\n",
      "         2.6415e-05, 7.6440e-04, 1.2388e-02, 2.4157e-02, 8.9408e-06, 4.8216e-07,\n",
      "         1.1369e-03, 6.4261e-03, 7.2607e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9886]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[5.9198e-08, 1.1901e-05, 3.0598e-07, 5.6070e-03, 1.3210e-06, 7.8564e-03,\n",
      "         1.6794e-06, 2.8071e-02, 9.9761e-02, 1.7144e-06, 1.8227e-08, 2.3090e-03,\n",
      "         3.1079e-06, 2.3289e-04, 2.9351e-03, 3.4177e-05, 4.6113e-08, 5.6179e-02,\n",
      "         3.1443e-07, 6.7161e-03, 4.8186e-07, 2.0434e-08, 2.6611e-04, 8.9347e-04,\n",
      "         6.1287e-05, 4.8737e-05, 2.5642e-02, 1.4627e-07, 1.3665e-05, 1.8588e-06,\n",
      "         1.3301e-06, 4.7055e-02, 6.0079e-06, 1.2040e-04, 1.5864e-02, 8.9694e-02,\n",
      "         2.1435e-03, 1.0610e-07, 1.3724e-07, 1.0648e-01, 8.6964e-02, 2.2566e-03,\n",
      "         1.4921e-04, 3.3034e-02, 5.0887e-06, 1.4098e-01, 2.0699e-05, 4.0219e-04,\n",
      "         2.6098e-02, 9.7814e-09, 2.4337e-05, 1.7231e-02, 2.7016e-06, 1.0330e-04,\n",
      "         5.5471e-07, 9.3340e-07, 7.7553e-03, 1.6636e-04, 1.6997e-02, 5.0749e-04,\n",
      "         4.4289e-04, 4.9935e-02, 2.8793e-06, 2.2104e-02, 1.1638e-04, 5.5201e-08,\n",
      "         6.1071e-03, 2.3269e-07, 2.3309e-04, 1.8279e-02, 4.5944e-05, 1.2267e-03,\n",
      "         9.2372e-06, 3.9736e-04, 1.0182e-02, 3.1449e-02, 7.5775e-07, 8.8954e-08,\n",
      "         8.5865e-04, 2.0535e-03, 2.5843e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9970]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[4.3627e-07, 1.9182e-05, 1.6930e-06, 2.6232e-03, 1.0179e-05, 5.1128e-03,\n",
      "         1.1821e-05, 1.6383e-02, 1.1616e-01, 2.7207e-06, 2.4516e-07, 4.1252e-03,\n",
      "         4.4085e-05, 1.9327e-03, 3.7077e-03, 2.3329e-04, 3.6138e-07, 3.6834e-02,\n",
      "         1.6668e-06, 1.0729e-02, 2.7939e-06, 1.0139e-07, 3.3849e-04, 2.5211e-03,\n",
      "         1.3102e-04, 1.1666e-04, 1.9800e-02, 1.6672e-06, 2.7630e-05, 8.9583e-06,\n",
      "         4.3473e-06, 2.9175e-02, 2.1918e-05, 5.9807e-04, 1.0135e-02, 2.7243e-02,\n",
      "         1.7933e-03, 2.9344e-07, 1.7148e-06, 2.0109e-01, 4.0528e-02, 3.7130e-03,\n",
      "         4.9186e-04, 2.0596e-02, 2.7287e-05, 1.4543e-01, 4.4641e-05, 5.0678e-04,\n",
      "         4.1249e-02, 9.1710e-08, 3.9545e-04, 3.2238e-02, 9.3074e-06, 2.3381e-04,\n",
      "         8.2252e-07, 4.3211e-06, 7.0713e-03, 2.9506e-04, 1.4727e-02, 2.5499e-03,\n",
      "         9.3546e-04, 4.4635e-02, 3.2144e-05, 6.0931e-02, 3.2669e-04, 5.0392e-07,\n",
      "         1.5299e-02, 9.2736e-07, 9.4673e-04, 2.3464e-02, 8.9329e-05, 2.5233e-03,\n",
      "         2.5555e-05, 7.4085e-04, 1.1429e-02, 2.2977e-02, 7.7807e-06, 4.0982e-07,\n",
      "         1.0467e-03, 6.3982e-03, 7.1394e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9903]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[5.1342e-08, 1.1157e-05, 2.7169e-07, 5.5181e-03, 1.2126e-06, 7.6650e-03,\n",
      "         1.5163e-06, 2.6916e-02, 1.0122e-01, 1.5571e-06, 1.5735e-08, 2.2164e-03,\n",
      "         2.6792e-06, 2.1941e-04, 2.8228e-03, 3.1577e-05, 4.2350e-08, 5.3701e-02,\n",
      "         2.7945e-07, 6.6562e-03, 4.3863e-07, 1.7975e-08, 2.5781e-04, 8.3432e-04,\n",
      "         5.8745e-05, 4.6253e-05, 2.5390e-02, 1.3009e-07, 1.2264e-05, 1.7463e-06,\n",
      "         1.2048e-06, 4.5039e-02, 5.2858e-06, 1.1203e-04, 1.5739e-02, 9.1830e-02,\n",
      "         2.0906e-03, 9.1801e-08, 1.1851e-07, 1.0847e-01, 8.7245e-02, 2.2471e-03,\n",
      "         1.4510e-04, 3.2387e-02, 4.8194e-06, 1.4232e-01, 1.8695e-05, 3.7794e-04,\n",
      "         2.6352e-02, 8.4252e-09, 2.2393e-05, 1.7310e-02, 2.3540e-06, 9.5433e-05,\n",
      "         5.0886e-07, 8.3414e-07, 7.7781e-03, 1.5431e-04, 1.6931e-02, 4.9719e-04,\n",
      "         4.1808e-04, 5.0533e-02, 2.5379e-06, 2.2490e-02, 1.0868e-04, 4.7978e-08,\n",
      "         5.9428e-03, 2.0690e-07, 2.2452e-04, 1.7828e-02, 4.3211e-05, 1.1307e-03,\n",
      "         8.5800e-06, 3.8581e-04, 1.0262e-02, 3.1207e-02, 6.7481e-07, 7.8561e-08,\n",
      "         7.9528e-04, 1.9471e-03, 2.5911e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9970]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[3.9712e-07, 1.6889e-05, 1.4766e-06, 2.4049e-03, 9.9737e-06, 5.0820e-03,\n",
      "         1.1452e-05, 1.4797e-02, 1.2382e-01, 2.4352e-06, 2.2315e-07, 3.9414e-03,\n",
      "         4.1226e-05, 1.9608e-03, 3.6187e-03, 2.1214e-04, 3.3293e-07, 3.6765e-02,\n",
      "         1.5098e-06, 1.1434e-02, 2.4437e-06, 8.7114e-08, 3.2596e-04, 2.4232e-03,\n",
      "         1.2362e-04, 1.0915e-04, 1.8954e-02, 1.4983e-06, 2.4584e-05, 8.1145e-06,\n",
      "         3.7386e-06, 2.7580e-02, 1.9963e-05, 5.7139e-04, 9.4934e-03, 2.5968e-02,\n",
      "         1.7439e-03, 2.4426e-07, 1.5239e-06, 2.0377e-01, 3.9552e-02, 3.5522e-03,\n",
      "         4.7519e-04, 2.1056e-02, 2.6471e-05, 1.4362e-01, 4.1815e-05, 5.0247e-04,\n",
      "         4.0950e-02, 8.0920e-08, 3.9460e-04, 3.1135e-02, 8.0607e-06, 2.1673e-04,\n",
      "         7.1813e-07, 4.0279e-06, 6.9760e-03, 2.6903e-04, 1.4395e-02, 2.3968e-03,\n",
      "         9.1717e-04, 4.3692e-02, 2.9378e-05, 6.5143e-02, 3.2267e-04, 4.4419e-07,\n",
      "         1.5577e-02, 8.3211e-07, 9.0388e-04, 2.2173e-02, 7.9125e-05, 2.4178e-03,\n",
      "         2.3432e-05, 7.1887e-04, 1.0871e-02, 2.2404e-02, 7.1060e-06, 3.6822e-07,\n",
      "         9.6668e-04, 6.2086e-03, 6.7214e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9930]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[6.3346e-08, 1.2390e-05, 3.2498e-07, 5.5835e-03, 1.4020e-06, 7.7101e-03,\n",
      "         1.7131e-06, 2.8493e-02, 9.8578e-02, 1.7233e-06, 1.9570e-08, 2.3413e-03,\n",
      "         3.1466e-06, 2.4593e-04, 3.0136e-03, 3.4482e-05, 5.0587e-08, 5.4968e-02,\n",
      "         3.3135e-07, 6.9934e-03, 5.3378e-07, 2.1799e-08, 2.7979e-04, 9.1038e-04,\n",
      "         6.5963e-05, 5.1245e-05, 2.5567e-02, 1.6034e-07, 1.4211e-05, 2.0408e-06,\n",
      "         1.4263e-06, 4.5574e-02, 6.0847e-06, 1.2071e-04, 1.6693e-02, 9.0008e-02,\n",
      "         2.1146e-03, 1.1265e-07, 1.5203e-07, 1.1017e-01, 8.6643e-02, 2.3842e-03,\n",
      "         1.5915e-04, 3.2385e-02, 5.3405e-06, 1.3928e-01, 2.0842e-05, 3.8509e-04,\n",
      "         2.5531e-02, 1.0337e-08, 2.5390e-05, 1.8272e-02, 2.8724e-06, 1.0924e-04,\n",
      "         6.0658e-07, 1.0193e-06, 8.0610e-03, 1.7382e-04, 1.5785e-02, 5.4883e-04,\n",
      "         4.4898e-04, 5.0942e-02, 3.0258e-06, 2.2194e-02, 1.1404e-04, 5.9769e-08,\n",
      "         6.0837e-03, 2.3400e-07, 2.3539e-04, 1.8667e-02, 4.7985e-05, 1.1605e-03,\n",
      "         9.4428e-06, 4.0676e-04, 1.0426e-02, 3.2069e-02, 7.9478e-07, 9.4846e-08,\n",
      "         8.4614e-04, 1.9925e-03, 2.5026e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9964]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[4.3359e-07, 1.7038e-05, 1.5178e-06, 2.2304e-03, 1.1032e-05, 5.6145e-03,\n",
      "         1.2446e-05, 1.4103e-02, 1.2991e-01, 2.4531e-06, 2.4952e-07, 3.8375e-03,\n",
      "         4.0720e-05, 2.0527e-03, 3.6495e-03, 1.9893e-04, 3.5220e-07, 3.7997e-02,\n",
      "         1.5730e-06, 1.2227e-02, 2.3838e-06, 9.0116e-08, 3.4751e-04, 2.4808e-03,\n",
      "         1.2855e-04, 1.1502e-04, 1.8175e-02, 1.5034e-06, 2.5915e-05, 8.1359e-06,\n",
      "         3.7655e-06, 2.8311e-02, 2.0030e-05, 5.7969e-04, 1.0145e-02, 2.5100e-02,\n",
      "         1.7792e-03, 2.4341e-07, 1.5928e-06, 1.9377e-01, 4.1146e-02, 3.5676e-03,\n",
      "         4.7340e-04, 2.1624e-02, 2.9718e-05, 1.3952e-01, 4.3176e-05, 5.4914e-04,\n",
      "         3.8655e-02, 8.8603e-08, 3.8224e-04, 3.1262e-02, 8.1581e-06, 2.2518e-04,\n",
      "         7.2146e-07, 4.3190e-06, 6.9344e-03, 2.6451e-04, 1.4358e-02, 2.4316e-03,\n",
      "         9.5342e-04, 4.1757e-02, 2.8783e-05, 7.2908e-02, 3.4048e-04, 4.9797e-07,\n",
      "         1.5420e-02, 8.3179e-07, 9.5743e-04, 2.2324e-02, 7.5490e-05, 2.4806e-03,\n",
      "         2.2734e-05, 7.1485e-04, 1.1566e-02, 2.2273e-02, 7.7278e-06, 4.2264e-07,\n",
      "         9.7661e-04, 5.9423e-03, 6.8697e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9940]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[5.8771e-08, 1.2755e-05, 3.1428e-07, 5.7728e-03, 1.2456e-06, 7.2692e-03,\n",
      "         1.5361e-06, 2.9610e-02, 9.0791e-02, 1.6990e-06, 1.8333e-08, 2.3675e-03,\n",
      "         3.1276e-06, 2.2841e-04, 2.9851e-03, 3.4667e-05, 4.6084e-08, 5.1970e-02,\n",
      "         3.2024e-07, 6.6869e-03, 5.3347e-07, 2.2304e-08, 2.6250e-04, 9.1096e-04,\n",
      "         6.1404e-05, 5.2787e-05, 2.6883e-02, 1.5434e-07, 1.4038e-05, 2.0251e-06,\n",
      "         1.4091e-06, 4.5439e-02, 5.6622e-06, 1.1134e-04, 1.6321e-02, 9.1746e-02,\n",
      "         2.0817e-03, 1.1947e-07, 1.4686e-07, 1.0968e-01, 8.5988e-02, 2.2716e-03,\n",
      "         1.6223e-04, 3.1526e-02, 4.8681e-06, 1.4127e-01, 2.1089e-05, 3.6661e-04,\n",
      "         2.6074e-02, 9.5615e-09, 2.3999e-05, 1.9326e-02, 3.0755e-06, 1.1132e-04,\n",
      "         6.5334e-07, 9.8347e-07, 7.9436e-03, 1.8486e-04, 1.6768e-02, 5.2359e-04,\n",
      "         4.1979e-04, 5.5815e-02, 3.0922e-06, 2.0945e-02, 1.1283e-04, 5.3271e-08,\n",
      "         5.8815e-03, 2.3243e-07, 2.2278e-04, 1.7102e-02, 4.7828e-05, 1.1670e-03,\n",
      "         9.4106e-06, 4.1403e-04, 1.0006e-02, 3.2439e-02, 7.4566e-07, 8.8320e-08,\n",
      "         8.1652e-04, 2.0631e-03, 2.8654e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9975]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[3.7229e-07, 1.4348e-05, 1.1767e-06, 1.8255e-03, 1.0068e-05, 5.2947e-03,\n",
      "         1.1239e-05, 1.2190e-02, 1.4119e-01, 1.9695e-06, 2.2331e-07, 3.6326e-03,\n",
      "         3.5999e-05, 2.0457e-03, 3.3618e-03, 1.7072e-04, 3.0226e-07, 3.7743e-02,\n",
      "         1.2931e-06, 1.3058e-02, 1.9022e-06, 6.5958e-08, 3.2835e-04, 2.3854e-03,\n",
      "         1.2218e-04, 1.0496e-04, 1.6346e-02, 1.2301e-06, 2.2262e-05, 6.4157e-06,\n",
      "         2.9822e-06, 2.6863e-02, 1.7106e-05, 5.2963e-04, 9.4681e-03, 2.2815e-02,\n",
      "         1.6153e-03, 1.7865e-07, 1.3030e-06, 1.9752e-01, 3.8454e-02, 3.5136e-03,\n",
      "         4.3859e-04, 2.0849e-02, 2.8503e-05, 1.3886e-01, 3.9829e-05, 5.4421e-04,\n",
      "         3.6109e-02, 7.2058e-08, 3.6694e-04, 3.0091e-02, 6.8047e-06, 1.9518e-04,\n",
      "         5.9008e-07, 3.8165e-06, 6.4274e-03, 2.1395e-04, 1.3740e-02, 2.2805e-03,\n",
      "         8.7881e-04, 3.7526e-02, 2.3648e-05, 8.4517e-02, 3.1173e-04, 4.3357e-07,\n",
      "         1.5494e-02, 6.7400e-07, 9.4068e-04, 2.1934e-02, 6.2143e-05, 2.3392e-03,\n",
      "         1.8730e-05, 6.7060e-04, 1.1053e-02, 2.0544e-02, 7.0447e-06, 3.8305e-07,\n",
      "         7.8359e-04, 5.5764e-03, 6.4111e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9966]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[5.1409e-08, 1.2450e-05, 2.8506e-07, 5.8575e-03, 1.1162e-06, 6.9107e-03,\n",
      "         1.4144e-06, 2.8473e-02, 8.8957e-02, 1.6038e-06, 1.5839e-08, 2.2742e-03,\n",
      "         2.7093e-06, 2.0726e-04, 2.7932e-03, 3.2750e-05, 4.1673e-08, 5.0323e-02,\n",
      "         2.7367e-07, 6.3590e-03, 4.8319e-07, 2.1192e-08, 2.4986e-04, 8.5917e-04,\n",
      "         6.0674e-05, 4.9788e-05, 2.6877e-02, 1.4376e-07, 1.3025e-05, 1.8971e-06,\n",
      "         1.2667e-06, 4.5221e-02, 5.1260e-06, 1.0294e-04, 1.5901e-02, 9.1979e-02,\n",
      "         2.0385e-03, 1.0529e-07, 1.2858e-07, 1.0714e-01, 8.6727e-02, 2.1957e-03,\n",
      "         1.5541e-04, 3.0264e-02, 4.7387e-06, 1.4803e-01, 1.9659e-05, 3.4182e-04,\n",
      "         2.6320e-02, 8.3564e-09, 2.1728e-05, 2.0358e-02, 2.7882e-06, 1.0640e-04,\n",
      "         6.0403e-07, 9.0981e-07, 8.0583e-03, 1.7086e-04, 1.6925e-02, 4.8842e-04,\n",
      "         3.7391e-04, 5.7829e-02, 2.7001e-06, 2.0635e-02, 1.0568e-04, 4.6429e-08,\n",
      "         5.6407e-03, 2.1955e-07, 2.1979e-04, 1.6073e-02, 4.3038e-05, 1.1000e-03,\n",
      "         8.9195e-06, 4.1291e-04, 9.9259e-03, 3.1845e-02, 6.8720e-07, 7.7875e-08,\n",
      "         7.8265e-04, 1.9646e-03, 3.0129e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9978]], grad_fn=<TanhBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[3.5058e-07, 1.3610e-05, 1.1063e-06, 1.8258e-03, 9.6487e-06, 4.8715e-03,\n",
      "         1.0848e-05, 1.2469e-02, 1.3637e-01, 1.9006e-06, 2.0801e-07, 3.5255e-03,\n",
      "         3.7206e-05, 2.0305e-03, 3.3266e-03, 1.6405e-04, 2.8250e-07, 3.8094e-02,\n",
      "         1.2380e-06, 1.2532e-02, 1.9231e-06, 6.2348e-08, 2.9924e-04, 2.3810e-03,\n",
      "         1.1660e-04, 9.6227e-05, 1.6228e-02, 1.2166e-06, 2.1359e-05, 6.2380e-06,\n",
      "         2.7784e-06, 2.5742e-02, 1.6727e-05, 5.0420e-04, 9.1715e-03, 2.3038e-02,\n",
      "         1.5421e-03, 1.6740e-07, 1.2532e-06, 2.0988e-01, 3.8019e-02, 3.3637e-03,\n",
      "         4.2048e-04, 2.1031e-02, 2.5989e-05, 1.4356e-01, 3.8033e-05, 5.0294e-04,\n",
      "         3.5086e-02, 6.6785e-08, 3.7027e-04, 2.9740e-02, 6.6154e-06, 1.9424e-04,\n",
      "         5.6296e-07, 3.6561e-06, 6.4320e-03, 2.1392e-04, 1.3294e-02, 2.2600e-03,\n",
      "         8.6631e-04, 4.0832e-02, 2.3727e-05, 7.5267e-02, 2.9841e-04, 3.8537e-07,\n",
      "         1.5378e-02, 6.4881e-07, 9.0027e-04, 2.1477e-02, 6.0327e-05, 2.2313e-03,\n",
      "         1.7931e-05, 6.7527e-04, 1.0320e-02, 2.0203e-02, 6.3784e-06, 3.6745e-07,\n",
      "         7.8039e-04, 5.4284e-03, 6.3277e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9967]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[4.0490e-08, 1.1126e-05, 2.3212e-07, 5.5925e-03, 9.2203e-07, 6.6998e-03,\n",
      "         1.1467e-06, 2.7788e-02, 9.0524e-02, 1.3504e-06, 1.2069e-08, 2.1490e-03,\n",
      "         2.3315e-06, 1.8976e-04, 2.5909e-03, 2.9169e-05, 3.3348e-08, 5.0243e-02,\n",
      "         2.1818e-07, 6.0472e-03, 3.8770e-07, 1.6535e-08, 2.2673e-04, 8.0531e-04,\n",
      "         5.3759e-05, 4.3490e-05, 2.6713e-02, 1.1255e-07, 1.1371e-05, 1.6033e-06,\n",
      "         1.0293e-06, 4.5100e-02, 4.4077e-06, 9.3513e-05, 1.5706e-02, 9.2368e-02,\n",
      "         1.9384e-03, 8.2513e-08, 9.9337e-08, 1.0612e-01, 8.9870e-02, 2.0588e-03,\n",
      "         1.4018e-04, 3.0140e-02, 4.0313e-06, 1.5008e-01, 1.7498e-05, 3.2449e-04,\n",
      "         2.6754e-02, 6.4326e-09, 1.8453e-05, 1.9358e-02, 2.2377e-06, 9.2599e-05,\n",
      "         4.9192e-07, 7.5571e-07, 7.7427e-03, 1.4977e-04, 1.6993e-02, 4.3466e-04,\n",
      "         3.3967e-04, 5.6891e-02, 2.2188e-06, 2.0792e-02, 9.4307e-05, 3.5974e-08,\n",
      "         5.5912e-03, 1.8179e-07, 2.0285e-04, 1.5658e-02, 3.7820e-05, 1.0196e-03,\n",
      "         7.8508e-06, 3.7878e-04, 9.7055e-03, 3.1417e-02, 5.8467e-07, 6.0828e-08,\n",
      "         7.3185e-04, 1.8950e-03, 2.9994e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9981]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[2.5901e-07, 1.0385e-05, 7.3127e-07, 1.5295e-03, 7.5308e-06, 4.0515e-03,\n",
      "         8.3803e-06, 1.0989e-02, 1.4199e-01, 1.3879e-06, 1.5077e-07, 3.3294e-03,\n",
      "         3.2310e-05, 1.8558e-03, 2.9771e-03, 1.3513e-04, 2.0449e-07, 3.5746e-02,\n",
      "         8.9598e-07, 1.2426e-02, 1.4007e-06, 3.7953e-08, 2.4133e-04, 2.2284e-03,\n",
      "         9.6278e-05, 7.6029e-05, 1.5068e-02, 8.9962e-07, 1.5985e-05, 4.6150e-06,\n",
      "         1.9018e-06, 2.3631e-02, 1.3165e-05, 4.2965e-04, 8.1031e-03, 2.0828e-02,\n",
      "         1.2890e-03, 1.0720e-07, 8.8846e-07, 2.3502e-01, 3.4972e-02, 3.2462e-03,\n",
      "         3.7821e-04, 1.9731e-02, 2.0472e-05, 1.4578e-01, 3.2309e-05, 4.3507e-04,\n",
      "         3.2794e-02, 4.4782e-08, 3.4194e-04, 2.8296e-02, 4.9072e-06, 1.5730e-04,\n",
      "         4.0862e-07, 2.7891e-06, 5.8074e-03, 1.7350e-04, 1.2571e-02, 1.9507e-03,\n",
      "         7.5205e-04, 3.9554e-02, 1.8757e-05, 7.2900e-02, 2.6076e-04, 2.7732e-07,\n",
      "         1.5178e-02, 4.8022e-07, 8.3542e-04, 2.0423e-02, 4.7460e-05, 1.9708e-03,\n",
      "         1.3580e-05, 5.8951e-04, 9.1471e-03, 1.8257e-02, 5.0862e-06, 2.7487e-07,\n",
      "         6.1692e-04, 5.1001e-03, 5.4855e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9981]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[2.3668e-08, 8.4778e-06, 1.4898e-07, 5.3266e-03, 5.8373e-07, 6.0546e-03,\n",
      "         7.2920e-07, 2.6399e-02, 8.9557e-02, 9.2668e-07, 6.7833e-09, 2.0172e-03,\n",
      "         1.6111e-06, 1.4767e-04, 2.2590e-03, 2.1921e-05, 1.9674e-08, 5.0033e-02,\n",
      "         1.3874e-07, 5.4671e-03, 2.2608e-07, 9.9315e-09, 1.8509e-04, 6.9906e-04,\n",
      "         4.0147e-05, 3.4837e-05, 2.6618e-02, 7.0487e-08, 8.1758e-06, 1.0925e-06,\n",
      "         6.6604e-07, 4.4021e-02, 3.1603e-06, 7.6185e-05, 1.4895e-02, 9.4378e-02,\n",
      "         1.7723e-03, 5.0498e-08, 5.5463e-08, 1.0228e-01, 9.1736e-02, 1.8240e-03,\n",
      "         1.1184e-04, 3.1284e-02, 2.9071e-06, 1.6157e-01, 1.3442e-05, 2.8094e-04,\n",
      "         2.6491e-02, 3.5927e-09, 1.3128e-05, 1.9075e-02, 1.4692e-06, 6.9287e-05,\n",
      "         3.3686e-07, 4.7135e-07, 6.9678e-03, 1.1217e-04, 1.7790e-02, 3.3363e-04,\n",
      "         2.8415e-04, 5.6495e-02, 1.4726e-06, 1.9347e-02, 7.8045e-05, 2.0539e-08,\n",
      "         5.0956e-03, 1.2437e-07, 1.6902e-04, 1.4249e-02, 2.8399e-05, 9.3818e-04,\n",
      "         5.6530e-06, 3.1229e-04, 9.3440e-03, 3.0027e-02, 3.8663e-07, 3.6365e-08,\n",
      "         6.0088e-04, 1.7154e-03, 3.1321e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9990]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[2.5881e-07, 9.8366e-06, 6.6417e-07, 1.4383e-03, 7.3586e-06, 4.1670e-03,\n",
      "         8.0479e-06, 1.0431e-02, 1.5390e-01, 1.2878e-06, 1.4644e-07, 3.1736e-03,\n",
      "         3.0758e-05, 1.8284e-03, 2.9486e-03, 1.2130e-04, 1.9051e-07, 3.6044e-02,\n",
      "         8.3723e-07, 1.2493e-02, 1.2945e-06, 3.4402e-08, 2.3456e-04, 2.2611e-03,\n",
      "         9.2474e-05, 7.1987e-05, 1.4448e-02, 8.1657e-07, 1.5468e-05, 4.1952e-06,\n",
      "         1.7986e-06, 2.3589e-02, 1.2451e-05, 4.1403e-04, 8.3544e-03, 1.9647e-02,\n",
      "         1.2482e-03, 9.8857e-08, 8.6303e-07, 2.3332e-01, 3.5081e-02, 3.1225e-03,\n",
      "         3.5965e-04, 2.0069e-02, 1.9988e-05, 1.4013e-01, 3.1390e-05, 4.4640e-04,\n",
      "         3.0590e-02, 4.2484e-08, 3.2427e-04, 2.8230e-02, 4.7461e-06, 1.5766e-04,\n",
      "         3.8206e-07, 2.7353e-06, 5.6117e-03, 1.6358e-04, 1.2600e-02, 1.8508e-03,\n",
      "         7.5781e-04, 3.8031e-02, 1.7657e-05, 7.4858e-02, 2.5658e-04, 2.7046e-07,\n",
      "         1.5216e-02, 4.3713e-07, 8.2899e-04, 2.0311e-02, 4.4175e-05, 1.9367e-03,\n",
      "         1.2201e-05, 5.7123e-04, 9.0414e-03, 1.7835e-02, 5.0852e-06, 2.7579e-07,\n",
      "         5.9432e-04, 5.0540e-03, 5.5115e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9983]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[2.2024e-08, 8.1717e-06, 1.3680e-07, 5.2379e-03, 5.4470e-07, 6.0209e-03,\n",
      "         7.0587e-07, 2.6339e-02, 8.9130e-02, 8.8114e-07, 6.2356e-09, 1.9453e-03,\n",
      "         1.5267e-06, 1.4189e-04, 2.2224e-03, 2.1397e-05, 1.8275e-08, 4.9452e-02,\n",
      "         1.3169e-07, 5.4005e-03, 2.1040e-07, 9.0682e-09, 1.7984e-04, 6.7902e-04,\n",
      "         3.9480e-05, 3.3985e-05, 2.6112e-02, 6.6479e-08, 7.8985e-06, 1.0369e-06,\n",
      "         6.1856e-07, 4.5025e-02, 3.0377e-06, 7.4550e-05, 1.4911e-02, 9.4414e-02,\n",
      "         1.7626e-03, 4.7458e-08, 5.1748e-08, 1.0079e-01, 9.1539e-02, 1.7632e-03,\n",
      "         1.0581e-04, 3.0363e-02, 2.7734e-06, 1.6465e-01, 1.2791e-05, 2.7480e-04,\n",
      "         2.6158e-02, 3.3155e-09, 1.2772e-05, 1.9512e-02, 1.4352e-06, 6.6499e-05,\n",
      "         3.0405e-07, 4.4808e-07, 7.0294e-03, 1.0882e-04, 1.7798e-02, 3.2607e-04,\n",
      "         2.7622e-04, 5.6545e-02, 1.4201e-06, 1.9386e-02, 7.6194e-05, 1.9084e-08,\n",
      "         4.9907e-03, 1.1776e-07, 1.6839e-04, 1.4202e-02, 2.7199e-05, 9.1475e-04,\n",
      "         5.4613e-06, 3.0265e-04, 9.4949e-03, 2.9640e-02, 3.7475e-07, 3.3239e-08,\n",
      "         5.9398e-04, 1.6724e-03, 3.2009e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9990]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[2.5094e-07, 9.8393e-06, 6.8050e-07, 1.4735e-03, 7.1869e-06, 4.0939e-03,\n",
      "         7.9484e-06, 1.0689e-02, 1.5063e-01, 1.2918e-06, 1.4885e-07, 3.2375e-03,\n",
      "         3.2402e-05, 1.7999e-03, 3.0006e-03, 1.2411e-04, 1.8426e-07, 3.7259e-02,\n",
      "         8.3566e-07, 1.2144e-02, 1.3456e-06, 3.3986e-08, 2.2882e-04, 2.2676e-03,\n",
      "         8.7634e-05, 7.4629e-05, 1.4873e-02, 8.1527e-07, 1.5684e-05, 4.2152e-06,\n",
      "         1.8129e-06, 2.4283e-02, 1.2663e-05, 4.2428e-04, 8.4980e-03, 2.0040e-02,\n",
      "         1.2223e-03, 1.0185e-07, 8.9272e-07, 2.3559e-01, 3.4897e-02, 3.1930e-03,\n",
      "         3.6313e-04, 2.0360e-02, 1.9389e-05, 1.3946e-01, 3.0918e-05, 4.3347e-04,\n",
      "         3.1226e-02, 4.0962e-08, 3.1235e-04, 2.8042e-02, 4.7449e-06, 1.5997e-04,\n",
      "         3.9013e-07, 2.7117e-06, 5.6776e-03, 1.6732e-04, 1.2402e-02, 1.8858e-03,\n",
      "         7.7046e-04, 3.8749e-02, 1.7724e-05, 7.1808e-02, 2.5802e-04, 2.6894e-07,\n",
      "         1.5537e-02, 4.3233e-07, 8.2184e-04, 2.0275e-02, 4.4821e-05, 1.9301e-03,\n",
      "         1.2380e-05, 5.5676e-04, 8.9359e-03, 1.8473e-02, 5.0411e-06, 2.6867e-07,\n",
      "         5.9852e-04, 4.9528e-03, 5.4752e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9980]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[1.9609e-08, 7.1562e-06, 1.2458e-07, 5.2367e-03, 5.2159e-07, 6.1289e-03,\n",
      "         6.4172e-07, 2.6460e-02, 9.1335e-02, 7.8703e-07, 5.3587e-09, 1.9402e-03,\n",
      "         1.3871e-06, 1.3771e-04, 2.1744e-03, 1.9665e-05, 1.6567e-08, 4.9287e-02,\n",
      "         1.1792e-07, 5.4884e-03, 1.7847e-07, 7.5661e-09, 1.7531e-04, 6.5666e-04,\n",
      "         3.6681e-05, 3.0955e-05, 2.5509e-02, 5.6578e-08, 7.0944e-06, 9.4173e-07,\n",
      "         5.5745e-07, 4.4445e-02, 2.7457e-06, 7.1082e-05, 1.4764e-02, 9.5648e-02,\n",
      "         1.7266e-03, 4.1087e-08, 4.3341e-08, 1.0452e-01, 9.2336e-02, 1.7682e-03,\n",
      "         9.8832e-05, 3.1142e-02, 2.4952e-06, 1.6418e-01, 1.1496e-05, 2.7256e-04,\n",
      "         2.5275e-02, 2.9256e-09, 1.1943e-05, 1.8132e-02, 1.2416e-06, 6.2648e-05,\n",
      "         2.6458e-07, 4.0483e-07, 6.8989e-03, 1.0105e-04, 1.7430e-02, 3.0855e-04,\n",
      "         2.7496e-04, 5.5415e-02, 1.2439e-06, 1.9031e-02, 7.4394e-05, 1.6863e-08,\n",
      "         5.0068e-03, 1.0593e-07, 1.6033e-04, 1.4224e-02, 2.5956e-05, 9.0859e-04,\n",
      "         4.9820e-06, 2.8512e-04, 9.4785e-03, 2.9337e-02, 3.2784e-07, 3.0199e-08,\n",
      "         5.7084e-04, 1.6515e-03, 2.9705e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9990]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[2.7637e-07, 1.0581e-05, 7.2493e-07, 1.4641e-03, 7.7448e-06, 4.3620e-03,\n",
      "         8.6567e-06, 1.0605e-02, 1.5482e-01, 1.3717e-06, 1.6210e-07, 3.2610e-03,\n",
      "         3.2686e-05, 1.8616e-03, 3.0916e-03, 1.2699e-04, 1.9847e-07, 3.7561e-02,\n",
      "         9.0285e-07, 1.2668e-02, 1.4173e-06, 3.6636e-08, 2.4190e-04, 2.2700e-03,\n",
      "         9.3749e-05, 7.9185e-05, 1.5093e-02, 8.5574e-07, 1.6435e-05, 4.4074e-06,\n",
      "         1.9018e-06, 2.4325e-02, 1.3098e-05, 4.3977e-04, 8.8119e-03, 1.9988e-02,\n",
      "         1.2860e-03, 1.0935e-07, 9.5317e-07, 2.2739e-01, 3.5592e-02, 3.2276e-03,\n",
      "         3.7017e-04, 2.0549e-02, 2.0859e-05, 1.3796e-01, 3.2292e-05, 4.7571e-04,\n",
      "         3.1168e-02, 4.5455e-08, 3.1682e-04, 2.8234e-02, 4.9751e-06, 1.6605e-04,\n",
      "         4.3168e-07, 2.8993e-06, 5.7436e-03, 1.7148e-04, 1.3044e-02, 1.9101e-03,\n",
      "         7.9341e-04, 3.6009e-02, 1.8190e-05, 7.5837e-02, 2.6428e-04, 3.0387e-07,\n",
      "         1.5555e-02, 4.7057e-07, 8.4803e-04, 2.0309e-02, 4.5208e-05, 2.0064e-03,\n",
      "         1.2784e-05, 5.7575e-04, 9.2008e-03, 1.8270e-02, 5.6963e-06, 2.9348e-07,\n",
      "         6.1606e-04, 4.9786e-03, 5.7180e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9980]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[3.0144e-08, 9.4863e-06, 1.7887e-07, 5.5004e-03, 7.3227e-07, 6.4902e-03,\n",
      "         8.9778e-07, 2.6951e-02, 9.1777e-02, 1.0879e-06, 8.8180e-09, 2.0347e-03,\n",
      "         1.8461e-06, 1.6444e-04, 2.3855e-03, 2.4419e-05, 2.5742e-08, 4.8982e-02,\n",
      "         1.7124e-07, 5.7996e-03, 2.6934e-07, 1.1875e-08, 2.0659e-04, 7.2060e-04,\n",
      "         4.5877e-05, 3.8983e-05, 2.5679e-02, 8.6037e-08, 9.1402e-06, 1.3115e-06,\n",
      "         8.0457e-07, 4.5413e-02, 3.5773e-06, 8.5254e-05, 1.5446e-02, 9.5953e-02,\n",
      "         1.8977e-03, 6.2712e-08, 6.7643e-08, 1.0538e-01, 8.9817e-02, 1.9140e-03,\n",
      "         1.1926e-04, 3.0555e-02, 3.3245e-06, 1.5515e-01, 1.4501e-05, 3.0841e-04,\n",
      "         2.6163e-02, 4.6928e-09, 1.5343e-05, 1.9362e-02, 1.7208e-06, 7.5349e-05,\n",
      "         3.7905e-07, 5.7791e-07, 7.4415e-03, 1.2396e-04, 1.8050e-02, 3.7405e-04,\n",
      "         3.2555e-04, 5.4904e-02, 1.7534e-06, 1.9866e-02, 8.7739e-05, 2.5984e-08,\n",
      "         5.3966e-03, 1.5113e-07, 1.9000e-04, 1.4768e-02, 3.2995e-05, 9.7836e-04,\n",
      "         6.5750e-06, 3.4261e-04, 9.7314e-03, 2.9955e-02, 4.5579e-07, 4.4515e-08,\n",
      "         6.4272e-04, 1.8009e-03, 3.0475e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9986]], grad_fn=<TanhBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[3.0690e-07, 1.1365e-05, 8.0618e-07, 1.4952e-03, 8.1518e-06, 4.6241e-03,\n",
      "         9.3955e-06, 1.0844e-02, 1.5695e-01, 1.4952e-06, 1.7356e-07, 3.2567e-03,\n",
      "         3.3054e-05, 1.8959e-03, 3.2158e-03, 1.3193e-04, 2.1211e-07, 3.7870e-02,\n",
      "         9.8662e-07, 1.2613e-02, 1.5405e-06, 4.1113e-08, 2.5113e-04, 2.3261e-03,\n",
      "         9.9422e-05, 8.2597e-05, 1.5368e-02, 8.9703e-07, 1.7893e-05, 4.7660e-06,\n",
      "         2.0839e-06, 2.5035e-02, 1.4003e-05, 4.6836e-04, 9.0595e-03, 2.0708e-02,\n",
      "         1.3215e-03, 1.2500e-07, 1.0357e-06, 2.1863e-01, 3.7380e-02, 3.1809e-03,\n",
      "         3.7039e-04, 2.1057e-02, 2.1931e-05, 1.3646e-01, 3.3215e-05, 5.0089e-04,\n",
      "         3.0643e-02, 5.0812e-08, 3.2174e-04, 2.8218e-02, 5.5796e-06, 1.7524e-04,\n",
      "         4.5854e-07, 3.0447e-06, 5.8355e-03, 1.8096e-04, 1.2950e-02, 1.9952e-03,\n",
      "         8.3380e-04, 3.5865e-02, 1.9043e-05, 7.7228e-02, 2.7459e-04, 3.2708e-07,\n",
      "         1.5723e-02, 5.0632e-07, 8.5461e-04, 2.1209e-02, 4.7659e-05, 2.1016e-03,\n",
      "         1.3466e-05, 5.9128e-04, 9.4100e-03, 1.8585e-02, 5.9808e-06, 3.2758e-07,\n",
      "         6.5552e-04, 5.0166e-03, 5.8709e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9976]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[3.3200e-08, 9.9241e-06, 1.9575e-07, 5.6224e-03, 7.6495e-07, 6.5069e-03,\n",
      "         9.4901e-07, 2.7560e-02, 9.0453e-02, 1.1717e-06, 9.6318e-09, 2.0723e-03,\n",
      "         1.9794e-06, 1.6874e-04, 2.4501e-03, 2.5393e-05, 2.7452e-08, 4.8474e-02,\n",
      "         1.8433e-07, 5.7914e-03, 2.9606e-07, 1.3035e-08, 2.1220e-04, 7.4456e-04,\n",
      "         4.7679e-05, 3.9658e-05, 2.5924e-02, 9.2844e-08, 9.7514e-06, 1.3973e-06,\n",
      "         8.8542e-07, 4.6226e-02, 3.8080e-06, 8.6576e-05, 1.5400e-02, 9.6578e-02,\n",
      "         1.9126e-03, 6.8994e-08, 7.4661e-08, 1.0641e-01, 8.9568e-02, 1.9459e-03,\n",
      "         1.2631e-04, 3.0070e-02, 3.4851e-06, 1.5234e-01, 1.5417e-05, 3.1289e-04,\n",
      "         2.6522e-02, 5.1092e-09, 1.5998e-05, 1.9595e-02, 1.8699e-06, 7.9647e-05,\n",
      "         4.0590e-07, 6.2077e-07, 7.5274e-03, 1.3075e-04, 1.7669e-02, 3.9160e-04,\n",
      "         3.3284e-04, 5.5122e-02, 1.9264e-06, 2.0099e-02, 9.0708e-05, 2.8176e-08,\n",
      "         5.5269e-03, 1.6104e-07, 1.9599e-04, 1.5009e-02, 3.4888e-05, 9.9061e-04,\n",
      "         7.0167e-06, 3.5122e-04, 9.6571e-03, 3.0606e-02, 4.8504e-07, 4.7695e-08,\n",
      "         6.6814e-04, 1.8474e-03, 3.0412e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9985]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[3.1393e-07, 1.1686e-05, 8.1876e-07, 1.5258e-03, 8.3980e-06, 4.7020e-03,\n",
      "         9.7376e-06, 1.1035e-02, 1.5586e-01, 1.5124e-06, 1.7862e-07, 3.3024e-03,\n",
      "         3.3505e-05, 1.9528e-03, 3.2969e-03, 1.3439e-04, 2.2005e-07, 3.8628e-02,\n",
      "         1.0199e-06, 1.2810e-02, 1.6059e-06, 4.2725e-08, 2.5941e-04, 2.3432e-03,\n",
      "         9.9783e-05, 8.5033e-05, 1.5432e-02, 9.5055e-07, 1.8348e-05, 4.8913e-06,\n",
      "         2.0901e-06, 2.5219e-02, 1.4230e-05, 4.7224e-04, 9.2406e-03, 2.0975e-02,\n",
      "         1.3241e-03, 1.2944e-07, 1.0693e-06, 2.1366e-01, 3.8790e-02, 3.1534e-03,\n",
      "         3.7736e-04, 2.1123e-02, 2.2512e-05, 1.3803e-01, 3.4051e-05, 5.1429e-04,\n",
      "         3.0647e-02, 5.2925e-08, 3.2577e-04, 2.8833e-02, 5.7385e-06, 1.8124e-04,\n",
      "         4.7780e-07, 3.1135e-06, 5.9080e-03, 1.8492e-04, 1.2935e-02, 2.0382e-03,\n",
      "         8.4485e-04, 3.6572e-02, 1.9632e-05, 7.6501e-02, 2.8131e-04, 3.4078e-07,\n",
      "         1.5903e-02, 5.2800e-07, 8.8038e-04, 2.0935e-02, 4.8172e-05, 2.1045e-03,\n",
      "         1.3738e-05, 5.9689e-04, 9.6012e-03, 1.8385e-02, 6.1953e-06, 3.3864e-07,\n",
      "         6.7292e-04, 5.0222e-03, 6.0391e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9975]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[3.5518e-08, 1.0376e-05, 2.1141e-07, 5.6535e-03, 8.2834e-07, 6.6784e-03,\n",
      "         1.0159e-06, 2.7844e-02, 9.1292e-02, 1.2285e-06, 1.0349e-08, 2.1185e-03,\n",
      "         2.0441e-06, 1.7422e-04, 2.4012e-03, 2.5852e-05, 2.9127e-08, 4.8556e-02,\n",
      "         1.9747e-07, 5.7801e-03, 3.0445e-07, 1.3998e-08, 2.2197e-04, 7.5106e-04,\n",
      "         5.0076e-05, 4.0643e-05, 2.5715e-02, 9.9359e-08, 1.0186e-05, 1.4794e-06,\n",
      "         9.3425e-07, 4.5927e-02, 3.9657e-06, 8.8751e-05, 1.5715e-02, 9.7327e-02,\n",
      "         1.9623e-03, 7.2174e-08, 7.9954e-08, 1.0797e-01, 8.8440e-02, 1.9964e-03,\n",
      "         1.2723e-04, 3.0358e-02, 3.7716e-06, 1.5223e-01, 1.5885e-05, 3.2329e-04,\n",
      "         2.5958e-02, 5.6088e-09, 1.6639e-05, 1.9272e-02, 1.9290e-06, 8.0757e-05,\n",
      "         4.1177e-07, 6.4535e-07, 7.5269e-03, 1.3055e-04, 1.7886e-02, 4.1305e-04,\n",
      "         3.4254e-04, 5.3682e-02, 2.0017e-06, 2.0464e-02, 9.2966e-05, 3.0541e-08,\n",
      "         5.5906e-03, 1.7272e-07, 2.0534e-04, 1.5465e-02, 3.5839e-05, 1.0170e-03,\n",
      "         7.1946e-06, 3.5703e-04, 9.9725e-03, 2.9815e-02, 5.0797e-07, 5.2005e-08,\n",
      "         6.9202e-04, 1.8605e-03, 2.9294e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9983]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[3.0210e-07, 1.1927e-05, 9.0339e-07, 1.6579e-03, 8.2376e-06, 4.6233e-03,\n",
      "         9.7110e-06, 1.1774e-02, 1.4593e-01, 1.6082e-06, 1.7214e-07, 3.5254e-03,\n",
      "         3.3805e-05, 1.9021e-03, 3.3740e-03, 1.5096e-04, 2.2709e-07, 3.7685e-02,\n",
      "         1.0439e-06, 1.2927e-02, 1.6567e-06, 4.5236e-08, 2.6711e-04, 2.2705e-03,\n",
      "         9.8325e-05, 8.7846e-05, 1.6326e-02, 1.0035e-06, 1.8162e-05, 5.2303e-06,\n",
      "         2.2135e-06, 2.5764e-02, 1.4099e-05, 4.7717e-04, 9.2819e-03, 2.2753e-02,\n",
      "         1.3527e-03, 1.3715e-07, 1.0806e-06, 2.1150e-01, 3.9770e-02, 3.3203e-03,\n",
      "         3.9003e-04, 2.0868e-02, 2.2490e-05, 1.4222e-01, 3.4489e-05, 4.9292e-04,\n",
      "         3.3196e-02, 5.2653e-08, 3.3061e-04, 2.9317e-02, 5.7686e-06, 1.7680e-04,\n",
      "         4.8030e-07, 3.0534e-06, 5.9963e-03, 1.9957e-04, 1.3030e-02, 2.0903e-03,\n",
      "         8.0976e-04, 3.9233e-02, 1.9783e-05, 7.4050e-02, 2.7702e-04, 3.3897e-07,\n",
      "         1.5937e-02, 5.5159e-07, 8.3088e-04, 1.9808e-02, 5.0127e-05, 2.1472e-03,\n",
      "         1.4900e-05, 5.8499e-04, 9.7710e-03, 1.9178e-02, 5.9121e-06, 3.0230e-07,\n",
      "         6.9980e-04, 5.1496e-03, 6.1301e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9973]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[2.9838e-08, 8.6129e-06, 1.8330e-07, 5.5252e-03, 7.1995e-07, 6.5037e-03,\n",
      "         8.5909e-07, 2.7896e-02, 9.1365e-02, 1.0494e-06, 8.4909e-09, 2.0796e-03,\n",
      "         1.8372e-06, 1.6294e-04, 2.2375e-03, 2.3271e-05, 2.4286e-08, 4.8922e-02,\n",
      "         1.6967e-07, 5.6515e-03, 2.4697e-07, 1.1102e-08, 2.0793e-04, 7.4658e-04,\n",
      "         4.3941e-05, 3.5461e-05, 2.4972e-02, 8.1954e-08, 8.9672e-06, 1.2623e-06,\n",
      "         8.4164e-07, 4.5933e-02, 3.5797e-06, 8.3421e-05, 1.5400e-02, 9.7798e-02,\n",
      "         1.8714e-03, 6.2824e-08, 6.5021e-08, 1.0914e-01, 9.0994e-02, 1.9349e-03,\n",
      "         1.2058e-04, 3.1237e-02, 3.2566e-06, 1.5452e-01, 1.4262e-05, 3.0361e-04,\n",
      "         2.5344e-02, 4.6958e-09, 1.5100e-05, 1.7403e-02, 1.6432e-06, 7.6035e-05,\n",
      "         3.3920e-07, 5.4141e-07, 7.3153e-03, 1.2026e-04, 1.7143e-02, 3.8131e-04,\n",
      "         3.4391e-04, 5.4015e-02, 1.7058e-06, 1.9697e-02, 8.7902e-05, 2.5612e-08,\n",
      "         5.5686e-03, 1.4780e-07, 1.8969e-04, 1.5564e-02, 3.4137e-05, 1.0129e-03,\n",
      "         6.3882e-06, 3.2915e-04, 9.6424e-03, 2.9896e-02, 4.2709e-07, 4.6104e-08,\n",
      "         6.5425e-04, 1.8740e-03, 2.7526e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9986]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[2.6763e-07, 1.0893e-05, 7.8417e-07, 1.5485e-03, 7.5873e-06, 4.3516e-03,\n",
      "         9.0858e-06, 1.0847e-02, 1.4715e-01, 1.4477e-06, 1.5504e-07, 3.4843e-03,\n",
      "         3.0980e-05, 1.8379e-03, 3.2045e-03, 1.4560e-04, 2.1104e-07, 3.5875e-02,\n",
      "         9.3697e-07, 1.2964e-02, 1.4993e-06, 3.8647e-08, 2.5371e-04, 2.1326e-03,\n",
      "         9.5744e-05, 8.2655e-05, 1.6101e-02, 9.1394e-07, 1.6105e-05, 4.5978e-06,\n",
      "         1.9616e-06, 2.4502e-02, 1.2774e-05, 4.5619e-04, 8.6038e-03, 2.2450e-02,\n",
      "         1.2878e-03, 1.1559e-07, 9.5106e-07, 2.1589e-01, 3.8790e-02, 3.2844e-03,\n",
      "         3.8307e-04, 1.9919e-02, 2.1266e-05, 1.4409e-01, 3.2992e-05, 4.6354e-04,\n",
      "         3.4248e-02, 4.5451e-08, 3.2273e-04, 2.9164e-02, 5.1455e-06, 1.6193e-04,\n",
      "         4.3637e-07, 2.8054e-06, 5.8588e-03, 1.8294e-04, 1.3151e-02, 1.9781e-03,\n",
      "         7.5678e-04, 3.8564e-02, 1.8245e-05, 7.6868e-02, 2.5999e-04, 3.0642e-07,\n",
      "         1.5765e-02, 5.0232e-07, 8.0739e-04, 1.9417e-02, 4.5492e-05, 2.0606e-03,\n",
      "         1.3977e-05, 5.7012e-04, 9.3324e-03, 1.8375e-02, 5.4643e-06, 2.7275e-07,\n",
      "         6.2913e-04, 5.0920e-03, 6.0014e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9979]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[3.2508e-08, 8.8014e-06, 1.9310e-07, 5.5731e-03, 7.4133e-07, 6.1496e-03,\n",
      "         8.7538e-07, 2.8958e-02, 8.8131e-02, 1.1223e-06, 9.1798e-09, 2.0885e-03,\n",
      "         1.9839e-06, 1.6446e-04, 2.2711e-03, 2.4446e-05, 2.4720e-08, 4.8805e-02,\n",
      "         1.7912e-07, 5.4996e-03, 2.7778e-07, 1.2587e-08, 2.0807e-04, 7.9961e-04,\n",
      "         4.4482e-05, 3.5921e-05, 2.5105e-02, 9.0284e-08, 9.6307e-06, 1.3351e-06,\n",
      "         9.2109e-07, 4.6370e-02, 3.8104e-06, 8.4061e-05, 1.5653e-02, 9.6817e-02,\n",
      "         1.8655e-03, 7.1027e-08, 7.4739e-08, 1.0874e-01, 9.0194e-02, 1.8812e-03,\n",
      "         1.2492e-04, 3.0326e-02, 3.3090e-06, 1.5765e-01, 1.5280e-05, 2.9211e-04,\n",
      "         2.5543e-02, 4.9951e-09, 1.5750e-05, 1.7581e-02, 1.8769e-06, 8.4280e-05,\n",
      "         3.6778e-07, 5.9508e-07, 7.4311e-03, 1.3218e-04, 1.6097e-02, 3.9499e-04,\n",
      "         3.4016e-04, 5.6938e-02, 1.8983e-06, 1.8463e-02, 8.7320e-05, 2.7187e-08,\n",
      "         5.5798e-03, 1.5262e-07, 1.8959e-04, 1.5281e-02, 3.6036e-05, 1.0449e-03,\n",
      "         6.7947e-06, 3.5824e-04, 9.1986e-03, 3.0449e-02, 4.5255e-07, 4.8672e-08,\n",
      "         6.6994e-04, 1.9455e-03, 2.8220e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9987]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[2.8093e-07, 1.1225e-05, 8.1330e-07, 1.5283e-03, 8.0495e-06, 4.6473e-03,\n",
      "         9.3827e-06, 1.0483e-02, 1.5316e-01, 1.4926e-06, 1.6421e-07, 3.4374e-03,\n",
      "         3.0926e-05, 1.8926e-03, 3.3065e-03, 1.4689e-04, 2.2326e-07, 3.6285e-02,\n",
      "         9.8011e-07, 1.3207e-02, 1.5221e-06, 4.0058e-08, 2.6771e-04, 2.1583e-03,\n",
      "         1.0180e-04, 8.9159e-05, 1.6070e-02, 9.3182e-07, 1.6602e-05, 4.7798e-06,\n",
      "         2.0426e-06, 2.5032e-02, 1.2895e-05, 4.7409e-04, 8.8890e-03, 2.2680e-02,\n",
      "         1.3229e-03, 1.2004e-07, 9.8603e-07, 2.0822e-01, 3.8026e-02, 3.2944e-03,\n",
      "         3.7651e-04, 2.0583e-02, 2.2661e-05, 1.4196e-01, 3.3477e-05, 4.8396e-04,\n",
      "         3.3512e-02, 4.7672e-08, 3.2694e-04, 2.9500e-02, 5.2469e-06, 1.6161e-04,\n",
      "         4.5598e-07, 2.9091e-06, 5.9054e-03, 1.8144e-04, 1.2663e-02, 2.0343e-03,\n",
      "         7.8818e-04, 3.6350e-02, 1.8138e-05, 8.1544e-02, 2.5939e-04, 3.3567e-07,\n",
      "         1.5805e-02, 5.0071e-07, 8.2116e-04, 1.9847e-02, 4.6966e-05, 2.0231e-03,\n",
      "         1.3773e-05, 5.5738e-04, 9.5674e-03, 1.8387e-02, 5.7329e-06, 2.8577e-07,\n",
      "         6.4988e-04, 4.8405e-03, 5.8962e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9978]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[4.0175e-08, 1.0361e-05, 2.3053e-07, 5.8147e-03, 8.3077e-07, 6.1580e-03,\n",
      "         1.0270e-06, 2.9804e-02, 8.4924e-02, 1.3233e-06, 1.1354e-08, 2.1787e-03,\n",
      "         2.3440e-06, 1.7485e-04, 2.4511e-03, 2.7529e-05, 2.9318e-08, 4.8766e-02,\n",
      "         2.1485e-07, 5.6280e-03, 3.5040e-07, 1.6289e-08, 2.1907e-04, 8.4066e-04,\n",
      "         5.1054e-05, 4.1974e-05, 2.6091e-02, 1.1459e-07, 1.1352e-05, 1.5774e-06,\n",
      "         1.0680e-06, 4.7129e-02, 4.3779e-06, 8.9303e-05, 1.6072e-02, 9.6219e-02,\n",
      "         1.9650e-03, 8.8192e-08, 9.6538e-08, 1.0879e-01, 8.7551e-02, 1.8960e-03,\n",
      "         1.3471e-04, 3.0060e-02, 3.7911e-06, 1.5509e-01, 1.7533e-05, 3.1045e-04,\n",
      "         2.6022e-02, 6.2224e-09, 1.7754e-05, 1.8702e-02, 2.3196e-06, 9.4416e-05,\n",
      "         4.5893e-07, 7.2871e-07, 7.5652e-03, 1.5091e-04, 1.6488e-02, 4.2834e-04,\n",
      "         3.4549e-04, 5.7771e-02, 2.2930e-06, 1.8343e-02, 9.4401e-05, 3.3267e-08,\n",
      "         5.6807e-03, 1.8516e-07, 2.0717e-04, 1.5411e-02, 3.9150e-05, 1.0745e-03,\n",
      "         7.8041e-06, 3.8349e-04, 9.3482e-03, 3.1264e-02, 5.4803e-07, 5.6551e-08,\n",
      "         7.2195e-04, 1.9807e-03, 2.9320e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9984]], grad_fn=<TanhBackward0>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[3.1751e-07, 1.1985e-05, 8.7412e-07, 1.5557e-03, 8.7975e-06, 5.0848e-03,\n",
      "         9.9708e-06, 1.0417e-02, 1.5463e-01, 1.5562e-06, 1.8824e-07, 3.3794e-03,\n",
      "         3.1935e-05, 1.9029e-03, 3.4183e-03, 1.4764e-04, 2.4378e-07, 3.6468e-02,\n",
      "         1.0465e-06, 1.3557e-02, 1.5977e-06, 4.4003e-08, 2.8121e-04, 2.2606e-03,\n",
      "         1.0755e-04, 9.4816e-05, 1.5547e-02, 9.6348e-07, 1.8434e-05, 5.0355e-06,\n",
      "         2.2790e-06, 2.6118e-02, 1.3876e-05, 4.8500e-04, 9.0202e-03, 2.1407e-02,\n",
      "         1.3563e-03, 1.3136e-07, 1.0689e-06, 2.0769e-01, 3.7452e-02, 3.4385e-03,\n",
      "         3.9666e-04, 2.0971e-02, 2.3985e-05, 1.3592e-01, 3.4190e-05, 5.2008e-04,\n",
      "         3.2306e-02, 5.3164e-08, 3.3032e-04, 3.0323e-02, 5.7940e-06, 1.7598e-04,\n",
      "         4.9183e-07, 3.2187e-06, 5.9858e-03, 1.8949e-04, 1.2443e-02, 2.0713e-03,\n",
      "         8.4082e-04, 3.6649e-02, 1.9098e-05, 8.3112e-02, 2.7560e-04, 3.7207e-07,\n",
      "         1.5910e-02, 5.1294e-07, 8.6423e-04, 2.1062e-02, 5.0381e-05, 2.0743e-03,\n",
      "         1.4350e-05, 5.6182e-04, 1.0224e-02, 1.9402e-02, 6.2597e-06, 3.2366e-07,\n",
      "         6.8710e-04, 4.7225e-03, 5.8906e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9976]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[3.7321e-08, 9.9286e-06, 2.1852e-07, 5.7708e-03, 8.0743e-07, 6.2026e-03,\n",
      "         9.9439e-07, 2.9092e-02, 8.6368e-02, 1.2715e-06, 1.0625e-08, 2.1265e-03,\n",
      "         2.1804e-06, 1.7061e-04, 2.4204e-03, 2.7127e-05, 2.7508e-08, 4.8476e-02,\n",
      "         2.0323e-07, 5.6062e-03, 3.2817e-07, 1.5469e-08, 2.1364e-04, 8.1918e-04,\n",
      "         4.9940e-05, 4.0459e-05, 2.6182e-02, 1.0548e-07, 1.0865e-05, 1.5231e-06,\n",
      "         1.0015e-06, 4.6059e-02, 4.2240e-06, 8.8482e-05, 1.5773e-02, 9.6110e-02,\n",
      "         1.9636e-03, 8.0486e-08, 8.9376e-08, 1.0865e-01, 8.7077e-02, 1.8919e-03,\n",
      "         1.3115e-04, 3.0784e-02, 3.7102e-06, 1.5637e-01, 1.6773e-05, 3.0713e-04,\n",
      "         2.6238e-02, 5.8177e-09, 1.7396e-05, 1.8680e-02, 2.1668e-06, 9.1545e-05,\n",
      "         4.3446e-07, 6.8690e-07, 7.5216e-03, 1.4375e-04, 1.6689e-02, 4.1968e-04,\n",
      "         3.3119e-04, 5.7461e-02, 2.1554e-06, 1.8581e-02, 9.2146e-05, 3.0919e-08,\n",
      "         5.5874e-03, 1.7460e-07, 2.0310e-04, 1.5288e-02, 3.8069e-05, 1.0738e-03,\n",
      "         7.4410e-06, 3.7588e-04, 9.4565e-03, 3.1223e-02, 5.2172e-07, 5.3655e-08,\n",
      "         7.0061e-04, 1.9356e-03, 2.9018e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9985]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[2.6843e-07, 1.0630e-05, 7.4956e-07, 1.4469e-03, 7.9166e-06, 4.6504e-03,\n",
      "         8.8449e-06, 1.0010e-02, 1.5478e-01, 1.3666e-06, 1.6131e-07, 3.3580e-03,\n",
      "         2.9406e-05, 1.8597e-03, 3.2046e-03, 1.3701e-04, 2.0800e-07, 3.5956e-02,\n",
      "         8.9844e-07, 1.3557e-02, 1.3538e-06, 3.6224e-08, 2.6594e-04, 2.2220e-03,\n",
      "         9.9456e-05, 8.6807e-05, 1.5095e-02, 8.5941e-07, 1.6129e-05, 4.2530e-06,\n",
      "         1.9046e-06, 2.5433e-02, 1.2459e-05, 4.5627e-04, 8.4651e-03, 2.0757e-02,\n",
      "         1.2775e-03, 1.0571e-07, 9.2500e-07, 2.1415e-01, 3.6103e-02, 3.3990e-03,\n",
      "         3.8010e-04, 2.0686e-02, 2.2503e-05, 1.3863e-01, 3.1665e-05, 4.8712e-04,\n",
      "         3.2616e-02, 4.4111e-08, 3.1600e-04, 2.9664e-02, 4.9212e-06, 1.5853e-04,\n",
      "         4.2348e-07, 2.7960e-06, 5.6092e-03, 1.6894e-04, 1.2387e-02, 1.9717e-03,\n",
      "         7.5944e-04, 3.5779e-02, 1.7013e-05, 8.5138e-02, 2.5335e-04, 3.1692e-07,\n",
      "         1.5759e-02, 4.5233e-07, 8.4440e-04, 1.9955e-02, 4.4824e-05, 1.9897e-03,\n",
      "         1.2697e-05, 5.3095e-04, 9.6032e-03, 1.8473e-02, 5.6316e-06, 2.7080e-07,\n",
      "         6.0553e-04, 4.6038e-03, 5.6153e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9982]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[3.0187e-08, 8.4543e-06, 1.8049e-07, 5.5296e-03, 6.6982e-07, 5.8750e-03,\n",
      "         8.1716e-07, 2.9015e-02, 8.5895e-02, 1.0853e-06, 8.4047e-09, 2.0550e-03,\n",
      "         1.9430e-06, 1.5298e-04, 2.3131e-03, 2.4281e-05, 2.1756e-08, 4.8161e-02,\n",
      "         1.7003e-07, 5.4030e-03, 2.7282e-07, 1.2469e-08, 1.9404e-04, 7.9191e-04,\n",
      "         4.3180e-05, 3.5504e-05, 2.5806e-02, 8.4693e-08, 9.4738e-06, 1.2769e-06,\n",
      "         8.5052e-07, 4.4920e-02, 3.6856e-06, 8.1436e-05, 1.5385e-02, 9.7254e-02,\n",
      "         1.8385e-03, 6.8850e-08, 7.1634e-08, 1.0886e-01, 8.7081e-02, 1.7708e-03,\n",
      "         1.1887e-04, 3.0789e-02, 3.1147e-06, 1.6195e-01, 1.4759e-05, 2.8034e-04,\n",
      "         2.5735e-02, 4.6079e-09, 1.5492e-05, 1.7730e-02, 1.8889e-06, 8.4259e-05,\n",
      "         3.6951e-07, 5.7271e-07, 7.2766e-03, 1.3469e-04, 1.6297e-02, 3.8012e-04,\n",
      "         3.0835e-04, 5.8340e-02, 1.8282e-06, 1.7742e-02, 8.5303e-05, 2.4845e-08,\n",
      "         5.4486e-03, 1.4437e-07, 1.7993e-04, 1.5176e-02, 3.4324e-05, 1.0347e-03,\n",
      "         6.4543e-06, 3.5215e-04, 9.0114e-03, 3.1383e-02, 4.3130e-07, 4.4730e-08,\n",
      "         6.5048e-04, 1.9238e-03, 2.8992e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9988]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[2.4817e-07, 9.7220e-06, 6.4910e-07, 1.3179e-03, 7.5288e-06, 4.6689e-03,\n",
      "         8.1214e-06, 9.2341e-03, 1.6597e-01, 1.2032e-06, 1.3361e-07, 3.1898e-03,\n",
      "         2.4583e-05, 1.8433e-03, 2.9693e-03, 1.2451e-04, 1.8781e-07, 3.4928e-02,\n",
      "         8.3561e-07, 1.4162e-02, 1.1217e-06, 3.1011e-08, 2.6389e-04, 2.0416e-03,\n",
      "         9.7596e-05, 8.4134e-05, 1.4535e-02, 7.4695e-07, 1.4337e-05, 3.9021e-06,\n",
      "         1.6288e-06, 2.4901e-02, 1.1100e-05, 4.2481e-04, 8.1362e-03, 2.0190e-02,\n",
      "         1.2503e-03, 8.9274e-08, 8.1678e-07, 2.1007e-01, 3.5480e-02, 3.1754e-03,\n",
      "         3.5448e-04, 2.0555e-02, 2.1567e-05, 1.3782e-01, 2.9739e-05, 4.9092e-04,\n",
      "         3.1864e-02, 3.9317e-08, 2.9632e-04, 2.8049e-02, 4.2248e-06, 1.3706e-04,\n",
      "         3.7121e-07, 2.6073e-06, 5.2895e-03, 1.4959e-04, 1.2142e-02, 1.9076e-03,\n",
      "         7.3565e-04, 3.2239e-02, 1.5098e-05, 9.3553e-02, 2.3825e-04, 2.8512e-07,\n",
      "         1.5345e-02, 3.8549e-07, 8.5112e-04, 1.9393e-02, 4.0024e-05, 1.9072e-03,\n",
      "         1.0902e-05, 4.9835e-04, 9.4024e-03, 1.7257e-02, 5.2298e-06, 2.3439e-07,\n",
      "         5.5990e-04, 4.4742e-03, 5.2256e-03]], grad_fn=<SoftmaxBackward0>), tensor([[0.9986]], grad_fn=<TanhBackward0>))\n",
      "== StudentAgent (1) vs RandomStudentAgent (2) - First Player: 2 ==\n",
      "You win!\n",
      "your_agent statistics:\n",
      "Timeout count: 0\n",
      "Invalid count: 0\n",
      "opponent_agent statistics:\n",
      "Timeout count: 0\n",
      "Invalid count: 0\n",
      "Turn count: 56\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class StudentAgent:\n",
    "    def __init__(self):\n",
    "        \"\"\"Instantiates your agent.\n",
    "        \"\"\"\n",
    "\n",
    "    def choose_action(self, state: State) -> Action:\n",
    "        \"\"\"Returns a valid action to be played on the board.\n",
    "        Assuming that you are filling in the board with number 1.\n",
    "\n",
    "        Parameters\n",
    "        ---------------\n",
    "        state: The board to make a move on.\n",
    "        \"\"\"\n",
    "        #return best_move(state, 1, inference_model)\n",
    "        return get_move(state, inference_model)\n",
    "\n",
    "# Use this cell to test your agent in two full games against a random agent.\n",
    "# The random agent will choose actions randomly among the valid actions.\n",
    "\n",
    "class RandomStudentAgent(StudentAgent):\n",
    "    def choose_action(self, state: State) -> Action:\n",
    "        # If you're using an existing Player 1 agent, you may need to invert the state\n",
    "        # to have it play as Player 2. Uncomment the next line to invert the state.\n",
    "        # state = state.invert()\n",
    "\n",
    "        # Choose a random valid action from the current game state\n",
    "        return state.get_random_valid_action()\n",
    "\n",
    "def run(your_agent: StudentAgent, opponent_agent: StudentAgent, start_num: int):\n",
    "    your_agent_stats = {\"timeout_count\": 0, \"invalid_count\": 0}\n",
    "    opponent_agent_stats = {\"timeout_count\": 0, \"invalid_count\": 0}\n",
    "    turn_count = 0\n",
    "    \n",
    "    state = State(fill_num=start_num)\n",
    "    \n",
    "    while not state.is_terminal():\n",
    "        #print(state)\n",
    "        turn_count += 1\n",
    "\n",
    "        agent_name = \"your_agent\" if state.fill_num == 1 else \"opponent_agent\"\n",
    "        agent = your_agent if state.fill_num == 1 else opponent_agent\n",
    "        stats = your_agent_stats if state.fill_num == 1 else opponent_agent_stats\n",
    "\n",
    "        start_time = time.time()\n",
    "        action = agent.choose_action(state.clone())\n",
    "        end_time = time.time()\n",
    "        \n",
    "        random_action = state.get_random_valid_action()\n",
    "        if end_time - start_time > 3:\n",
    "            print(f\"{agent_name} timed out!\")\n",
    "            stats[\"timeout_count\"] += 1\n",
    "            action = random_action\n",
    "        if not state.is_valid_action(action):\n",
    "            print(f\"{agent_name} made an invalid action!\")\n",
    "            stats[\"invalid_count\"] += 1\n",
    "            action = random_action\n",
    "                \n",
    "        #print(action)\n",
    "        print(inference_model(state_to_tensor(state)))\n",
    "        state = state.change_state(action)\n",
    "\n",
    "    print(f\"== {your_agent.__class__.__name__} (1) vs {opponent_agent.__class__.__name__} (2) - First Player: {start_num} ==\")\n",
    "        \n",
    "    if state.terminal_utility() == 1:\n",
    "        print(\"You win!\")\n",
    "    elif state.terminal_utility() == 0:\n",
    "        print(\"You lose!\")\n",
    "    else:\n",
    "        print(\"Draw\")\n",
    "\n",
    "    for agent_name, stats in [(\"your_agent\", your_agent_stats), (\"opponent_agent\", opponent_agent_stats)]:\n",
    "        print(f\"{agent_name} statistics:\")\n",
    "        print(f\"Timeout count: {stats['timeout_count']}\")\n",
    "        print(f\"Invalid count: {stats['invalid_count']}\")\n",
    "        \n",
    "    print(f\"Turn count: {turn_count}\\n\")\n",
    "    #print(state)\n",
    "\n",
    "your_agent = lambda: StudentAgent()\n",
    "opponent_agent = lambda: RandomStudentAgent()\n",
    "\n",
    "run(your_agent(), opponent_agent(), 1)\n",
    "run(your_agent(), opponent_agent(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "99ddfd8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[9.4793e-06, 3.2631e-04, 3.0510e-05, 7.2048e-03, 5.4976e-05, 1.2403e-02,\n",
      "         6.2163e-05, 3.5673e-02, 6.2828e-02, 5.7124e-05, 3.9309e-06, 5.4976e-03,\n",
      "         1.7686e-04, 2.3642e-03, 6.4218e-03, 9.1988e-04, 6.8387e-06, 3.5382e-02,\n",
      "         3.2539e-05, 9.5501e-03, 3.5474e-05, 5.0363e-06, 1.6491e-03, 3.9291e-03,\n",
      "         5.5464e-04, 4.8744e-04, 3.0758e-02, 1.2322e-05, 2.8126e-04, 8.7949e-05,\n",
      "         7.6690e-05, 5.6819e-02, 1.8095e-04, 1.2417e-03, 2.1750e-02, 6.2042e-02,\n",
      "         4.2854e-03, 1.4375e-05, 2.0925e-05, 8.4585e-02, 5.8950e-02, 7.7374e-03,\n",
      "         1.6837e-03, 2.1506e-02, 1.0092e-04, 7.8711e-02, 3.1605e-04, 1.5606e-03,\n",
      "         5.4704e-02, 2.3885e-06, 4.3532e-04, 3.5001e-02, 1.0134e-04, 1.0264e-03,\n",
      "         2.7607e-05, 4.7374e-05, 1.3499e-02, 1.8256e-03, 2.3566e-02, 4.7220e-03,\n",
      "         1.7754e-03, 5.3280e-02, 1.4972e-04, 5.1974e-02, 8.0774e-04, 6.0268e-06,\n",
      "         1.5922e-02, 1.6171e-05, 1.7093e-03, 3.0057e-02, 7.0029e-04, 3.2271e-03,\n",
      "         2.3708e-04, 2.2771e-03, 1.4681e-02, 3.3146e-02, 5.4460e-05, 8.3950e-06,\n",
      "         3.7514e-03, 8.5712e-03, 2.4303e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.7447]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[3.5913e-05, 6.6233e-04, 1.0162e-04, 1.2797e-02, 1.7956e-04, 1.7890e-02,\n",
      "         2.3547e-04, 3.5435e-02, 6.4347e-02, 1.8894e-04, 1.9852e-05, 8.1252e-03,\n",
      "         3.0265e-04, 3.5510e-03, 9.0699e-03, 1.1651e-03, 3.4825e-05, 4.0465e-02,\n",
      "         9.6887e-05, 1.3172e-02, 1.0134e-04, 2.0175e-05, 3.0347e-03, 4.8424e-03,\n",
      "         1.4860e-03, 1.1648e-03, 3.0555e-02, 5.5831e-05, 5.4247e-04, 2.7687e-04,\n",
      "         2.2736e-04, 5.1730e-02, 3.6221e-04, 1.8908e-03, 2.6309e-02, 5.3906e-02,\n",
      "         7.8171e-03, 5.1714e-05, 6.7144e-05, 8.2604e-02, 5.8374e-02, 1.0243e-02,\n",
      "         2.6826e-03, 2.7456e-02, 3.5023e-04, 6.0933e-02, 6.2468e-04, 3.2657e-03,\n",
      "         3.6668e-02, 1.5590e-05, 8.8826e-04, 2.9380e-02, 2.4249e-04, 1.6458e-03,\n",
      "         8.4960e-05, 1.6341e-04, 1.5849e-02, 2.4946e-03, 2.7569e-02, 5.6772e-03,\n",
      "         4.2626e-03, 4.1335e-02, 3.4240e-04, 4.3518e-02, 2.0264e-03, 3.8610e-05,\n",
      "         1.8668e-02, 7.2271e-05, 3.6464e-03, 2.7178e-02, 1.3091e-03, 5.1507e-03,\n",
      "         4.7756e-04, 3.0288e-03, 2.0045e-02, 3.0336e-02, 1.5389e-04, 4.0024e-05,\n",
      "         6.0067e-03, 9.2218e-03, 2.3613e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.6329]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[6.4296e-06, 1.7429e-04, 1.7654e-05, 9.1667e-03, 4.9809e-05, 1.3971e-02,\n",
      "         7.3455e-05, 2.7968e-02, 9.1048e-02, 4.2084e-05, 3.2496e-06, 6.2552e-03,\n",
      "         9.7653e-05, 2.0209e-03, 8.2826e-03, 4.1887e-04, 5.3339e-06, 5.4283e-02,\n",
      "         2.0189e-05, 1.4724e-02, 3.1583e-05, 2.8984e-06, 1.5065e-03, 3.9580e-03,\n",
      "         6.2383e-04, 5.5545e-04, 2.4180e-02, 1.3863e-05, 2.4408e-04, 6.0048e-05,\n",
      "         4.3841e-05, 3.9920e-02, 1.0799e-04, 1.1590e-03, 2.3217e-02, 6.0806e-02,\n",
      "         4.6156e-03, 7.7326e-06, 1.4060e-05, 9.4910e-02, 6.2295e-02, 6.3961e-03,\n",
      "         9.2606e-04, 3.4073e-02, 1.3988e-04, 9.7004e-02, 3.4839e-04, 1.9031e-03,\n",
      "         2.7591e-02, 1.5706e-06, 5.5469e-04, 3.1850e-02, 8.5165e-05, 1.0437e-03,\n",
      "         2.2709e-05, 4.0795e-05, 1.2680e-02, 1.1026e-03, 2.0354e-02, 3.5821e-03,\n",
      "         2.6026e-03, 4.4931e-02, 1.1332e-04, 3.4451e-02, 8.4713e-04, 8.9298e-06,\n",
      "         1.2165e-02, 1.1707e-05, 1.5897e-03, 2.7746e-02, 5.0430e-04, 4.1629e-03,\n",
      "         1.5060e-04, 2.0838e-03, 1.7631e-02, 2.9171e-02, 4.6166e-05, 9.0950e-06,\n",
      "         2.9464e-03, 6.2662e-03, 2.5964e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.7590]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[7.5920e-07, 5.3300e-05, 3.4624e-06, 4.8403e-03, 1.5308e-05, 9.9561e-03,\n",
      "         1.6206e-05, 2.6636e-02, 1.1517e-01, 7.5887e-06, 3.5178e-07, 3.5987e-03,\n",
      "         2.8501e-05, 1.2904e-03, 4.5854e-03, 2.0697e-04, 6.4537e-07, 4.9894e-02,\n",
      "         3.1963e-06, 9.9169e-03, 3.9591e-06, 3.1855e-07, 6.9511e-04, 2.0713e-03,\n",
      "         2.0393e-04, 1.7539e-04, 2.4126e-02, 1.9906e-06, 5.0553e-05, 1.1591e-05,\n",
      "         9.7765e-06, 4.2667e-02, 3.1633e-05, 5.5199e-04, 2.1274e-02, 5.3614e-02,\n",
      "         3.0812e-03, 8.8226e-07, 2.7383e-06, 1.2907e-01, 6.4972e-02, 4.6692e-03,\n",
      "         5.1715e-04, 2.6857e-02, 3.3481e-05, 1.0340e-01, 5.9364e-05, 7.6357e-04,\n",
      "         3.3481e-02, 1.8562e-07, 1.8843e-04, 3.1169e-02, 1.4694e-05, 3.2812e-04,\n",
      "         2.3098e-06, 9.6248e-06, 8.7720e-03, 4.4003e-04, 2.0810e-02, 1.9176e-03,\n",
      "         1.1325e-03, 4.4282e-02, 2.3830e-05, 4.9445e-02, 3.7560e-04, 1.0118e-06,\n",
      "         1.3619e-02, 1.6954e-06, 8.3998e-04, 2.1931e-02, 1.4718e-04, 2.1655e-03,\n",
      "         3.5783e-05, 9.9307e-04, 1.3828e-02, 2.9152e-02, 1.0214e-05, 8.8940e-07,\n",
      "         1.9103e-03, 4.2531e-03, 1.3580e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.0401]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[3.2476e-07, 3.3647e-05, 1.7430e-06, 7.0530e-03, 5.3425e-06, 6.8918e-03,\n",
      "         8.9567e-06, 2.8791e-02, 9.7305e-02, 5.6781e-06, 1.2944e-07, 3.1563e-03,\n",
      "         1.3812e-05, 6.2349e-04, 4.0023e-03, 1.1427e-04, 2.6615e-07, 5.7822e-02,\n",
      "         1.5385e-06, 7.8768e-03, 2.6484e-06, 1.6862e-07, 4.4140e-04, 1.5247e-03,\n",
      "         1.6505e-04, 1.3568e-04, 2.8400e-02, 9.6716e-07, 3.6301e-05, 8.9917e-06,\n",
      "         4.8610e-06, 4.6931e-02, 1.8460e-05, 2.6898e-04, 1.6413e-02, 8.2219e-02,\n",
      "         2.6629e-03, 5.6254e-07, 1.1176e-06, 1.1767e-01, 6.5125e-02, 3.1745e-03,\n",
      "         3.3465e-04, 2.7837e-02, 2.0818e-05, 1.2339e-01, 5.9797e-05, 5.8601e-04,\n",
      "         2.8425e-02, 6.3757e-08, 9.8057e-05, 2.9498e-02, 1.0994e-05, 2.6312e-04,\n",
      "         2.0346e-06, 4.8774e-06, 9.9133e-03, 3.8384e-04, 1.8923e-02, 1.3471e-03,\n",
      "         7.9291e-04, 5.5156e-02, 1.4027e-05, 2.7699e-02, 2.5299e-04, 3.6768e-07,\n",
      "         9.3729e-03, 1.1581e-06, 5.3983e-04, 1.7913e-02, 1.0116e-04, 1.5709e-03,\n",
      "         3.0037e-05, 7.2294e-04, 1.1323e-02, 2.9624e-02, 3.8717e-06, 3.9628e-07,\n",
      "         1.3741e-03, 2.8421e-03, 2.0653e-02]], grad_fn=<SoftmaxBackward0>), tensor([[-0.9109]], grad_fn=<TanhBackward0>))\n"
     ]
    }
   ],
   "source": [
    "s=State()\n",
    "print(inference_model(state_to_tensor(s)))\n",
    "s1=change_state(s,(0,0,0,0))\n",
    "s2=change_state(s,(1,1,1,1))\n",
    "\n",
    "print(inference_model(state_to_tensor(s1)))\n",
    "\n",
    "print(inference_model(state_to_tensor(s2)))\n",
    "\n",
    "s3 = torch.tensor(np.ones((9,9)),dtype=torch.float32).unsqueeze(0).unsqueeze(1).to(device)\n",
    "print(inference_model(s3))\n",
    "\n",
    "\n",
    "s3 = torch.tensor(np.identity(9),dtype=torch.float32).unsqueeze(0).unsqueeze(1).to(device)\n",
    "print(inference_model(s3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "21bc33d0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0.0075, 0.0089, 0.0076, 0.0097, 0.0064, 0.0301, 0.0132, 0.0142, 0.0232,\n",
      "         0.0073, 0.0046, 0.0184, 0.0207, 0.0106, 0.0129, 0.0115, 0.0052, 0.0167,\n",
      "         0.0099, 0.0173, 0.0065, 0.0034, 0.0077, 0.0069, 0.0080, 0.0060, 0.0095,\n",
      "         0.0078, 0.0132, 0.0083, 0.0074, 0.0180, 0.0073, 0.0109, 0.0168, 0.0231,\n",
      "         0.0131, 0.0066, 0.0053, 0.0220, 0.0129, 0.0129, 0.0117, 0.0150, 0.0079,\n",
      "         0.0225, 0.0107, 0.0134, 0.0141, 0.0042, 0.0097, 0.0150, 0.0080, 0.0108,\n",
      "         0.0055, 0.0095, 0.0232, 0.0098, 0.0244, 0.0069, 0.0176, 0.0161, 0.0114,\n",
      "         0.0302, 0.0082, 0.0067, 0.0172, 0.0077, 0.0125, 0.0283, 0.0149, 0.0194,\n",
      "         0.0061, 0.0097, 0.0246, 0.0129, 0.0108, 0.0050, 0.0082, 0.0083, 0.0124]],\n",
      "       grad_fn=<SoftmaxBackward0>), tensor([[-0.2573]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[0.0077, 0.0098, 0.0076, 0.0131, 0.0075, 0.0247, 0.0146, 0.0131, 0.0246,\n",
      "         0.0085, 0.0046, 0.0139, 0.0181, 0.0098, 0.0131, 0.0127, 0.0063, 0.0160,\n",
      "         0.0124, 0.0151, 0.0058, 0.0040, 0.0080, 0.0082, 0.0093, 0.0072, 0.0117,\n",
      "         0.0083, 0.0144, 0.0089, 0.0082, 0.0206, 0.0096, 0.0111, 0.0175, 0.0198,\n",
      "         0.0140, 0.0081, 0.0059, 0.0194, 0.0157, 0.0121, 0.0126, 0.0169, 0.0098,\n",
      "         0.0212, 0.0107, 0.0127, 0.0141, 0.0049, 0.0089, 0.0120, 0.0077, 0.0099,\n",
      "         0.0076, 0.0078, 0.0169, 0.0091, 0.0233, 0.0083, 0.0173, 0.0142, 0.0096,\n",
      "         0.0264, 0.0113, 0.0080, 0.0172, 0.0086, 0.0146, 0.0253, 0.0155, 0.0194,\n",
      "         0.0061, 0.0102, 0.0222, 0.0121, 0.0091, 0.0071, 0.0077, 0.0078, 0.0154]],\n",
      "       grad_fn=<SoftmaxBackward0>), tensor([[-0.6762]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[0.0079, 0.0103, 0.0082, 0.0109, 0.0065, 0.0242, 0.0124, 0.0162, 0.0267,\n",
      "         0.0077, 0.0043, 0.0164, 0.0212, 0.0104, 0.0127, 0.0099, 0.0056, 0.0182,\n",
      "         0.0112, 0.0201, 0.0066, 0.0038, 0.0071, 0.0085, 0.0081, 0.0068, 0.0117,\n",
      "         0.0078, 0.0125, 0.0070, 0.0066, 0.0209, 0.0076, 0.0098, 0.0151, 0.0211,\n",
      "         0.0141, 0.0062, 0.0057, 0.0172, 0.0121, 0.0140, 0.0099, 0.0167, 0.0077,\n",
      "         0.0192, 0.0105, 0.0138, 0.0131, 0.0049, 0.0110, 0.0149, 0.0088, 0.0090,\n",
      "         0.0066, 0.0100, 0.0212, 0.0094, 0.0265, 0.0067, 0.0149, 0.0150, 0.0099,\n",
      "         0.0328, 0.0089, 0.0068, 0.0174, 0.0069, 0.0140, 0.0273, 0.0177, 0.0201,\n",
      "         0.0057, 0.0092, 0.0209, 0.0131, 0.0093, 0.0067, 0.0080, 0.0098, 0.0142]],\n",
      "       grad_fn=<SoftmaxBackward0>), tensor([[-0.2101]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[0.0056, 0.0071, 0.0061, 0.0089, 0.0056, 0.0387, 0.0127, 0.0149, 0.0315,\n",
      "         0.0059, 0.0029, 0.0174, 0.0230, 0.0099, 0.0108, 0.0111, 0.0036, 0.0165,\n",
      "         0.0094, 0.0223, 0.0046, 0.0022, 0.0070, 0.0059, 0.0056, 0.0053, 0.0101,\n",
      "         0.0065, 0.0116, 0.0060, 0.0054, 0.0223, 0.0062, 0.0092, 0.0156, 0.0256,\n",
      "         0.0129, 0.0048, 0.0041, 0.0207, 0.0124, 0.0124, 0.0105, 0.0147, 0.0075,\n",
      "         0.0268, 0.0097, 0.0132, 0.0137, 0.0027, 0.0104, 0.0140, 0.0061, 0.0081,\n",
      "         0.0044, 0.0073, 0.0275, 0.0081, 0.0322, 0.0056, 0.0187, 0.0179, 0.0098,\n",
      "         0.0392, 0.0082, 0.0048, 0.0196, 0.0060, 0.0134, 0.0313, 0.0162, 0.0220,\n",
      "         0.0039, 0.0079, 0.0276, 0.0118, 0.0086, 0.0041, 0.0068, 0.0063, 0.0134]],\n",
      "       grad_fn=<SoftmaxBackward0>), tensor([[-0.4141]], grad_fn=<TanhBackward0>))\n"
     ]
    }
   ],
   "source": [
    "inference_model=UTTT()\n",
    "s=State()\n",
    "print(inference_model(state_to_tensor(s)))\n",
    "s1=change_state(s,(0,0,0,0))\n",
    "s2=change_state(s,(1,1,1,1))\n",
    "\n",
    "print(inference_model(state_to_tensor(s1)))\n",
    "\n",
    "print(inference_model(state_to_tensor(s2)))\n",
    "\n",
    "s3 = torch.tensor(np.ones((9,9)),dtype=torch.float32).unsqueeze(0).unsqueeze(1).to(device)\n",
    "print(inference_model(s3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fc11558c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6349010\n",
      "OrderedDict([('conv1.weight', tensor([[[[ 3.1599280238e-01, -1.7453873158e-01, -1.5413686633e-01],\n",
      "          [ 1.9262206554e-01, -2.7660986781e-01,  1.9655749202e-01],\n",
      "          [-1.9012737274e-01, -9.0148687363e-02,  3.2760399580e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5253325701e-01, -2.2546005249e-01, -2.3694178462e-01],\n",
      "          [ 3.9737224579e-02, -7.8327856958e-02, -1.1168801785e-01],\n",
      "          [-1.7405840755e-01,  2.2267961502e-01,  2.9447036982e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.6848883033e-01, -1.7537355423e-02,  2.0572642982e-01],\n",
      "          [ 2.1543502808e-02, -1.2507376075e-01,  5.1644644700e-03],\n",
      "          [-2.2771283984e-01, -1.4232861996e-01,  8.6099468172e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.3433628082e-02,  2.2211501002e-01,  1.9809398055e-01],\n",
      "          [ 9.6673093736e-02,  2.9852300882e-01,  5.6699715555e-02],\n",
      "          [-2.6685258746e-01, -2.0141530037e-01, -1.8569605052e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.7623476982e-02,  3.0630892515e-01,  1.6581630707e-01],\n",
      "          [-2.1793437004e-01, -1.1966534704e-01,  3.3210796118e-01],\n",
      "          [-2.0490691066e-01,  1.2726148963e-01, -2.7031251788e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6529547572e-01, -3.2547864318e-01, -1.5591359138e-01],\n",
      "          [ 2.5892210007e-01, -3.0279558897e-01, -2.4005851150e-01],\n",
      "          [-1.8493553996e-01,  2.4087819457e-01,  1.9299313426e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.7420566082e-01, -2.0323853195e-01, -3.2682061195e-01],\n",
      "          [-2.4587237835e-01, -2.6764091849e-01,  2.7328127623e-01],\n",
      "          [ 2.3840495944e-01,  4.4227879494e-02,  2.6762366295e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9493305087e-01, -1.6723017395e-01, -2.2712668777e-01],\n",
      "          [-1.0767035186e-01,  2.2390219569e-01,  1.7456361651e-01],\n",
      "          [ 1.5417933464e-01,  1.3409166038e-01,  1.1094574630e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.2488379478e-01, -3.9735000581e-02,  6.0567460954e-02],\n",
      "          [ 2.3424899578e-01, -1.9445347786e-01, -9.8684906960e-02],\n",
      "          [ 2.3232719302e-01, -7.6254211366e-02,  1.0965943336e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.2226779163e-01, -2.0166890323e-01, -1.0104235262e-01],\n",
      "          [ 2.6339006424e-01,  1.5627694130e-01, -3.2388198376e-01],\n",
      "          [ 1.4341163635e-01, -1.9694268703e-01,  1.7178313434e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3393878341e-01, -4.1535656899e-02, -3.3329653740e-01],\n",
      "          [ 2.0381598175e-01, -7.6605796814e-02,  1.3149619102e-01],\n",
      "          [-2.3429696262e-01, -2.0809996128e-01,  6.1737699434e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3433358073e-01, -2.2853760421e-01,  9.9331855774e-02],\n",
      "          [ 2.9030248523e-01,  9.2351280153e-02, -1.2532250583e-01],\n",
      "          [-2.4659857154e-01, -3.3210405707e-01,  3.2967525721e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3921074569e-01, -1.3384005427e-01,  4.6813052148e-02],\n",
      "          [-1.5470108017e-02, -2.5599559769e-02,  4.9101792276e-02],\n",
      "          [ 2.9242798686e-01, -1.6266910732e-01,  2.7035945654e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.4598378539e-01,  1.9647049904e-01,  5.5279254913e-02],\n",
      "          [ 1.1734688282e-01, -1.5224644542e-01,  1.9565653801e-01],\n",
      "          [ 1.9951479137e-01,  1.8417557701e-02, -3.1615012884e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.9602486491e-01, -3.1758973002e-01, -4.9796819687e-02],\n",
      "          [-3.4557305276e-02, -1.9369316101e-01,  1.9550959766e-01],\n",
      "          [ 1.6612529755e-01,  1.6472920775e-01,  1.8666701019e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.0802249908e-02,  1.7808437347e-01,  2.5196129084e-01],\n",
      "          [ 1.4153008163e-01,  3.1331574917e-01, -5.2033424377e-02],\n",
      "          [ 2.7738499641e-01,  1.5061295033e-01, -2.5926002860e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4765014648e-01, -1.1052966118e-01,  1.0395010561e-01],\n",
      "          [ 2.8356593847e-01, -5.6107085198e-02,  2.3381528258e-01],\n",
      "          [-2.8706300259e-01, -1.7806498706e-01, -1.9304983318e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.0654442012e-01, -1.4737546444e-01,  1.9806790352e-01],\n",
      "          [ 8.9963674545e-03, -2.8692349792e-01, -2.6456873864e-02],\n",
      "          [-2.9936200380e-01, -3.0120182037e-01, -1.8130092323e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4090692997e-01,  1.2044107914e-01,  6.4516827464e-02],\n",
      "          [-6.0142636299e-02, -1.3551823795e-01,  1.3095486164e-01],\n",
      "          [-2.8861850500e-01,  2.1166524291e-01,  1.0586361587e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.2761378251e-03,  3.0973625183e-01,  1.8878588080e-01],\n",
      "          [-2.2403085232e-01, -1.7755293846e-01, -2.4467198551e-01],\n",
      "          [ 1.0717225075e-01, -2.3150444031e-01,  1.6963021457e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1801998131e-02, -1.3652288914e-01,  2.2727096081e-01],\n",
      "          [-3.0872786045e-01,  2.8253301978e-01, -5.0794482231e-02],\n",
      "          [ 9.7177669406e-02,  2.5153756142e-01, -2.6747545600e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5035306811e-01, -7.9144082963e-02, -9.4927273691e-02],\n",
      "          [ 2.0839934051e-01,  2.2231948376e-01, -1.5698382258e-01],\n",
      "          [ 2.8003618121e-01,  2.1408002358e-03,  2.5791084766e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5664064884e-01,  2.8175275773e-02, -2.5577461720e-01],\n",
      "          [ 2.4502579868e-01, -2.3838075995e-01,  1.6267785430e-01],\n",
      "          [ 5.8099668473e-02,  1.0416471958e-01,  5.4133933038e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.4798161387e-02,  1.3186681271e-01, -6.1462521553e-02],\n",
      "          [ 1.3154236972e-01,  1.3339731097e-01,  2.1005317569e-01],\n",
      "          [-3.1590151787e-01, -1.2305160612e-01,  3.3611655235e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.0497033000e-01, -1.5236246586e-01,  1.0549108684e-01],\n",
      "          [-2.9873239994e-01,  2.3008164763e-01, -1.7008742318e-02],\n",
      "          [ 3.1317919493e-01, -3.1725472212e-01,  1.8014320731e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.3312058449e-01, -2.4415791035e-01,  3.3070737123e-01],\n",
      "          [-1.6342441738e-01,  2.5963211060e-01,  4.0040217340e-02],\n",
      "          [-2.7797621489e-01, -2.9712748528e-01, -1.5229277313e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.4652230144e-02,  1.4931368828e-01, -3.1777966022e-01],\n",
      "          [-1.4415189624e-01,  7.8360125422e-02, -2.9819637537e-01],\n",
      "          [-9.3921899796e-02, -8.8579416275e-02,  5.0041280687e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.3484637439e-01,  3.1124219298e-01,  2.2836935520e-01],\n",
      "          [ 3.0940419436e-01,  2.6455351710e-01, -3.3162436448e-03],\n",
      "          [-2.2084364295e-01, -3.3200594783e-01,  3.2882177830e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.1021676064e-02,  8.6863204837e-02, -7.5194641948e-02],\n",
      "          [-6.5125942230e-02,  1.6898855567e-01, -1.8877427280e-01],\n",
      "          [-2.7948722243e-01,  3.2932060957e-01,  3.0803799629e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.8959264755e-02, -2.2954702377e-01, -5.1056742668e-02],\n",
      "          [-1.4011725783e-01,  2.8068789840e-01,  3.1799024343e-01],\n",
      "          [ 3.6605358124e-02, -1.5806595981e-01,  8.3052873611e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3490560055e-01,  2.2324495018e-01, -1.6170224175e-02],\n",
      "          [-3.2260483503e-01,  2.5521713495e-01, -1.0558351129e-01],\n",
      "          [-4.4048946351e-02,  2.1496948600e-01, -3.0320286751e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.0626401305e-01, -1.9572183490e-01, -8.1757903099e-02],\n",
      "          [ 3.6377273500e-02,  2.9858964682e-01,  1.8706440926e-02],\n",
      "          [-1.0159727186e-01, -1.4270842075e-01,  2.7187472582e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8546807170e-01, -2.5073587894e-01, -2.6894339919e-01],\n",
      "          [ 1.6865405440e-01,  3.0137428641e-01,  1.3736848533e-01],\n",
      "          [ 2.9224061966e-01,  1.4415161312e-01, -2.6086470485e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.7635905147e-01,  2.8809595108e-01,  1.2311553955e-01],\n",
      "          [-7.6245389879e-02,  5.3118787706e-02,  1.9268767536e-01],\n",
      "          [-1.1661593616e-01,  1.5687048435e-01,  1.6361872852e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.2620942593e-01, -2.6691564918e-01, -7.4919864535e-02],\n",
      "          [-2.9817280173e-01,  2.4032247066e-01, -2.1580652893e-01],\n",
      "          [-7.5561806560e-02,  2.4229054153e-01, -2.0712456107e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.2713749111e-01,  1.1201083660e-01,  9.7411714494e-02],\n",
      "          [-2.9243016243e-01,  3.0961054564e-01, -1.3419732451e-01],\n",
      "          [ 1.9509968162e-01, -2.8205916286e-01,  2.8244623542e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.7047879100e-01,  1.2340935320e-01,  1.2566173077e-01],\n",
      "          [ 1.4997801185e-01,  2.3138806224e-01, -1.1205279827e-01],\n",
      "          [-2.3944911361e-01,  1.7498247325e-01,  3.2325181365e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3215443492e-01,  2.6921018958e-01,  2.7032097802e-02],\n",
      "          [ 2.1775805950e-01,  1.7988054454e-01, -2.4460634217e-02],\n",
      "          [ 2.4540767074e-01,  2.8367036581e-01, -1.9628886878e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8422415257e-01, -4.5804064721e-02,  7.2547361255e-02],\n",
      "          [ 1.2779673934e-01, -7.7406883240e-02, -2.6893740892e-01],\n",
      "          [ 2.9499804974e-01, -8.0275580287e-02, -3.2311338186e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.1763815582e-01,  9.7763381898e-02,  2.5602695346e-01],\n",
      "          [-1.5175426006e-01,  1.1025063694e-01, -4.3303132057e-02],\n",
      "          [ 7.7210508287e-02, -1.1928689480e-01,  1.2151690573e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7495250702e-01, -3.1544679403e-01,  2.9734298587e-01],\n",
      "          [ 1.7128834128e-01, -1.5650515258e-01,  3.3025953174e-01],\n",
      "          [-2.5937923789e-01,  2.0464062691e-01, -2.7351689339e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.1851172447e-02,  4.3401282281e-02,  5.7181041688e-02],\n",
      "          [ 2.6174184680e-01,  2.8219902515e-01, -1.7039963603e-01],\n",
      "          [-9.8541781306e-02,  1.9412903488e-01, -3.2400500774e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4452147484e-01,  1.5683345497e-01,  2.5338804722e-01],\n",
      "          [-1.7597334087e-01, -1.3562421501e-01,  1.6909122467e-02],\n",
      "          [ 1.8948869407e-01, -5.3690474480e-02, -2.5508758426e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.3247206211e-01, -2.1886138618e-01,  2.8649097681e-01],\n",
      "          [ 1.4593562111e-02,  1.2405078113e-01, -6.7469559610e-02],\n",
      "          [-8.7480664253e-02, -2.3157525063e-01, -5.4573178291e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.9857816696e-02, -2.8574371338e-01, -2.0142006874e-01],\n",
      "          [-1.8693161011e-01,  2.0986041427e-01, -2.2683331370e-01],\n",
      "          [-3.2133823633e-01,  3.1763333082e-01, -1.7027854919e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2620258331e-01, -2.8624242544e-01, -3.2496544719e-01],\n",
      "          [-2.1045359969e-01, -2.2441896796e-01, -2.2388546169e-01],\n",
      "          [-3.3244332671e-01, -6.7635498941e-02, -1.5569710732e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.0255220383e-02, -3.1827449799e-02, -2.5590142608e-01],\n",
      "          [-1.6743814945e-01, -1.5091614425e-01, -2.0236012340e-01],\n",
      "          [-1.6325458884e-01, -1.8507516384e-01, -3.0351531506e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.4896534635e-04, -4.5845112763e-03, -1.9309374690e-01],\n",
      "          [-1.9704496861e-01, -1.9098997116e-01,  1.2359794229e-01],\n",
      "          [-6.0478888452e-02,  1.0707657039e-01, -2.7175635099e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.2112886608e-01, -9.8416849971e-02, -2.6912140846e-01],\n",
      "          [ 7.0960246027e-02,  4.2748771608e-02, -2.8916132450e-01],\n",
      "          [-1.4339387417e-01,  8.7432503700e-02, -3.0235764384e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.3221834898e-01, -1.3853101432e-01,  3.1806239486e-01],\n",
      "          [ 1.3800093532e-01, -1.3722714782e-01,  5.5611453950e-02],\n",
      "          [ 2.7628955245e-01, -2.3659853637e-01, -2.2435542941e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.3379316032e-01,  1.9299793243e-01,  3.2196748257e-01],\n",
      "          [ 9.0947985649e-02, -9.9529428408e-03, -2.6406532526e-01],\n",
      "          [-1.7399200797e-01, -2.5639778376e-01, -1.4146821201e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8100611866e-01,  2.6712012291e-01,  1.5596859157e-01],\n",
      "          [-7.4370227754e-02,  1.6880655289e-01, -3.1040725112e-01],\n",
      "          [ 2.6735436916e-01, -3.0530580878e-01, -2.3997437954e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.8463015556e-01,  2.3769192398e-01, -2.3289494216e-01],\n",
      "          [-2.9959630966e-01, -2.3945808411e-02,  3.7871479988e-02],\n",
      "          [ 2.8006076813e-01, -2.3840439320e-01,  1.2031789869e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.7512341738e-01,  1.1161637306e-01, -1.9661029801e-02],\n",
      "          [-5.1896613091e-02, -3.3187922835e-01, -2.7677690983e-01],\n",
      "          [ 1.9481584430e-01,  2.4368870258e-01, -1.1292072386e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3248112202e-01, -2.7801072598e-01, -2.1152600646e-01],\n",
      "          [ 9.2165991664e-02, -2.7876481414e-01, -3.2115983963e-01],\n",
      "          [-2.6709672809e-01, -1.2301202863e-01,  5.5692952126e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8210911155e-01, -2.6839885116e-01, -2.5267499685e-01],\n",
      "          [-1.6392052174e-01, -3.1997364759e-01,  1.8119820952e-01],\n",
      "          [-1.1439903826e-01, -1.7232513428e-01,  2.9477763176e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.5608254373e-02,  1.2292146683e-02, -1.9240772724e-01],\n",
      "          [-3.0207902193e-01,  1.7699858546e-01, -9.8347947001e-02],\n",
      "          [ 2.9445347190e-01,  3.0174672604e-01, -4.7575116158e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.5254732966e-02, -5.7296197861e-02,  3.1108665466e-01],\n",
      "          [-5.7713747025e-02, -2.7971827984e-01, -1.3405239582e-01],\n",
      "          [ 3.0976209044e-01, -2.2609591484e-01, -1.4986547828e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1788403392e-01, -1.9992372394e-01, -2.0339867473e-01],\n",
      "          [ 2.0371136069e-01, -1.8164288998e-01,  2.5932240486e-01],\n",
      "          [-1.4992281795e-01,  2.3901717365e-01, -6.2439166009e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0583009720e-01,  1.4580368996e-01,  2.4593405426e-01],\n",
      "          [ 3.1699621677e-01,  1.7954063416e-01,  1.9818310440e-01],\n",
      "          [-4.6865146607e-02, -1.0614164919e-01,  3.7722349167e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.2229146361e-01,  1.4826679230e-01, -6.6334210336e-02],\n",
      "          [-1.0666513443e-01, -1.3897371292e-01,  2.5906223059e-01],\n",
      "          [-1.1193096638e-01, -4.3577075005e-02,  1.6799589992e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.0270677805e-01, -1.1519213766e-01,  3.2518023252e-01],\n",
      "          [ 3.7832699716e-02,  1.2342437357e-01,  1.8483579159e-01],\n",
      "          [-2.8099501133e-01,  2.0061485469e-01,  2.7828073502e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.7849084139e-01, -5.7212514803e-03,  7.7531382442e-02],\n",
      "          [-2.9128193855e-02,  1.8251340371e-03,  1.3653907180e-01],\n",
      "          [ 1.9654595852e-01,  2.4516102672e-01,  1.9090569019e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5774979591e-01, -2.9315346479e-01, -1.6156165302e-01],\n",
      "          [ 1.3039812446e-01,  2.0744983852e-01,  7.7767774463e-02],\n",
      "          [-2.5391691923e-01, -1.8965673447e-01, -6.0523591936e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.7599070072e-01, -2.3641797900e-01, -7.9333662987e-02],\n",
      "          [ 2.6908862591e-01, -5.2740573883e-02,  1.0660278797e-01],\n",
      "          [-2.4731521308e-01,  3.5636942834e-02,  1.3703612983e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.9087228179e-01,  1.8396811187e-01, -1.6763648391e-01],\n",
      "          [ 2.4591013789e-01,  2.5938650966e-01,  3.6650419235e-02],\n",
      "          [-2.0731100440e-01, -1.6967377067e-01,  5.2648346871e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.5603372455e-01, -2.1823911369e-01, -9.1732427478e-02],\n",
      "          [-5.7647269219e-02, -1.0692811012e-01, -2.7024877071e-01],\n",
      "          [-5.1607411355e-02,  3.2709680498e-02, -9.1631174088e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0810928047e-01,  5.5235110223e-02,  8.8923022151e-02],\n",
      "          [ 4.3424010277e-02, -2.9926380515e-01, -6.1435621232e-02],\n",
      "          [ 1.3846084476e-01,  6.8318724632e-02,  1.0010107607e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.7259927988e-01,  2.2730688751e-01, -2.6305589080e-01],\n",
      "          [-9.5229983330e-02, -2.2894649208e-01,  3.4042082727e-02],\n",
      "          [-9.4217300415e-02, -6.2724791467e-02,  3.7021756172e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.1095356941e-02, -1.9943527877e-01, -4.9420557916e-02],\n",
      "          [ 3.0320024490e-01,  3.3164173365e-01, -2.7517092228e-01],\n",
      "          [-7.7888414264e-02,  3.0041500926e-01, -2.5226855278e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.1678433418e-01,  1.9644686580e-01, -3.0563610792e-01],\n",
      "          [-1.7067115754e-02, -2.6881867647e-01,  5.1542127039e-04],\n",
      "          [ 2.7599883080e-01, -8.5651598871e-02, -8.1209227443e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.7374824509e-02, -3.0462455750e-01,  2.5084847212e-01],\n",
      "          [-1.0348288715e-01,  2.4248008430e-01, -2.2985498607e-01],\n",
      "          [-3.1782478094e-01,  2.3704314232e-01,  1.6925005615e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.9972898960e-01, -1.4781305194e-01, -1.6824910045e-01],\n",
      "          [-1.5733453631e-01,  2.7462822199e-01,  1.4728081226e-01],\n",
      "          [-6.4682684839e-02, -2.7618572116e-01,  2.0445398986e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.3574123383e-02,  1.0409180820e-01,  4.9933195114e-02],\n",
      "          [ 5.3413551301e-02, -2.8218707442e-01,  1.6794523224e-02],\n",
      "          [-1.5690097213e-01, -6.4264535904e-03, -3.7327926606e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.5267158449e-02,  6.4459130168e-02, -2.2794445977e-02],\n",
      "          [-2.1457824111e-01, -1.8119689822e-01,  1.7662084103e-01],\n",
      "          [ 6.7553721368e-02,  2.3774906993e-01,  1.6301636398e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.0284887552e-01,  3.1875404716e-01, -1.2864407897e-01],\n",
      "          [ 1.5842470527e-01, -1.8486320972e-01, -1.1062511057e-01],\n",
      "          [ 3.8850270212e-02, -2.6676830649e-01,  8.3313107491e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.8772983551e-01, -8.1519171596e-02,  1.0866546631e-01],\n",
      "          [ 2.8109973669e-01, -3.0633342266e-01, -1.9084410369e-01],\n",
      "          [ 2.3209369183e-01, -9.4916306436e-02, -2.1894881129e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.5775831938e-01,  1.4300327003e-01,  1.1278998852e-01],\n",
      "          [ 2.0999424160e-01, -1.8026098609e-01,  1.2446372211e-01],\n",
      "          [-3.0042776465e-01, -1.2229355425e-01, -1.5625286102e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.0968517065e-01, -3.1540209055e-01,  2.2155666351e-01],\n",
      "          [-2.8147715330e-01,  2.1830169857e-01,  3.0802091584e-02],\n",
      "          [ 2.1141605079e-01,  3.1234127283e-01,  1.5726971626e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.9632350802e-01,  7.1636795998e-02, -2.9201945662e-01],\n",
      "          [ 1.4673464000e-01, -5.2554130554e-02, -2.9472464323e-01],\n",
      "          [-2.6493692398e-01,  1.3271085918e-01, -1.9128915668e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.3974523544e-01, -2.5639414787e-02, -2.6824673638e-02],\n",
      "          [-1.7592255771e-01,  2.1824841201e-01,  3.2329162955e-01],\n",
      "          [ 2.3184053600e-01, -3.1428667903e-01,  2.9963725805e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5648671985e-01, -1.4589457214e-01, -1.3982820511e-01],\n",
      "          [ 2.1895170212e-01,  2.9754969478e-01, -3.1188592315e-01],\n",
      "          [ 1.5996074677e-01,  2.2554183006e-01,  3.2132226229e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.0552015305e-01, -8.9403748512e-02, -1.2941734493e-01],\n",
      "          [-3.2644468546e-01, -2.0889274776e-01,  3.4905552864e-02],\n",
      "          [ 1.5520927310e-01,  9.1421365738e-02, -2.4852900207e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.2828587294e-01,  1.6151463985e-01, -1.7717760056e-02],\n",
      "          [-2.5095474720e-01,  1.3558189385e-02, -4.1639130563e-02],\n",
      "          [ 6.0067973100e-03, -6.2980055809e-02, -1.6444210708e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0660930723e-01, -2.2733446956e-01, -2.9327115044e-02],\n",
      "          [ 2.3432800174e-01, -2.3818461597e-01,  1.0959657282e-01],\n",
      "          [-1.0881066322e-01, -1.7788204551e-01,  8.7602935731e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4940461516e-01, -1.1531683058e-01,  3.3427517861e-02],\n",
      "          [ 2.0852753520e-01, -1.1935969442e-01,  4.3518863618e-02],\n",
      "          [ 2.3026709259e-01, -2.9442951083e-01, -1.8835830688e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0896575451e-01, -2.1402582526e-01,  1.2754389644e-01],\n",
      "          [-2.5705534220e-01,  5.7754557580e-02,  2.3163506389e-01],\n",
      "          [-1.0486209393e-01, -2.1383719146e-01,  3.0309945345e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.7886137962e-01, -2.6474270225e-01,  5.9899091721e-03],\n",
      "          [-2.0925530791e-01,  2.2257408500e-01, -1.9693252444e-01],\n",
      "          [ 3.0648249388e-01, -2.1225902438e-01,  5.8005571365e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.2975069880e-01, -2.4558385834e-02,  2.5654017925e-01],\n",
      "          [-1.3173660263e-02,  2.6641675830e-01, -2.3311686516e-01],\n",
      "          [ 2.4030995369e-01,  6.3754245639e-02,  3.0726370215e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.8070718646e-01, -3.0372494459e-01, -3.2564005256e-01],\n",
      "          [ 2.0567545295e-01,  7.3210082948e-02, -1.8728980422e-01],\n",
      "          [ 1.7728722095e-01, -1.9013309479e-01,  2.3763990402e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.8902235925e-02,  3.1449151039e-01,  2.8553193808e-01],\n",
      "          [ 5.3057193756e-02, -1.1432676017e-01,  1.5602013469e-01],\n",
      "          [ 2.7352651581e-02,  1.4879608154e-01, -3.2644754648e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6461324692e-01,  1.5079915524e-01,  2.2992996871e-01],\n",
      "          [ 2.6568371058e-01,  4.8599643633e-03, -6.1157785356e-02],\n",
      "          [-8.5083290935e-02, -1.5587720275e-01,  2.2757475078e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9899024889e-03, -1.8980531394e-01, -1.1262214184e-01],\n",
      "          [ 2.3170587420e-01,  2.2718632221e-01,  3.2312613726e-01],\n",
      "          [ 2.4827675521e-01, -2.7360510826e-01,  2.8858762980e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.0240369737e-02,  1.0960452259e-01,  1.8032424152e-01],\n",
      "          [-5.2124105394e-02, -2.3021062836e-02, -2.4438218772e-01],\n",
      "          [ 2.2667536139e-01, -6.9799065590e-02,  3.1697484851e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.4415740967e-01,  2.8169679642e-01,  2.8395080566e-01],\n",
      "          [-2.7464973927e-01,  1.0717773438e-01, -2.0537436008e-01],\n",
      "          [ 1.9185941666e-02, -2.9983395338e-01,  3.0002623796e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.0727564991e-01, -1.1543893814e-01, -2.7628883719e-01],\n",
      "          [-2.4618315697e-01,  8.5363909602e-02,  2.0450291038e-01],\n",
      "          [-2.4545297027e-01, -3.1448814273e-01,  2.3105911911e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4151059985e-01, -5.9057078324e-03, -5.8733701706e-02],\n",
      "          [ 3.9177341387e-03, -1.1465895176e-01,  2.4051229656e-01],\n",
      "          [ 1.7087352276e-01, -8.3436056972e-02,  1.7098280787e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.2899065912e-02, -2.5112271309e-01,  2.3653814197e-01],\n",
      "          [-2.4899518490e-01,  1.4949278533e-01,  2.3414258659e-01],\n",
      "          [ 1.1128537357e-01, -2.7804598212e-01, -2.7476167679e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.1166324019e-01,  1.0789601505e-01,  9.3058191240e-02],\n",
      "          [-2.4614147842e-01, -3.0911144614e-01, -2.9780206084e-01],\n",
      "          [ 2.4321314692e-01,  3.1585198641e-01,  1.8313984573e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3572759330e-01,  2.6013335213e-02, -9.6167847514e-02],\n",
      "          [-2.4441099167e-01, -1.5328685753e-02, -2.6448401809e-01],\n",
      "          [ 2.7199655771e-01,  2.3818942904e-01,  3.0855637789e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4490962029e-02,  8.1837698817e-02,  2.3470720649e-01],\n",
      "          [-1.7009660602e-01, -3.1321245432e-01, -2.2288417816e-01],\n",
      "          [ 4.6632690355e-03,  2.8146454692e-01,  2.4792604148e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.9525430650e-02, -1.3197788596e-01, -6.7627511919e-02],\n",
      "          [ 1.6313910484e-02,  1.4260487258e-01,  2.9365584254e-01],\n",
      "          [ 2.9139399529e-01,  1.2266623974e-01,  7.6461955905e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9351181388e-01,  1.8779198825e-01,  7.0563954068e-04],\n",
      "          [ 6.7878169939e-03,  3.3255618066e-02,  1.3764254749e-01],\n",
      "          [-2.7995091677e-01,  9.6176385880e-02, -2.3404726386e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2799064815e-01, -1.5137743950e-01, -3.0394142866e-01],\n",
      "          [-1.0085602850e-01, -6.3524805009e-02, -6.6645070910e-02],\n",
      "          [-7.6727032661e-02, -2.9972618818e-01, -8.9078865945e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.1648778915e-01, -2.7209532261e-01, -2.3381023109e-01],\n",
      "          [-2.4102425575e-01, -2.6524132490e-01,  4.7815642320e-03],\n",
      "          [-3.0544647574e-01,  1.0841159523e-01, -3.0175966024e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3520201668e-02, -2.5770121813e-01,  8.7745986879e-02],\n",
      "          [-2.1986421943e-01, -2.0263993740e-01,  1.4554028213e-01],\n",
      "          [ 9.8132774234e-02,  8.7230682373e-02,  7.6551675797e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.0445775986e-01,  1.3442823291e-01, -2.0657610893e-01],\n",
      "          [ 1.3590633869e-01, -3.6018174142e-02, -2.9741644859e-01],\n",
      "          [ 2.9893708229e-01,  1.3881973922e-01,  3.2331484556e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.6774901748e-01, -1.4196988940e-01,  2.1194009483e-01],\n",
      "          [ 2.7095204592e-01,  6.5473720431e-02, -2.4901811779e-01],\n",
      "          [-1.7033490539e-01,  2.9088184237e-01,  3.1614181399e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6407024264e-01,  3.2981681824e-01,  1.1424633116e-01],\n",
      "          [-7.0334792137e-02, -2.0901004970e-01,  2.6389098167e-01],\n",
      "          [ 1.3821125031e-02, -2.1911501884e-01,  2.8770774603e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1608346552e-01,  2.6598829031e-01,  3.0503544211e-01],\n",
      "          [-2.2084435448e-02, -3.1923374534e-01,  1.4638563991e-01],\n",
      "          [ 2.0454590023e-01, -1.8029341102e-01,  1.1573128402e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.6068980098e-01,  2.7687296271e-01, -1.5789572895e-01],\n",
      "          [ 1.5716581047e-01,  3.1438165903e-01,  1.6412553191e-01],\n",
      "          [ 1.2430290878e-01, -1.2646834366e-02, -7.2212859988e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.8716735840e-02, -9.9592089653e-02,  1.4908036590e-01],\n",
      "          [-1.0070395470e-01, -1.6865496337e-01, -2.9820114374e-01],\n",
      "          [ 3.0231305957e-01,  1.5489673615e-01,  1.9131660461e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4871787056e-02, -1.5292474627e-01,  1.4167122543e-01],\n",
      "          [-5.0506513566e-02, -2.2002598643e-01, -2.7930054069e-01],\n",
      "          [-1.1662892997e-01,  9.0822979808e-02, -1.9119863212e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8103634715e-01, -6.3970886171e-02, -1.2246362865e-01],\n",
      "          [-1.2242953293e-02,  1.2875346839e-01,  5.6112527847e-02],\n",
      "          [ 2.8223428130e-01, -5.6396167725e-02,  1.1421009153e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.7579257488e-01,  2.7025779709e-02,  2.5643372536e-01],\n",
      "          [ 2.1504592896e-01, -1.7985522747e-01,  3.0548200011e-01],\n",
      "          [ 2.3734001815e-01, -2.3594042659e-01,  9.1646075249e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.5450950861e-01, -2.9431229830e-01, -1.8746614456e-01],\n",
      "          [ 2.2050301731e-01,  2.6916250587e-01, -1.0203441232e-01],\n",
      "          [-1.7696508765e-01,  1.1950795352e-01,  8.5077807307e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4871375263e-01, -2.3289000988e-01, -2.2459828854e-01],\n",
      "          [ 3.5821359605e-02,  2.1168684959e-01, -1.1641605943e-01],\n",
      "          [-2.9348012805e-01,  2.3839268088e-01, -1.5041713417e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.1983405948e-01, -1.6399964690e-01, -2.5671428442e-01],\n",
      "          [-1.8369469047e-01,  2.9610842466e-01, -1.1818365753e-01],\n",
      "          [ 1.5706551075e-01, -4.9080334604e-02,  1.9773209095e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2837347388e-01, -2.1220600605e-01,  1.1270551383e-01],\n",
      "          [-1.6414746642e-01, -3.0191224813e-01,  2.9011303186e-01],\n",
      "          [-1.0406272113e-01, -9.1617345810e-02, -1.7463204265e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.1819095612e-02,  2.9198300838e-01,  9.2241525650e-02],\n",
      "          [ 2.9448121786e-01, -1.1513106525e-01,  1.9560086727e-01],\n",
      "          [-1.9486224651e-01, -2.0477125049e-01,  2.8171825409e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3269853592e-01, -2.8270781040e-01,  1.3121990860e-01],\n",
      "          [-1.3236448169e-01,  3.0269813538e-01, -2.1750140190e-01],\n",
      "          [ 2.6672440767e-01,  2.5816130638e-01,  3.0398142338e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7789849639e-01,  4.2284332216e-02,  3.0838233232e-01],\n",
      "          [-1.3394531608e-01, -2.0580951869e-01,  3.0585393310e-01],\n",
      "          [ 1.8124127388e-01, -1.7953431606e-01, -3.6762516946e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.4933438301e-02,  7.0134043694e-02,  3.1075030565e-01],\n",
      "          [-4.3853124953e-04, -1.4948329329e-01, -2.5911554694e-01],\n",
      "          [ 2.6866227388e-01, -7.3599576950e-02, -2.4258546531e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0968353748e-01, -2.1608321369e-01, -4.1312895715e-02],\n",
      "          [ 2.5961539149e-01,  1.2526087463e-01,  2.6910302043e-01],\n",
      "          [-2.9036879539e-02, -2.7253553271e-01, -1.0780863464e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.0546301603e-01, -1.3203990459e-01, -1.6102604568e-01],\n",
      "          [-3.2669708133e-01, -2.2934120148e-02, -2.2424714267e-01],\n",
      "          [-3.3189058304e-02,  4.4442176819e-02,  8.4068857133e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.0941379070e-01, -1.9939741469e-04,  2.0892295241e-01],\n",
      "          [ 6.2764763832e-02,  3.2131704688e-01, -5.1108323038e-02],\n",
      "          [ 1.4611136913e-01,  3.0697685480e-01,  2.9978001118e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.8599414825e-01, -1.7505535483e-01, -1.1409497261e-01],\n",
      "          [-1.1709436029e-01, -3.0892223120e-01,  9.1802798212e-02],\n",
      "          [-1.3437792659e-01, -2.2789053619e-01,  2.1403023601e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.6997802258e-01,  1.0408890247e-01, -9.3773648143e-02],\n",
      "          [-1.7492842674e-01, -2.4472598732e-01,  1.2726983428e-01],\n",
      "          [ 5.7464681566e-02,  3.6097049713e-02,  3.0993660912e-02]]]])), ('bn1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])), ('bn1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])), ('bn1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])), ('bn1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])), ('bn1.num_batches_tracked', tensor(0)), ('conv2.weight', tensor([[[[ 1.9554803148e-03, -2.8960613534e-02, -2.1092204377e-02],\n",
      "          [ 1.5231315978e-02,  9.1254357249e-03,  6.8947817199e-03],\n",
      "          [-2.2111656144e-02, -9.3130981550e-03,  3.1259721145e-03]],\n",
      "\n",
      "         [[-2.2157968488e-03,  1.4507113956e-02,  2.5598660577e-03],\n",
      "          [ 2.9277871363e-03,  2.8670288157e-03,  8.9562721550e-03],\n",
      "          [-2.7845860459e-03, -2.1535504609e-02, -2.8119387105e-02]],\n",
      "\n",
      "         [[-1.6976105049e-02, -2.8193024918e-02, -1.8349543680e-03],\n",
      "          [ 2.4567304179e-02,  1.1927730404e-02,  2.3752607405e-02],\n",
      "          [ 1.4599211514e-02, -1.2643875554e-02, -2.8232365847e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.1498916000e-03,  2.3319657892e-02, -8.6186686531e-03],\n",
      "          [ 2.5615457445e-02,  2.1510722116e-02, -2.4010641500e-02],\n",
      "          [-2.7883315459e-02,  1.5588064678e-02, -2.7121353894e-02]],\n",
      "\n",
      "         [[-1.5263062902e-02, -2.5361725129e-03,  1.8321994692e-02],\n",
      "          [-6.0521713458e-03, -1.8816689029e-02,  2.5464911014e-02],\n",
      "          [-2.1407466382e-02, -4.1827936657e-03, -2.3103065789e-02]],\n",
      "\n",
      "         [[ 9.5232138410e-03,  4.2186924256e-03, -1.8306616694e-02],\n",
      "          [-2.0209122449e-02, -5.5311312899e-03, -2.5970065966e-02],\n",
      "          [ 2.8009120375e-02,  2.9136352241e-02, -8.1168860197e-04]]],\n",
      "\n",
      "\n",
      "        [[[-8.4295561537e-03,  9.8268641159e-03, -4.6538938768e-03],\n",
      "          [-7.4333520606e-03,  1.9039863721e-02, -2.6352068409e-02],\n",
      "          [-1.6555598006e-02, -1.1910155416e-02, -2.8022702318e-03]],\n",
      "\n",
      "         [[ 8.3418870345e-03, -8.5596737335e-05, -2.5317110121e-02],\n",
      "          [-2.3400934413e-02, -3.5093924962e-03,  2.4263096973e-02],\n",
      "          [ 1.8327401951e-02,  1.8021538854e-02, -2.3216264322e-02]],\n",
      "\n",
      "         [[-1.9997416064e-02, -1.6479192302e-02,  8.0256769434e-03],\n",
      "          [-1.4883499593e-02, -4.0082954802e-03, -2.6974475477e-03],\n",
      "          [-1.4533445239e-02,  1.6779426485e-02,  3.2309351955e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.7019774579e-03,  6.4028967172e-03, -1.1242889799e-02],\n",
      "          [-2.9112471268e-02, -9.5747737214e-03, -5.9879925102e-03],\n",
      "          [-1.6960488865e-03, -1.1930263136e-03,  2.0245894790e-02]],\n",
      "\n",
      "         [[-1.2684898451e-02, -9.8829828203e-03,  2.6359068230e-02],\n",
      "          [-2.1566323936e-02, -1.3370659202e-02,  3.2051377930e-03],\n",
      "          [-1.7922371626e-02,  1.6836384311e-02, -1.8249465153e-02]],\n",
      "\n",
      "         [[-2.0045351237e-02,  1.0134086944e-02,  2.1483127493e-03],\n",
      "          [ 1.1504077353e-02, -1.1947690509e-02, -3.9691445418e-03],\n",
      "          [-9.8892729729e-03,  3.2579549588e-03,  2.4900916964e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.1823544353e-03,  1.9023243338e-02, -1.6047269106e-02],\n",
      "          [ 2.3781457916e-02, -1.4211973175e-02, -1.2332470156e-02],\n",
      "          [-5.3693926893e-03, -2.1973526105e-02, -7.5464742258e-03]],\n",
      "\n",
      "         [[ 7.9026044114e-04,  1.1720813811e-02,  2.1308744326e-02],\n",
      "          [ 2.3347534239e-02, -6.7220889032e-03, -8.2085868344e-03],\n",
      "          [-1.4872958884e-02, -2.6655605063e-02,  1.4336099848e-02]],\n",
      "\n",
      "         [[-2.3309634998e-02, -3.4751761705e-03, -9.3411849812e-03],\n",
      "          [ 1.2537893839e-02,  1.8393175676e-02,  2.8464857489e-02],\n",
      "          [-1.1198628927e-03, -1.0192347690e-02,  1.7693001777e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.1714624539e-03,  1.5050639398e-02,  1.7991814762e-02],\n",
      "          [ 2.7550621890e-03, -1.8017321825e-02, -2.2086830810e-02],\n",
      "          [ 2.5454167277e-02, -9.9955257028e-03, -7.8347306699e-03]],\n",
      "\n",
      "         [[ 1.3187029399e-02, -2.2132514045e-02,  2.0342173055e-02],\n",
      "          [-1.3157424517e-02,  1.9048985094e-02,  4.5516630635e-03],\n",
      "          [-3.2022718806e-03,  1.7672967166e-02,  2.0888758823e-02]],\n",
      "\n",
      "         [[-1.0700481012e-02,  1.6496118158e-02,  2.5931933895e-02],\n",
      "          [-1.4197106473e-02,  1.7769774422e-02, -1.3476763852e-02],\n",
      "          [-6.7015280947e-03,  2.8633041307e-02, -2.3371601477e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 5.8700549416e-03, -1.1650320143e-02,  2.7732998133e-02],\n",
      "          [ 3.8797156885e-03,  2.3237964138e-02, -2.3859154899e-03],\n",
      "          [ 1.4163581654e-02, -2.7256585658e-02, -5.2736420184e-03]],\n",
      "\n",
      "         [[-2.8653616086e-02,  1.8958210945e-02, -2.1738033742e-02],\n",
      "          [ 7.9187992960e-03, -1.8108980730e-02, -1.6607414931e-02],\n",
      "          [-1.1581919156e-02, -2.8973942623e-02, -1.6429709271e-02]],\n",
      "\n",
      "         [[ 1.3071728870e-02, -1.8545666710e-02,  2.3713460192e-02],\n",
      "          [-1.1368690990e-02, -2.1352261305e-02,  2.0711323246e-02],\n",
      "          [-1.0860743932e-02, -2.4344503880e-02, -1.0205044411e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.1938242018e-02,  8.0348327756e-03, -2.0898373332e-03],\n",
      "          [-2.5417657569e-02, -2.1456433460e-03, -1.1041550897e-02],\n",
      "          [-1.2706231326e-02,  1.1953011155e-02, -1.4792711474e-02]],\n",
      "\n",
      "         [[ 8.9705139399e-03, -7.5941667892e-03, -1.1497632600e-02],\n",
      "          [-1.0243320838e-02,  1.2282009237e-02, -2.7970615774e-02],\n",
      "          [-1.7346976092e-03,  1.1227049865e-02,  2.2878721356e-02]],\n",
      "\n",
      "         [[ 1.5380933881e-02, -2.6803070679e-02,  2.2988254204e-02],\n",
      "          [-1.2363689952e-02,  9.7280964255e-03, -2.3299213499e-02],\n",
      "          [ 1.4130946249e-02, -5.3710537031e-04, -8.7168952450e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8436724097e-03,  3.3669711556e-03,  2.4552397430e-02],\n",
      "          [-2.5485437363e-02,  3.7176893093e-03, -1.5907625493e-04],\n",
      "          [ 1.6862919554e-02,  2.7553113177e-02, -1.5638515353e-02]],\n",
      "\n",
      "         [[-1.9627405331e-02, -2.3449452128e-03,  5.7093910873e-03],\n",
      "          [-7.3111434467e-03, -2.7848768979e-02, -1.2164395303e-02],\n",
      "          [-6.5293265507e-03, -1.0839586146e-02,  1.4816113748e-02]],\n",
      "\n",
      "         [[-1.7736425623e-02,  2.2954033688e-02,  2.4356495589e-02],\n",
      "          [-8.3188358694e-03,  6.1592492275e-03, -8.6099654436e-03],\n",
      "          [ 2.0179025829e-02, -1.0007491335e-02,  6.9910627790e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.4167507887e-02,  1.8544146791e-02,  2.0509310067e-02],\n",
      "          [ 2.5396373123e-02,  7.7359415591e-03, -1.3350572437e-02],\n",
      "          [-2.5173442438e-02,  2.5892565027e-03,  2.1431883797e-03]],\n",
      "\n",
      "         [[-2.8359979391e-02, -1.6217401251e-02,  1.5955876559e-02],\n",
      "          [ 4.6086912043e-03, -2.5204075500e-02, -1.8988057971e-02],\n",
      "          [ 4.3716360815e-03, -1.7339061946e-02, -1.1219578795e-02]],\n",
      "\n",
      "         [[-1.3491280377e-02,  9.7581436858e-03,  1.3328202767e-03],\n",
      "          [-1.0519179516e-02, -1.8369957805e-02, -1.4540030621e-02],\n",
      "          [ 9.3637937680e-03,  9.7916433588e-03, -1.8061267212e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.6628783196e-02, -2.3462222889e-02,  8.8260984048e-03],\n",
      "          [ 1.7863549292e-02, -1.4008327387e-02, -1.1026633903e-02],\n",
      "          [ 1.8322519958e-02, -2.3768950254e-02, -1.2981791515e-03]],\n",
      "\n",
      "         [[-2.5076752529e-02, -2.3906933144e-02, -8.4526771680e-03],\n",
      "          [-2.3971230257e-03, -2.8191827238e-02, -6.2588630244e-03],\n",
      "          [ 4.5218826272e-03, -2.6584856212e-02, -1.1089215055e-02]],\n",
      "\n",
      "         [[-1.6774958000e-02, -8.9851109078e-04, -1.7004461959e-02],\n",
      "          [-1.6250912100e-02, -3.3247084357e-03, -8.9784488082e-03],\n",
      "          [ 1.3673259877e-02,  1.8532725051e-02,  2.8879933525e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2849777006e-02,  9.7358692437e-03, -1.2075254694e-02],\n",
      "          [-7.5747403316e-03,  3.9610066451e-03, -2.6751851663e-02],\n",
      "          [ 2.1544011310e-02, -4.1461996734e-03, -1.1663157493e-03]],\n",
      "\n",
      "         [[-1.9961368293e-02,  2.5195000693e-02,  8.1458901986e-03],\n",
      "          [ 2.5414539501e-02, -2.1111454815e-02, -3.6870026961e-03],\n",
      "          [-2.3312876001e-02,  1.0593420826e-02,  2.4982606992e-02]],\n",
      "\n",
      "         [[-1.0824620724e-02,  1.4760508202e-02, -5.8851647191e-03],\n",
      "          [ 6.7219026387e-03,  1.0906255804e-02,  1.2090600096e-02],\n",
      "          [ 8.9462408796e-03, -2.7647875249e-02, -7.0846006274e-03]]]])), ('bn2.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])), ('bn2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])), ('bn2.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])), ('bn2.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])), ('bn2.num_batches_tracked', tensor(0)), ('conv3.weight', tensor([[[[-1.7068712041e-02,  5.4702712223e-03,  1.3169390149e-02],\n",
      "          [ 4.8263864592e-03,  1.8386250362e-02,  2.7821907774e-02],\n",
      "          [-6.7959474400e-03,  4.2323828675e-03, -1.4696581289e-02]],\n",
      "\n",
      "         [[-9.1413455084e-03, -1.0672410950e-02,  5.3258654661e-03],\n",
      "          [ 2.4929804727e-02, -9.4355028123e-03,  2.1421549842e-02],\n",
      "          [-2.3870004341e-02,  1.5964481980e-02, -6.1284820549e-03]],\n",
      "\n",
      "         [[-2.2837709635e-02,  1.3909095898e-02,  4.2942618020e-03],\n",
      "          [ 2.6683960110e-02,  4.7464058734e-03,  2.7936371043e-03],\n",
      "          [ 2.8807610273e-02, -2.2853858769e-02,  2.1938628051e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9863096997e-02,  6.8158796057e-03,  2.0813107491e-02],\n",
      "          [ 2.3006612435e-02, -4.4545708079e-05, -1.0168064386e-02],\n",
      "          [ 2.3097522557e-02,  1.1899073608e-02,  9.6421483904e-03]],\n",
      "\n",
      "         [[ 2.4480385706e-02, -1.2169945054e-02,  1.4672761783e-02],\n",
      "          [ 2.1500062197e-02,  6.3077113591e-03, -2.1822953597e-02],\n",
      "          [ 1.7567772418e-02, -9.3835042790e-03,  1.3619719539e-03]],\n",
      "\n",
      "         [[-2.4542622268e-02, -2.4314407259e-02, -2.4586511776e-02],\n",
      "          [ 2.7586854994e-02,  8.1264320761e-03, -2.5218401104e-02],\n",
      "          [-2.6406180114e-02, -1.4713057317e-02, -1.0631802492e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.7295822501e-02, -2.5506591424e-02,  2.0655853674e-02],\n",
      "          [-9.2313922942e-03, -2.4863138795e-02, -2.2961361334e-02],\n",
      "          [ 2.1475529298e-02, -1.3507116586e-02,  1.0836252943e-02]],\n",
      "\n",
      "         [[ 1.2654706836e-02,  2.6255583391e-02,  5.4378248751e-03],\n",
      "          [ 2.7569223195e-02,  2.0931642503e-02,  1.9330788404e-02],\n",
      "          [ 1.6715152189e-02,  2.3194875568e-02,  1.9177835435e-02]],\n",
      "\n",
      "         [[ 1.6903517768e-02,  5.2718333900e-03,  2.3489043117e-02],\n",
      "          [ 1.3494782150e-02, -2.3994555697e-02, -8.9226560667e-03],\n",
      "          [-4.0400740691e-03,  7.0436904207e-03, -2.0876271650e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1644025333e-02,  2.5210464373e-02, -1.3899788260e-02],\n",
      "          [-2.1959491074e-02, -1.7417715862e-02,  1.3645214029e-02],\n",
      "          [-5.6498586200e-03,  1.7329709604e-02, -2.1961806342e-02]],\n",
      "\n",
      "         [[ 9.4242673367e-03, -1.9873868674e-02,  2.2358538583e-02],\n",
      "          [ 1.9908482209e-02,  2.5418462232e-02,  2.9240433127e-02],\n",
      "          [-8.9870039374e-03,  1.2422291562e-02,  3.5933488980e-03]],\n",
      "\n",
      "         [[-9.3011424178e-04, -1.4493816532e-02,  5.0142174587e-03],\n",
      "          [ 1.1541239917e-02, -2.8178149834e-02, -7.1227052249e-03],\n",
      "          [ 2.1908016875e-02, -2.1700298414e-02,  3.4835003316e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1459819749e-02, -2.6133662090e-02,  2.3569181561e-02],\n",
      "          [ 1.9890256226e-03, -1.2571635656e-02, -8.3731357008e-03],\n",
      "          [-6.3244928606e-03,  4.4093187898e-03,  3.6087958142e-03]],\n",
      "\n",
      "         [[-1.6608985141e-02,  1.0836713016e-02, -1.5580380335e-02],\n",
      "          [-2.8665779158e-02,  9.8043791950e-03, -2.4676803499e-02],\n",
      "          [ 2.5979485363e-02, -2.0737685263e-02, -3.0227369280e-04]],\n",
      "\n",
      "         [[-9.5973992720e-03, -1.0017821565e-02,  8.8595272973e-03],\n",
      "          [-9.6763260663e-03, -4.6998690814e-03,  2.4557668716e-02],\n",
      "          [ 4.4106221758e-03,  1.1099418625e-02, -2.3793473840e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.9020240288e-03, -1.1319151148e-02,  2.1231896244e-03],\n",
      "          [-8.8922120631e-03,  2.3730330169e-02,  8.7515581399e-03],\n",
      "          [ 1.3913426548e-02, -1.9266739488e-02, -2.4010978639e-02]],\n",
      "\n",
      "         [[ 2.1638082340e-02, -8.7959310040e-03, -2.1589400247e-02],\n",
      "          [ 2.0544685423e-02, -1.9059110433e-02, -1.7204189673e-02],\n",
      "          [ 1.0772460140e-02, -3.5286571365e-03, -2.8538534418e-02]],\n",
      "\n",
      "         [[-3.6301009823e-03, -1.8691452220e-02,  1.1075605638e-02],\n",
      "          [ 2.0489584655e-02, -2.4806898087e-02, -2.1298818290e-02],\n",
      "          [-7.0619890466e-03,  1.0369635187e-02,  2.5596279651e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.7740918323e-02,  1.5894239768e-02,  3.1367018819e-03],\n",
      "          [-2.8902966529e-02,  5.5351350456e-03,  5.2527966909e-04],\n",
      "          [-1.3729353435e-02,  1.0838982649e-02, -9.6770534292e-03]],\n",
      "\n",
      "         [[-1.9843673334e-02, -1.0337213986e-02,  8.1800399348e-03],\n",
      "          [-2.8808971867e-02, -1.1001265608e-02, -7.7049531974e-03],\n",
      "          [ 2.8481930494e-02,  1.3896528631e-02,  2.6229690760e-02]],\n",
      "\n",
      "         [[ 2.5462850928e-02, -2.0356839523e-02,  1.5373256058e-02],\n",
      "          [-1.8059773371e-02, -5.7617900893e-03, -2.0922882482e-02],\n",
      "          [-2.2573219612e-02, -1.8134580925e-02,  7.8078373335e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9701136276e-02, -2.5789044797e-02, -2.2057348862e-02],\n",
      "          [-4.8501435667e-03, -1.6060924158e-02,  1.4848566614e-02],\n",
      "          [ 1.2073884718e-02, -2.4587980006e-03, -1.7222484574e-02]],\n",
      "\n",
      "         [[-1.3818087056e-02,  1.1474668980e-02,  1.2664039386e-03],\n",
      "          [-1.0812844150e-02, -3.9194319397e-03, -2.3190706968e-02],\n",
      "          [-5.4981126450e-03,  9.4404239208e-03,  2.1709842607e-02]],\n",
      "\n",
      "         [[-8.0253221095e-03, -1.2275764719e-02,  1.5375054441e-02],\n",
      "          [ 1.4777605422e-02,  2.8707975522e-02, -1.9079638645e-02],\n",
      "          [ 2.2747486830e-02, -1.9467569888e-02,  6.5761692822e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8399251625e-02,  2.6087693870e-02, -1.3102468103e-02],\n",
      "          [ 3.4046575893e-03, -2.6592927054e-02, -1.8469732022e-03],\n",
      "          [ 2.6159947738e-02, -2.2110482678e-03,  2.8763193637e-02]],\n",
      "\n",
      "         [[ 6.8995938636e-03, -2.8384413570e-02, -1.4778932557e-02],\n",
      "          [ 2.8569642454e-02,  7.1372841485e-03,  2.4844173342e-02],\n",
      "          [-2.8650550172e-02, -1.6781754792e-02, -7.4165809201e-04]],\n",
      "\n",
      "         [[ 4.9137044698e-03, -1.9450794905e-02,  2.0354038104e-02],\n",
      "          [-2.0248997025e-03,  2.1823719144e-02, -1.5842588618e-02],\n",
      "          [-2.1058522165e-02, -1.1357834563e-02, -1.0332521051e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.5272372924e-03,  1.2933462858e-02,  8.2651376724e-03],\n",
      "          [-1.4377259649e-02, -6.8273963407e-03,  4.2157419957e-03],\n",
      "          [ 1.9846579060e-02, -2.2043574601e-02,  8.7144998834e-03]],\n",
      "\n",
      "         [[-1.1377640069e-02,  8.0417385325e-03, -9.1066733003e-03],\n",
      "          [ 8.2227587700e-03,  2.6334756985e-03,  2.5203658268e-02],\n",
      "          [ 1.6648897901e-02,  2.4880696088e-02, -2.0094910637e-02]],\n",
      "\n",
      "         [[ 2.6253191754e-02, -3.1838151626e-03, -2.3400327191e-02],\n",
      "          [-1.1458031833e-02, -1.3081992045e-02, -9.5812361687e-03],\n",
      "          [ 2.0141115412e-02, -1.4479219913e-02, -2.6328124106e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5537063591e-02, -4.2422735132e-03, -2.0051511005e-02],\n",
      "          [-1.9111935049e-02, -3.8902243250e-04, -7.5058867224e-03],\n",
      "          [ 2.4891708046e-02,  9.3678217381e-03, -2.0235443488e-02]],\n",
      "\n",
      "         [[ 5.5943513289e-03, -2.0229468122e-02,  1.2352131307e-02],\n",
      "          [ 6.4312578179e-03,  1.4537407085e-02, -2.8248345479e-02],\n",
      "          [-1.1157752946e-02, -8.9193405584e-03,  1.4452825300e-02]],\n",
      "\n",
      "         [[ 1.2573068962e-02,  5.5547123775e-03,  1.9502069801e-02],\n",
      "          [ 1.5847738832e-02,  2.1148305386e-02,  2.4358553812e-02],\n",
      "          [ 2.8179092333e-02,  7.6280245557e-03, -1.3572767377e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.1213967353e-02,  1.9182017073e-02,  1.1587485671e-02],\n",
      "          [ 1.3210466132e-02,  2.6252814569e-03, -2.9394816607e-02],\n",
      "          [ 1.7082149163e-02, -3.3033471555e-03, -2.8365580365e-02]],\n",
      "\n",
      "         [[ 2.9187630862e-02, -1.0403478518e-02, -2.6382217184e-02],\n",
      "          [ 2.6742968708e-02, -1.0312223807e-02,  2.1360866725e-02],\n",
      "          [-2.4827085435e-02,  2.0748676732e-02,  2.2424867377e-02]],\n",
      "\n",
      "         [[ 2.7959983796e-02, -1.9289776683e-02,  1.8883930519e-02],\n",
      "          [-7.8170951456e-03, -1.0641534813e-02, -2.5876620784e-03],\n",
      "          [-5.1700202748e-03, -9.6041075885e-03,  1.1684026569e-02]]]])), ('bn3.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])), ('bn3.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])), ('bn3.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])), ('bn3.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])), ('bn3.num_batches_tracked', tensor(0)), ('res2.conv1.weight', tensor([[[[ 0.0146654248,  0.0286659189, -0.0065186671],\n",
      "          [ 0.0017763422, -0.0126068806,  0.0286576375],\n",
      "          [ 0.0011020312,  0.0257265028,  0.0077931876]],\n",
      "\n",
      "         [[ 0.0112878177, -0.0158895999,  0.0186426919],\n",
      "          [ 0.0271676239, -0.0017615311, -0.0211964194],\n",
      "          [-0.0219682232, -0.0113317212, -0.0224695075]],\n",
      "\n",
      "         [[ 0.0188225787, -0.0166469757,  0.0228314959],\n",
      "          [-0.0240129139,  0.0191501789, -0.0099376086],\n",
      "          [ 0.0236090627,  0.0125386976,  0.0039347699]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0186582487,  0.0158635993,  0.0235447995],\n",
      "          [-0.0293739513, -0.0020763117,  0.0167631824],\n",
      "          [-0.0224260390,  0.0029531664, -0.0155476071]],\n",
      "\n",
      "         [[-0.0157243777,  0.0053407890,  0.0024752247],\n",
      "          [-0.0053906417,  0.0206528548,  0.0147243384],\n",
      "          [ 0.0279343482, -0.0043510264,  0.0068275719]],\n",
      "\n",
      "         [[-0.0181565396, -0.0085428040, -0.0248517320],\n",
      "          [-0.0247162599, -0.0229636263,  0.0133878058],\n",
      "          [ 0.0078803934, -0.0267586093,  0.0226808414]]],\n",
      "\n",
      "\n",
      "        [[[-0.0133943073, -0.0258524213,  0.0020538580],\n",
      "          [ 0.0093322219,  0.0279139951, -0.0049482509],\n",
      "          [-0.0041752071, -0.0183032807,  0.0093537904]],\n",
      "\n",
      "         [[ 0.0271674450,  0.0110944239,  0.0198790319],\n",
      "          [ 0.0236362796, -0.0038910462, -0.0110177519],\n",
      "          [-0.0032135181,  0.0282780565, -0.0208987370]],\n",
      "\n",
      "         [[-0.0105432384, -0.0124495188,  0.0169349089],\n",
      "          [ 0.0049074981,  0.0009659074,  0.0153398300],\n",
      "          [-0.0234749597,  0.0177992359,  0.0231681373]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0098752528, -0.0251756366,  0.0167603232],\n",
      "          [ 0.0186319035,  0.0063171736, -0.0239965394],\n",
      "          [ 0.0092288880,  0.0008358177, -0.0264125522]],\n",
      "\n",
      "         [[-0.0150425546,  0.0171755124, -0.0232904460],\n",
      "          [ 0.0172737520,  0.0127857979,  0.0093409847],\n",
      "          [ 0.0245089307, -0.0227531269, -0.0075567402]],\n",
      "\n",
      "         [[-0.0247461982,  0.0265599787, -0.0162207093],\n",
      "          [ 0.0255548768, -0.0216815937, -0.0046929987],\n",
      "          [-0.0230123550,  0.0202528704,  0.0276955161]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0149232438, -0.0285797752, -0.0071033384],\n",
      "          [ 0.0131372502, -0.0101418803, -0.0174986310],\n",
      "          [-0.0011253631,  0.0075402260, -0.0126408618]],\n",
      "\n",
      "         [[-0.0038393848,  0.0110519538, -0.0082672695],\n",
      "          [-0.0279606860,  0.0014580843, -0.0244839583],\n",
      "          [ 0.0137734283, -0.0161183737, -0.0127130141]],\n",
      "\n",
      "         [[ 0.0290339496,  0.0140455887,  0.0065585133],\n",
      "          [ 0.0157964882, -0.0267366301, -0.0152130593],\n",
      "          [ 0.0171362106,  0.0063964198, -0.0209022071]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0107360035, -0.0097458651,  0.0030295542],\n",
      "          [-0.0008242097,  0.0215776525,  0.0104050208],\n",
      "          [-0.0075307074, -0.0184180140,  0.0075179264]],\n",
      "\n",
      "         [[ 0.0015877913,  0.0047614700,  0.0192843284],\n",
      "          [-0.0189024266,  0.0017106353,  0.0212621968],\n",
      "          [-0.0229993518,  0.0013503288, -0.0205063075]],\n",
      "\n",
      "         [[-0.0108459713, -0.0139239347,  0.0011018661],\n",
      "          [ 0.0231004246, -0.0043451888,  0.0244499277],\n",
      "          [ 0.0022664713,  0.0277434364, -0.0048481659]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0143696489,  0.0006054324,  0.0085266372],\n",
      "          [-0.0190172419,  0.0038854338,  0.0064413906],\n",
      "          [ 0.0042275921, -0.0091942158, -0.0154629694]],\n",
      "\n",
      "         [[ 0.0058412687,  0.0055214372,  0.0092609450],\n",
      "          [ 0.0260226801, -0.0063667451,  0.0057549169],\n",
      "          [ 0.0055622458, -0.0123441620,  0.0266009830]],\n",
      "\n",
      "         [[-0.0008763981,  0.0084402543,  0.0147094121],\n",
      "          [ 0.0017927549,  0.0073105572,  0.0093729431],\n",
      "          [-0.0004707873,  0.0104618873, -0.0066727381]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0158578847, -0.0145148337,  0.0293491259],\n",
      "          [-0.0214232318, -0.0138360206, -0.0117041869],\n",
      "          [ 0.0283597428,  0.0105783250, -0.0124194361]],\n",
      "\n",
      "         [[-0.0076051285, -0.0129994508, -0.0208779927],\n",
      "          [-0.0269290619, -0.0084833419,  0.0092434604],\n",
      "          [ 0.0086691147, -0.0056462833, -0.0025072738]],\n",
      "\n",
      "         [[-0.0150044821, -0.0278947931,  0.0214016605],\n",
      "          [-0.0016387467,  0.0127108470, -0.0256710313],\n",
      "          [ 0.0168601442,  0.0025710736,  0.0225575510]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0157343671,  0.0164013803,  0.0223739743],\n",
      "          [-0.0185804386,  0.0277348049,  0.0126884421],\n",
      "          [-0.0143682510, -0.0248417556, -0.0025618225]],\n",
      "\n",
      "         [[ 0.0134968963, -0.0086265858,  0.0198927969],\n",
      "          [ 0.0197189469,  0.0156944357, -0.0091586784],\n",
      "          [-0.0154083855, -0.0175821725,  0.0284914989]],\n",
      "\n",
      "         [[ 0.0026918068, -0.0189476889, -0.0231805556],\n",
      "          [-0.0143119879,  0.0023071396, -0.0211843681],\n",
      "          [ 0.0001062698,  0.0023745534, -0.0221047681]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0078375889,  0.0241142064, -0.0285869669],\n",
      "          [ 0.0281717088, -0.0235137697,  0.0012876845],\n",
      "          [-0.0095155006, -0.0005210369,  0.0011048656]],\n",
      "\n",
      "         [[ 0.0220556669, -0.0228817593,  0.0125922840],\n",
      "          [-0.0212781765,  0.0091586327,  0.0250031054],\n",
      "          [ 0.0039792103, -0.0251608547, -0.0217814632]],\n",
      "\n",
      "         [[-0.0239204187, -0.0063774576,  0.0195705909],\n",
      "          [ 0.0085576018, -0.0062373332,  0.0141937658],\n",
      "          [-0.0072717713, -0.0190976746, -0.0067036883]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0140441377, -0.0237618554, -0.0052448031],\n",
      "          [-0.0079976451,  0.0042109303, -0.0217493158],\n",
      "          [-0.0130074900, -0.0151381502, -0.0182249267]],\n",
      "\n",
      "         [[-0.0195045508, -0.0008657946, -0.0244726129],\n",
      "          [-0.0115517415,  0.0258764941,  0.0074237809],\n",
      "          [-0.0199962594,  0.0287106410, -0.0113749811]],\n",
      "\n",
      "         [[-0.0122915134,  0.0055782162, -0.0210555363],\n",
      "          [ 0.0165339876,  0.0087368982, -0.0196085367],\n",
      "          [-0.0278749168,  0.0015684739,  0.0231607091]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0162074696,  0.0240218453, -0.0212155432],\n",
      "          [ 0.0101778843, -0.0250878353, -0.0001531722],\n",
      "          [ 0.0279891640, -0.0268554594, -0.0013970310]],\n",
      "\n",
      "         [[ 0.0224658828,  0.0091633750, -0.0176599678],\n",
      "          [ 0.0237733945,  0.0128215523, -0.0281039122],\n",
      "          [-0.0256658401, -0.0091408538,  0.0194643270]],\n",
      "\n",
      "         [[-0.0212270468, -0.0294066984,  0.0016235564],\n",
      "          [-0.0253227744,  0.0253443681,  0.0060193636],\n",
      "          [ 0.0055710864,  0.0214521587, -0.0181734189]]]])), ('res2.bn1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])), ('res2.bn1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])), ('res2.bn1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])), ('res2.bn1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])), ('res2.bn1.num_batches_tracked', tensor(0)), ('res2.conv2.weight', tensor([[[[ 0.0258196127, -0.0222647507,  0.0243875720],\n",
      "          [ 0.0131527884,  0.0076689003, -0.0194267016],\n",
      "          [-0.0126743512, -0.0085200034, -0.0141343921]],\n",
      "\n",
      "         [[ 0.0258406047, -0.0233265739,  0.0025967867],\n",
      "          [ 0.0291687064, -0.0191845950, -0.0083863726],\n",
      "          [-0.0166206025, -0.0258744843,  0.0205774158]],\n",
      "\n",
      "         [[ 0.0016927544, -0.0269727781,  0.0291426536],\n",
      "          [ 0.0211609490,  0.0250127148, -0.0084606037],\n",
      "          [ 0.0151662836, -0.0283372439,  0.0211372841]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0240417644, -0.0220372695,  0.0112670045],\n",
      "          [-0.0189041644,  0.0093443077, -0.0055325641],\n",
      "          [ 0.0204974320, -0.0217347890,  0.0069772843]],\n",
      "\n",
      "         [[-0.0088849030,  0.0281283390, -0.0082760993],\n",
      "          [-0.0185818113,  0.0235808175, -0.0065257475],\n",
      "          [-0.0257712565, -0.0037926403, -0.0046772254]],\n",
      "\n",
      "         [[ 0.0257792957,  0.0194150787, -0.0078691710],\n",
      "          [-0.0274094827,  0.0035680574, -0.0213880539],\n",
      "          [-0.0287396349, -0.0254516769,  0.0072538625]]],\n",
      "\n",
      "\n",
      "        [[[-0.0215180870,  0.0167965721,  0.0005298596],\n",
      "          [ 0.0153545570, -0.0208737366,  0.0179206040],\n",
      "          [-0.0158648398, -0.0068012862,  0.0252983607]],\n",
      "\n",
      "         [[ 0.0092862044, -0.0162893180,  0.0242780037],\n",
      "          [ 0.0096159233, -0.0033048328,  0.0169538166],\n",
      "          [-0.0152872279, -0.0203929599,  0.0046777665]],\n",
      "\n",
      "         [[ 0.0292786993,  0.0212948676,  0.0074264538],\n",
      "          [ 0.0167223625,  0.0137769161,  0.0110738138],\n",
      "          [-0.0197837204, -0.0031920162, -0.0094581358]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0086110579,  0.0240108799,  0.0255572870],\n",
      "          [ 0.0024164931, -0.0205854829, -0.0255261194],\n",
      "          [ 0.0273473654,  0.0092058554,  0.0099206585]],\n",
      "\n",
      "         [[ 0.0118103055,  0.0042748074,  0.0031589661],\n",
      "          [-0.0112930443, -0.0123382444,  0.0177496579],\n",
      "          [-0.0169446487,  0.0253466237,  0.0100900186]],\n",
      "\n",
      "         [[-0.0078847343,  0.0012502723,  0.0195997283],\n",
      "          [ 0.0027469664, -0.0256620739,  0.0086743273],\n",
      "          [ 0.0010065475, -0.0258000419,  0.0007786841]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0042006993,  0.0266711432, -0.0282814279],\n",
      "          [-0.0115065994, -0.0062303650, -0.0120721636],\n",
      "          [-0.0069827037,  0.0049626790, -0.0220069252]],\n",
      "\n",
      "         [[ 0.0196550842, -0.0026263422,  0.0035345613],\n",
      "          [ 0.0228109322, -0.0117671266, -0.0031110381],\n",
      "          [ 0.0160627849, -0.0220824014, -0.0256218705]],\n",
      "\n",
      "         [[-0.0154913655,  0.0255598612,  0.0188718941],\n",
      "          [ 0.0186690129, -0.0252772346,  0.0263916962],\n",
      "          [-0.0227753520, -0.0126298824,  0.0029804003]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0140341986, -0.0060522943,  0.0070814644],\n",
      "          [-0.0218191277, -0.0047935122,  0.0007792776],\n",
      "          [ 0.0136754969,  0.0228410102,  0.0165852308]],\n",
      "\n",
      "         [[ 0.0028960118,  0.0040611052,  0.0093070148],\n",
      "          [-0.0201016665, -0.0091438396,  0.0280155521],\n",
      "          [-0.0187942497, -0.0183817446, -0.0010279476]],\n",
      "\n",
      "         [[ 0.0217536073, -0.0171392895,  0.0015881810],\n",
      "          [ 0.0015659099,  0.0201972090, -0.0202719923],\n",
      "          [-0.0174861588, -0.0235329028, -0.0030328627]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0010751029,  0.0275408626,  0.0280935541],\n",
      "          [-0.0101325242,  0.0285318326, -0.0175259598],\n",
      "          [ 0.0008827447, -0.0223254599,  0.0283477288]],\n",
      "\n",
      "         [[ 0.0013851105, -0.0275374204, -0.0127674742],\n",
      "          [ 0.0280741323,  0.0017820391,  0.0098856594],\n",
      "          [-0.0069061266,  0.0186851136,  0.0204040371]],\n",
      "\n",
      "         [[-0.0218776148,  0.0024320418, -0.0103173833],\n",
      "          [-0.0144043984, -0.0184048712, -0.0250527188],\n",
      "          [ 0.0180027280,  0.0082952343, -0.0048213326]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0242700409, -0.0169673730,  0.0066618468],\n",
      "          [-0.0025556760,  0.0263837017,  0.0137527622],\n",
      "          [ 0.0214459598,  0.0053455867,  0.0033393896]],\n",
      "\n",
      "         [[ 0.0054573775, -0.0210472029,  0.0173770115],\n",
      "          [ 0.0283522420,  0.0045621893, -0.0243272986],\n",
      "          [ 0.0002166208, -0.0163069889, -0.0187153742]],\n",
      "\n",
      "         [[ 0.0052045141,  0.0282776766,  0.0048125307],\n",
      "          [-0.0002534817, -0.0121216299,  0.0097646378],\n",
      "          [ 0.0263071470,  0.0073447451, -0.0132094054]]],\n",
      "\n",
      "\n",
      "        [[[-0.0268791318, -0.0291596409, -0.0274468567],\n",
      "          [ 0.0101564983, -0.0179623049, -0.0055169100],\n",
      "          [ 0.0060592312,  0.0132935941,  0.0267605688]],\n",
      "\n",
      "         [[-0.0219422225,  0.0225471240, -0.0201124903],\n",
      "          [ 0.0157975703, -0.0027004434, -0.0035257209],\n",
      "          [-0.0251415018,  0.0144120231,  0.0064423038]],\n",
      "\n",
      "         [[ 0.0030002901, -0.0111600077,  0.0209701825],\n",
      "          [ 0.0021506730, -0.0236770324, -0.0042411988],\n",
      "          [ 0.0189745352, -0.0274317991,  0.0165369939]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0250329562,  0.0061098989,  0.0032186073],\n",
      "          [-0.0192522593, -0.0131919533, -0.0050529400],\n",
      "          [ 0.0245100502, -0.0190513581,  0.0052596913]],\n",
      "\n",
      "         [[-0.0238496121, -0.0157968011,  0.0200588442],\n",
      "          [-0.0283422954,  0.0005701274, -0.0258470401],\n",
      "          [ 0.0180938151,  0.0198566485,  0.0208574701]],\n",
      "\n",
      "         [[-0.0273694005,  0.0225837212, -0.0124795558],\n",
      "          [-0.0269667506,  0.0217891522, -0.0108641684],\n",
      "          [ 0.0074644773,  0.0128632430, -0.0272919703]]],\n",
      "\n",
      "\n",
      "        [[[-0.0049625211,  0.0202143621,  0.0210329778],\n",
      "          [-0.0239557885,  0.0239011478,  0.0067387754],\n",
      "          [-0.0258336049,  0.0184710007, -0.0162629969]],\n",
      "\n",
      "         [[ 0.0199793130,  0.0089828391,  0.0244699754],\n",
      "          [ 0.0288742092,  0.0133623844,  0.0063455137],\n",
      "          [-0.0125193736,  0.0218390711, -0.0037737340]],\n",
      "\n",
      "         [[ 0.0155091062, -0.0137258768, -0.0091275042],\n",
      "          [ 0.0190565046, -0.0119180754,  0.0288716871],\n",
      "          [ 0.0159553494,  0.0226450209,  0.0136619778]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0138993217,  0.0227020308,  0.0076788785],\n",
      "          [ 0.0060373396,  0.0259192828, -0.0170420650],\n",
      "          [ 0.0169099439,  0.0057190321, -0.0215271562]],\n",
      "\n",
      "         [[-0.0091791237, -0.0214989986, -0.0161982309],\n",
      "          [-0.0235187281,  0.0042780419, -0.0014399049],\n",
      "          [-0.0101721454,  0.0021106966, -0.0079754591]],\n",
      "\n",
      "         [[ 0.0136945825,  0.0216175392, -0.0233857892],\n",
      "          [ 0.0238452256, -0.0213831756,  0.0177337322],\n",
      "          [ 0.0227882918, -0.0169271901, -0.0184014924]]]])), ('res2.bn2.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])), ('res2.bn2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])), ('res2.bn2.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])), ('res2.bn2.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])), ('res2.bn2.num_batches_tracked', tensor(0)), ('res3.conv1.weight', tensor([[[[-0.0159522668,  0.0041011130,  0.0196299553],\n",
      "          [-0.0151030561, -0.0201333947, -0.0053219772],\n",
      "          [-0.0100261448, -0.0120825004, -0.0077971774]],\n",
      "\n",
      "         [[ 0.0101048788, -0.0018168488,  0.0062233722],\n",
      "          [ 0.0210602954,  0.0188330133, -0.0043059750],\n",
      "          [ 0.0090620499, -0.0110490918,  0.0262156837]],\n",
      "\n",
      "         [[-0.0162014663,  0.0193978790,  0.0274204407],\n",
      "          [-0.0031162852,  0.0055912994,  0.0003056806],\n",
      "          [-0.0191334579,  0.0107247187, -0.0217092615]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0204904098, -0.0124820108, -0.0193461031],\n",
      "          [-0.0018623183, -0.0115728015,  0.0096047930],\n",
      "          [ 0.0043023117,  0.0103077982,  0.0144161647]],\n",
      "\n",
      "         [[ 0.0071652276, -0.0267259832, -0.0082777217],\n",
      "          [ 0.0208522771, -0.0173422825,  0.0103268912],\n",
      "          [-0.0049766228, -0.0226145629,  0.0126728974]],\n",
      "\n",
      "         [[-0.0202198979,  0.0178647954, -0.0219249446],\n",
      "          [-0.0084906342,  0.0249300748, -0.0004341441],\n",
      "          [ 0.0203027762, -0.0008757694, -0.0061014974]]],\n",
      "\n",
      "\n",
      "        [[[-0.0283578783, -0.0002583778, -0.0074055032],\n",
      "          [-0.0004373473, -0.0002974057,  0.0119449859],\n",
      "          [ 0.0083744070,  0.0076199183, -0.0157527812]],\n",
      "\n",
      "         [[-0.0240856279, -0.0201513153, -0.0168744102],\n",
      "          [-0.0063515618,  0.0099626090,  0.0255231801],\n",
      "          [-0.0293510798,  0.0167612862, -0.0278717987]],\n",
      "\n",
      "         [[ 0.0219870415, -0.0208167788,  0.0275166444],\n",
      "          [-0.0070136571,  0.0182472542,  0.0131402211],\n",
      "          [-0.0015897896, -0.0060441461, -0.0023586676]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0187191535, -0.0233869031, -0.0187468790],\n",
      "          [ 0.0113048423, -0.0270909928,  0.0239165314],\n",
      "          [ 0.0057236403, -0.0230526924, -0.0042668451]],\n",
      "\n",
      "         [[ 0.0230081081,  0.0190188009,  0.0226834062],\n",
      "          [ 0.0276691746,  0.0215810407, -0.0045029554],\n",
      "          [ 0.0045621051,  0.0198680107,  0.0011438198]],\n",
      "\n",
      "         [[ 0.0256477874,  0.0200094581,  0.0230450053],\n",
      "          [ 0.0056212093,  0.0022949416,  0.0219106786],\n",
      "          [-0.0292516612,  0.0036637166,  0.0241688322]]],\n",
      "\n",
      "\n",
      "        [[[-0.0183227286,  0.0203929078,  0.0225540921],\n",
      "          [-0.0221603978,  0.0133071439,  0.0002901284],\n",
      "          [ 0.0099589843,  0.0279192626, -0.0112335151]],\n",
      "\n",
      "         [[ 0.0139887566, -0.0117936432, -0.0012948179],\n",
      "          [ 0.0193479750,  0.0028300239,  0.0057146386],\n",
      "          [ 0.0118486313, -0.0274877492,  0.0200306755]],\n",
      "\n",
      "         [[-0.0004444596, -0.0262330212,  0.0003044794],\n",
      "          [ 0.0068119741, -0.0038331996,  0.0162773374],\n",
      "          [ 0.0222485587, -0.0077160657,  0.0178360716]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0286347792,  0.0131271351, -0.0130123897],\n",
      "          [ 0.0186857525, -0.0224340726,  0.0200477205],\n",
      "          [-0.0267678667,  0.0146276187, -0.0057692961]],\n",
      "\n",
      "         [[-0.0051919543, -0.0058869980, -0.0051453118],\n",
      "          [ 0.0112870662,  0.0202895589,  0.0012538934],\n",
      "          [-0.0052692131,  0.0019086938, -0.0107308757]],\n",
      "\n",
      "         [[ 0.0084493756, -0.0011700457,  0.0149291232],\n",
      "          [-0.0223736539, -0.0281320941,  0.0183801465],\n",
      "          [ 0.0039363015, -0.0178082194, -0.0247452650]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0217758752, -0.0005680341, -0.0076848455],\n",
      "          [-0.0108758500,  0.0036839191,  0.0204143990],\n",
      "          [ 0.0251255594, -0.0291724894,  0.0025477209]],\n",
      "\n",
      "         [[ 0.0259567406,  0.0197809674,  0.0129354373],\n",
      "          [ 0.0241926592,  0.0173666365,  0.0108848838],\n",
      "          [-0.0120304944,  0.0137289073, -0.0028066956]],\n",
      "\n",
      "         [[-0.0024068449, -0.0048370217, -0.0071028713],\n",
      "          [ 0.0081452578, -0.0237244759,  0.0117638176],\n",
      "          [-0.0265189447, -0.0117820669,  0.0117741786]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0009296506,  0.0033509589, -0.0223608520],\n",
      "          [-0.0285187345,  0.0219755843, -0.0066420906],\n",
      "          [-0.0186758414, -0.0223135278,  0.0040289578]],\n",
      "\n",
      "         [[-0.0221681986, -0.0098265978, -0.0189222172],\n",
      "          [-0.0055527068, -0.0198694579,  0.0228932798],\n",
      "          [-0.0160791427, -0.0208717734,  0.0210282747]],\n",
      "\n",
      "         [[ 0.0221750103, -0.0268922262,  0.0233004000],\n",
      "          [ 0.0223542359,  0.0024986267,  0.0217205640],\n",
      "          [ 0.0206806511,  0.0267945565, -0.0067549949]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0196483694,  0.0050378586,  0.0245274249],\n",
      "          [-0.0046860971, -0.0177117642,  0.0034361237],\n",
      "          [-0.0195279177, -0.0163095798, -0.0279268678]],\n",
      "\n",
      "         [[ 0.0272953138, -0.0200108010,  0.0150112184],\n",
      "          [ 0.0080786552,  0.0054086349, -0.0005077782],\n",
      "          [-0.0114052324,  0.0082446327, -0.0160147026]],\n",
      "\n",
      "         [[ 0.0231200010,  0.0043576681,  0.0255515613],\n",
      "          [-0.0067049735,  0.0173809920, -0.0056396243],\n",
      "          [ 0.0225898605,  0.0082418518,  0.0229276754]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0250299852,  0.0053835222, -0.0145226382],\n",
      "          [-0.0201725923, -0.0128066745,  0.0273060203],\n",
      "          [ 0.0220850054,  0.0027483713, -0.0139835868]],\n",
      "\n",
      "         [[ 0.0116084889, -0.0088523766,  0.0125423651],\n",
      "          [-0.0169472694,  0.0260141306,  0.0156637114],\n",
      "          [ 0.0018017286, -0.0030452257, -0.0148041863]],\n",
      "\n",
      "         [[-0.0218548980,  0.0167880338,  0.0053846990],\n",
      "          [-0.0156306531, -0.0009248564,  0.0196900554],\n",
      "          [-0.0087198177,  0.0076234974,  0.0099161416]]],\n",
      "\n",
      "\n",
      "        [[[-0.0023595984, -0.0046370523,  0.0146342004],\n",
      "          [ 0.0268084370, -0.0245493352, -0.0028051890],\n",
      "          [ 0.0110824713, -0.0062362091, -0.0063288128]],\n",
      "\n",
      "         [[-0.0281173363,  0.0081347106, -0.0030107882],\n",
      "          [-0.0009583983,  0.0015242161, -0.0022411130],\n",
      "          [ 0.0201997198,  0.0016598939,  0.0218298379]],\n",
      "\n",
      "         [[-0.0237223711, -0.0097455038, -0.0291200299],\n",
      "          [-0.0085318321,  0.0217561051, -0.0189608000],\n",
      "          [ 0.0094168214,  0.0270522423, -0.0141561013]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0194557719, -0.0073124431,  0.0030728530],\n",
      "          [ 0.0229583587,  0.0231130123, -0.0247909520],\n",
      "          [ 0.0182657726,  0.0135704884, -0.0246703774]],\n",
      "\n",
      "         [[ 0.0103675062,  0.0254909974, -0.0157281775],\n",
      "          [-0.0020941154,  0.0249976814,  0.0186511744],\n",
      "          [ 0.0065072766,  0.0290142447, -0.0001799495]],\n",
      "\n",
      "         [[ 0.0042640213, -0.0238052700,  0.0202845857],\n",
      "          [ 0.0231086016, -0.0103298910,  0.0275715906],\n",
      "          [ 0.0002977570,  0.0056040557,  0.0109627219]]]])), ('res3.bn1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])), ('res3.bn1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])), ('res3.bn1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])), ('res3.bn1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])), ('res3.bn1.num_batches_tracked', tensor(0)), ('res3.conv2.weight', tensor([[[[ 0.0227668080, -0.0137842605,  0.0189597309],\n",
      "          [ 0.0206000973,  0.0215142071, -0.0227100253],\n",
      "          [ 0.0179737974,  0.0165898241,  0.0125874653]],\n",
      "\n",
      "         [[ 0.0163118280,  0.0137991589,  0.0192229040],\n",
      "          [ 0.0090248166,  0.0275579486,  0.0198562648],\n",
      "          [ 0.0285633542, -0.0268103275,  0.0085157640]],\n",
      "\n",
      "         [[-0.0024900252, -0.0098274862, -0.0051597259],\n",
      "          [ 0.0196127836, -0.0059573343,  0.0084939841],\n",
      "          [ 0.0060241683,  0.0200920030,  0.0259751584]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0291226339, -0.0040213433,  0.0226765387],\n",
      "          [ 0.0030380678,  0.0091422591,  0.0263369232],\n",
      "          [ 0.0112208780,  0.0112564750, -0.0024350905]],\n",
      "\n",
      "         [[ 0.0284158438,  0.0258874930, -0.0094979014],\n",
      "          [-0.0282487739,  0.0164191481, -0.0166194122],\n",
      "          [-0.0194108747,  0.0131902564,  0.0162851904]],\n",
      "\n",
      "         [[-0.0041557564, -0.0233799387,  0.0037330587],\n",
      "          [-0.0211958513, -0.0258860681, -0.0219476838],\n",
      "          [ 0.0240055937, -0.0200833976,  0.0015569994]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0157900564,  0.0146576799, -0.0263911169],\n",
      "          [ 0.0165312439, -0.0219452735, -0.0091822147],\n",
      "          [ 0.0036742638, -0.0231029782,  0.0188679788]],\n",
      "\n",
      "         [[-0.0170205384,  0.0250983052,  0.0237516500],\n",
      "          [-0.0253386218, -0.0141818915, -0.0274648387],\n",
      "          [ 0.0085386811, -0.0106716277, -0.0234718286]],\n",
      "\n",
      "         [[-0.0039850585, -0.0206413586, -0.0079989731],\n",
      "          [ 0.0187569950, -0.0115838889,  0.0234655030],\n",
      "          [ 0.0058020335,  0.0107076773,  0.0117875254]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0096680094, -0.0206979979, -0.0158851612],\n",
      "          [ 0.0173848588,  0.0070412527, -0.0176729951],\n",
      "          [ 0.0012056598,  0.0227958318,  0.0145039950]],\n",
      "\n",
      "         [[-0.0067347926,  0.0017543064, -0.0242248140],\n",
      "          [ 0.0146973543,  0.0022360063,  0.0184659995],\n",
      "          [-0.0122819291,  0.0028065867, -0.0247049276]],\n",
      "\n",
      "         [[ 0.0016939380, -0.0120160030,  0.0128157008],\n",
      "          [ 0.0033072527, -0.0088365190,  0.0171926506],\n",
      "          [ 0.0045509958,  0.0190451499, -0.0074285753]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0257798620,  0.0148982648, -0.0218894929],\n",
      "          [-0.0194018409, -0.0190173369,  0.0212290939],\n",
      "          [ 0.0292911679,  0.0281037968, -0.0163680799]],\n",
      "\n",
      "         [[ 0.0273967683, -0.0147525594, -0.0010213973],\n",
      "          [ 0.0184071101,  0.0079796808, -0.0226540547],\n",
      "          [-0.0039485451, -0.0160314459, -0.0101160062]],\n",
      "\n",
      "         [[-0.0042378763,  0.0085281441,  0.0198561139],\n",
      "          [ 0.0096516525, -0.0141722746, -0.0234867632],\n",
      "          [ 0.0165674351, -0.0048766434, -0.0243636630]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0031521241,  0.0153153883,  0.0174218044],\n",
      "          [-0.0251798518,  0.0152920075, -0.0103993099],\n",
      "          [-0.0207741298, -0.0098838219,  0.0148093561]],\n",
      "\n",
      "         [[ 0.0073502841,  0.0197581481, -0.0179652981],\n",
      "          [-0.0293442197, -0.0217668451, -0.0020047780],\n",
      "          [ 0.0149068208, -0.0294576399, -0.0212654136]],\n",
      "\n",
      "         [[-0.0047041713, -0.0252069626,  0.0103214225],\n",
      "          [ 0.0169361569,  0.0063697551, -0.0056081722],\n",
      "          [-0.0278221536, -0.0259656515, -0.0168366432]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0040011620,  0.0100296047, -0.0229372215],\n",
      "          [-0.0032944542, -0.0143904835, -0.0258838832],\n",
      "          [ 0.0059442651,  0.0182985812,  0.0051143654]],\n",
      "\n",
      "         [[-0.0155043574,  0.0026225350, -0.0277517196],\n",
      "          [-0.0031366809, -0.0211427808, -0.0204093866],\n",
      "          [ 0.0061596110, -0.0034807923,  0.0092256218]],\n",
      "\n",
      "         [[-0.0020573528, -0.0128231924, -0.0040569291],\n",
      "          [ 0.0096902773,  0.0125614572, -0.0037842637],\n",
      "          [-0.0223651696,  0.0110411961, -0.0150549067]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0109365452,  0.0232070666,  0.0284310803],\n",
      "          [ 0.0196359605,  0.0254967809,  0.0078555057],\n",
      "          [ 0.0013188276, -0.0013548174,  0.0038037670]],\n",
      "\n",
      "         [[-0.0072251991,  0.0245384425,  0.0074907136],\n",
      "          [ 0.0094505493,  0.0215713996,  0.0174074285],\n",
      "          [-0.0094510512, -0.0140817752, -0.0061133304]],\n",
      "\n",
      "         [[-0.0039241244, -0.0204122290,  0.0074947667],\n",
      "          [ 0.0241798721,  0.0248315986, -0.0165593568],\n",
      "          [-0.0018258225,  0.0097758844, -0.0031177744]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0201926567, -0.0274603013,  0.0115718953],\n",
      "          [-0.0132130440, -0.0192899480,  0.0160697401],\n",
      "          [ 0.0192805678,  0.0254243948,  0.0115781501]],\n",
      "\n",
      "         [[ 0.0098293796,  0.0043890253,  0.0206829235],\n",
      "          [-0.0265490841,  0.0021635208,  0.0123932632],\n",
      "          [ 0.0191855822, -0.0023171706,  0.0122912573]],\n",
      "\n",
      "         [[ 0.0152764097, -0.0232068170,  0.0168674458],\n",
      "          [-0.0080386717, -0.0288716312,  0.0021490853],\n",
      "          [ 0.0011201017, -0.0016602030, -0.0100419717]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0271531679,  0.0109523432, -0.0214643367],\n",
      "          [ 0.0271098781, -0.0114421491,  0.0275220014],\n",
      "          [-0.0093305539,  0.0003402515,  0.0041458802]],\n",
      "\n",
      "         [[ 0.0242566280,  0.0107867382,  0.0255339351],\n",
      "          [-0.0222149901, -0.0240305495,  0.0023597458],\n",
      "          [ 0.0073611331,  0.0111952536,  0.0169215519]],\n",
      "\n",
      "         [[-0.0027198908,  0.0011332128, -0.0029567208],\n",
      "          [ 0.0053321561, -0.0152536081,  0.0255496688],\n",
      "          [-0.0039545931,  0.0194188822, -0.0064739492]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0102375085, -0.0195778757, -0.0048601921],\n",
      "          [ 0.0203368030, -0.0209446102, -0.0006987280],\n",
      "          [-0.0080164047, -0.0270946454, -0.0261964723]],\n",
      "\n",
      "         [[ 0.0227894858, -0.0055642026,  0.0077124098],\n",
      "          [-0.0278161336,  0.0095730843,  0.0220980421],\n",
      "          [ 0.0017015386, -0.0192563515,  0.0107757095]],\n",
      "\n",
      "         [[ 0.0081936531,  0.0020133725,  0.0100239357],\n",
      "          [-0.0029609636,  0.0087257568,  0.0127521018],\n",
      "          [-0.0084862430, -0.0259435847, -0.0227473043]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0144725293,  0.0144692417, -0.0152315414],\n",
      "          [-0.0210638884,  0.0112225963,  0.0060793422],\n",
      "          [-0.0038537567,  0.0029556847,  0.0235806108]],\n",
      "\n",
      "         [[-0.0231063142,  0.0148702264,  0.0063821953],\n",
      "          [-0.0068069547,  0.0129846996, -0.0245274007],\n",
      "          [-0.0239927229,  0.0248391759, -0.0024463471]],\n",
      "\n",
      "         [[ 0.0227329526,  0.0003659822,  0.0179312266],\n",
      "          [-0.0071192738,  0.0111730034, -0.0217102487],\n",
      "          [-0.0220411159, -0.0015800537, -0.0146226240]]]])), ('res3.bn2.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])), ('res3.bn2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])), ('res3.bn2.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])), ('res3.bn2.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])), ('res3.bn2.num_batches_tracked', tensor(0)), ('fc1.weight', tensor([[-0.0015572137,  0.0084578749,  0.0048185005,  ...,\n",
      "         -0.0066173105,  0.0065396740, -0.0012561318],\n",
      "        [-0.0080597857, -0.0083353464,  0.0041118735,  ...,\n",
      "         -0.0037890885,  0.0053935852,  0.0003551867],\n",
      "        [ 0.0092630647,  0.0033572519,  0.0034639500,  ...,\n",
      "         -0.0026871883, -0.0006769592,  0.0038474607],\n",
      "        ...,\n",
      "        [-0.0012731872,  0.0082894051, -0.0048870770,  ...,\n",
      "         -0.0041349572,  0.0011970489,  0.0090249386],\n",
      "        [ 0.0003865592,  0.0044253618,  0.0005268590,  ...,\n",
      "         -0.0048973751,  0.0033335418,  0.0072345291],\n",
      "        [ 0.0076510068,  0.0082290778,  0.0096630426,  ...,\n",
      "         -0.0048263366, -0.0071365153,  0.0035808878]])), ('fc1.bias', tensor([ 9.6796350554e-03, -2.1932728123e-03,  2.1139455494e-03,\n",
      "        -4.5778164640e-03, -6.2168571167e-03, -2.3363684304e-03,\n",
      "         1.9015687285e-03, -9.6092361491e-04,  2.4209138937e-03,\n",
      "        -8.1101180986e-03, -2.8616515920e-03,  6.0786632821e-03,\n",
      "         7.4990275316e-03,  1.8670106074e-03, -5.1507796161e-03,\n",
      "        -6.8415775895e-03, -6.9118139800e-04,  5.1231533289e-03,\n",
      "        -6.5868617967e-03,  9.1072497889e-03,  3.5927849240e-05,\n",
      "         4.7000995837e-03, -8.0991517752e-03,  1.1801844230e-03,\n",
      "        -4.0697231889e-03, -5.2848050836e-04, -8.8609419763e-03,\n",
      "         8.4688542411e-03, -8.0263018608e-03, -2.5697706733e-03,\n",
      "         5.6835496798e-03,  6.0560409911e-03,  9.1059952974e-03,\n",
      "        -3.1220430974e-03,  7.9407067969e-03,  4.7137471847e-03,\n",
      "        -5.8366009034e-04, -3.6739150528e-03, -7.0172818378e-03,\n",
      "         7.1463262429e-04, -4.9566556700e-03, -2.4359591771e-04,\n",
      "         2.3316913284e-03, -4.1650044732e-03, -8.5299815983e-03,\n",
      "         3.7103369832e-03,  7.8379148617e-03, -9.1780489311e-03,\n",
      "         9.7745070234e-03, -7.4492214480e-05, -2.9836585745e-03,\n",
      "         6.1056711711e-03,  1.2235675240e-03,  3.5078835208e-03,\n",
      "         8.9001851156e-03, -1.7335549928e-03,  8.5192425177e-03,\n",
      "         1.5122359619e-03,  5.1870723255e-03, -7.7488822863e-03,\n",
      "        -7.4193077162e-03,  9.9019461777e-04,  6.5493816510e-03,\n",
      "         9.4559574500e-03, -9.1269034892e-03, -3.6012142664e-04,\n",
      "         2.1751790773e-03, -6.4600384794e-03,  3.9464682341e-03,\n",
      "         5.2185622044e-03,  4.2298273183e-03,  5.9924498200e-03,\n",
      "         5.9219612740e-03, -9.4048334286e-03,  9.0286247432e-03,\n",
      "        -3.8951358292e-03, -6.3555892557e-03,  4.2885062285e-03,\n",
      "         1.0559448274e-03,  5.2779912949e-03, -7.0228185505e-03,\n",
      "        -9.0205846354e-03, -2.1757199429e-03, -5.2891368978e-03,\n",
      "        -5.1270425320e-03,  8.0958101898e-03,  7.9968767241e-03,\n",
      "         3.7629117724e-03, -3.4376785625e-03,  7.2289258242e-03,\n",
      "         5.4800915532e-03, -3.3681187779e-03,  8.5804210976e-03,\n",
      "         5.9131678427e-04, -5.6758532301e-03,  8.4548369050e-03,\n",
      "        -3.3559699077e-03,  1.8171239644e-03, -9.3314545229e-03,\n",
      "        -3.5696930718e-03, -8.8279442862e-03, -5.5818245746e-03,\n",
      "        -7.4165789410e-03, -4.8636295105e-05, -8.3529553376e-04,\n",
      "        -2.0923616830e-03,  4.8574102111e-03,  5.4640746675e-03,\n",
      "        -2.5874595158e-03,  5.5002328008e-03,  8.8622065959e-04,\n",
      "         4.1536507197e-03, -2.3953693744e-04, -1.0640089022e-04,\n",
      "         3.2889714930e-03,  2.9194421950e-04,  2.1032742225e-03,\n",
      "        -5.2857571281e-03, -1.1733800056e-04, -1.1411891319e-03,\n",
      "         4.0670502931e-03, -2.3166320752e-03, -2.7093493845e-03,\n",
      "         6.6235903651e-03,  3.8304356858e-03, -1.0880150367e-03,\n",
      "         4.2463443242e-03,  4.0262360126e-03, -6.9408942945e-03,\n",
      "         1.3030049740e-04, -6.7500779405e-03, -2.2145125549e-03,\n",
      "        -4.6206410043e-03, -5.6906184182e-03, -1.1676386930e-03,\n",
      "        -5.6987772696e-03,  6.5946709365e-03,  4.9279304221e-03,\n",
      "         2.1954621188e-03, -4.8368871212e-03, -9.1574684484e-04,\n",
      "        -3.2323871274e-03,  7.8444806859e-03, -2.3308706004e-03,\n",
      "        -7.6128393412e-03,  7.9495795071e-03, -6.2306202017e-03,\n",
      "         4.3173455633e-03, -1.3764458708e-03, -5.8372966014e-03,\n",
      "        -8.2857199013e-03, -3.2622844446e-03, -4.6174838208e-03,\n",
      "         6.5443650819e-03,  5.4034604691e-03,  6.9459029473e-03,\n",
      "         2.4057163391e-03, -3.8798868190e-03,  9.7462907434e-03,\n",
      "         5.2524199709e-03, -6.1715948395e-03, -3.7332461216e-03,\n",
      "         3.4876470454e-03, -3.2173232175e-03,  9.3096680939e-03,\n",
      "         9.2487968504e-03,  5.5542290211e-03, -2.2987173870e-03,\n",
      "        -8.8272280991e-03,  6.1149997637e-03,  7.3051471263e-03,\n",
      "        -5.3227879107e-03,  9.6404431388e-03, -6.2597002834e-03,\n",
      "         4.1720205918e-03, -7.2231492959e-03, -4.9924887717e-03,\n",
      "        -2.5483495556e-03, -5.1761553623e-03,  8.0945370428e-05,\n",
      "        -8.0945193768e-03, -4.3027638458e-03,  3.5822107457e-03,\n",
      "         7.8694177791e-03,  4.0876356070e-04,  3.9080441929e-03,\n",
      "         6.4751622267e-03, -6.9863088429e-03, -8.4181465209e-03,\n",
      "        -2.2411271930e-03, -4.0929834358e-03,  5.2055879496e-03,\n",
      "         2.4579211604e-03, -4.6075874707e-05,  5.2297497168e-03,\n",
      "         8.9808478951e-03, -9.0852146968e-03, -3.6041317508e-03,\n",
      "         5.9398771264e-03,  3.8921853993e-03, -7.6703989180e-04,\n",
      "         5.7796092005e-04,  3.4554833546e-03,  2.2508993279e-03,\n",
      "         9.6560390666e-03,  9.6789393574e-03,  7.1715079248e-03,\n",
      "        -7.8821164789e-04, -6.8786200136e-03, -6.4758164808e-04,\n",
      "        -2.5627861032e-04, -2.3507159203e-03, -8.1401958596e-06,\n",
      "         6.8490561098e-03, -4.5360978693e-03,  1.6667908058e-03,\n",
      "         9.3714185059e-03, -6.0840616934e-03,  5.9411018156e-03,\n",
      "        -4.4084247202e-03, -3.5929358564e-03,  2.3856265470e-03,\n",
      "         1.3858902967e-03,  5.5757462978e-03,  7.8629842028e-03,\n",
      "        -7.5311819091e-03, -6.7925960757e-03,  3.8742145989e-03,\n",
      "         4.6081985347e-03,  4.2399615049e-03, -1.4748716494e-03,\n",
      "        -2.9816462193e-03, -7.3520648293e-03, -2.6055299677e-03,\n",
      "        -5.2436231636e-03,  1.8630406121e-03,  2.4031372741e-03,\n",
      "        -5.9678582475e-03, -4.9511790276e-03,  9.4310601708e-04,\n",
      "        -5.3216814995e-03,  4.5236996375e-03,  6.1161364429e-03,\n",
      "        -4.7209095210e-03,  6.5000769682e-03,  2.3917038925e-03,\n",
      "         2.9227201594e-04,  1.6717185499e-03, -7.9071680084e-03,\n",
      "         3.6658628960e-04, -7.0743723772e-03,  1.5049481299e-03,\n",
      "        -8.2970171934e-04, -8.3645228297e-03,  2.9993746430e-03,\n",
      "         3.3124287147e-03,  5.3476658650e-03,  2.1553442348e-03,\n",
      "        -3.1692499761e-03, -1.9097884651e-03, -7.2999997064e-03,\n",
      "         3.1940240879e-03, -1.8894432287e-04,  6.7456946708e-03,\n",
      "        -2.2503912915e-03,  8.2060769200e-03,  7.1389866062e-03,\n",
      "         4.9183326773e-03,  2.0302068442e-03,  2.9080787208e-03,\n",
      "         2.1309668664e-03, -5.6297257543e-03, -9.4217583537e-03,\n",
      "         3.6090512294e-03,  1.7514474166e-04, -5.0752883544e-04,\n",
      "         2.1543514449e-03,  8.6043132469e-03, -8.3568571135e-03,\n",
      "        -8.4675131366e-03, -8.5735470057e-03,  7.7608120628e-03,\n",
      "         6.5160575323e-03, -1.0126659181e-03,  9.0520428494e-03,\n",
      "        -1.9600850064e-03, -5.7885069400e-03, -8.8124489412e-03,\n",
      "        -5.9789861552e-03, -3.2431473956e-03, -8.8382754475e-03,\n",
      "         9.6782512264e-04, -1.7460234230e-03, -1.4756560558e-03,\n",
      "         8.5053816438e-03,  5.2671306767e-03,  5.2521107718e-03,\n",
      "         6.8685901351e-04, -1.8562058685e-03,  9.4180740416e-03,\n",
      "        -5.6289285421e-03, -6.8043456413e-03, -3.0063348822e-03,\n",
      "        -1.4149902854e-03, -1.7079542158e-03,  6.0967127793e-03,\n",
      "        -8.7769534439e-03,  2.4841553532e-03, -8.9210057631e-03,\n",
      "        -1.3715521200e-03, -6.1217444018e-03, -6.3332432183e-04,\n",
      "         3.1418942381e-03, -8.4740220336e-04,  7.5967400335e-03,\n",
      "         6.0271141119e-03,  8.8370684534e-03, -6.9602071308e-03,\n",
      "        -4.2338267667e-04,  4.4274986722e-03,  4.5256223530e-03,\n",
      "        -8.9251045138e-03,  1.3913635630e-03,  7.8638726845e-03,\n",
      "         1.1557486141e-03, -8.1373695284e-03,  1.7587810289e-03,\n",
      "         2.4519048166e-03, -2.1902990993e-03, -2.8950788546e-03,\n",
      "         5.7164439932e-03,  4.4421609346e-05,  9.8189543933e-03,\n",
      "         6.8343039602e-03, -2.5778289419e-03, -5.6438427418e-03,\n",
      "         6.5829983214e-04,  5.6308638304e-03, -2.4937109556e-03,\n",
      "         7.7264248393e-03,  1.8903681485e-04,  7.5651933439e-03,\n",
      "        -3.5811078269e-03,  5.3445156664e-03, -8.2327853888e-03,\n",
      "        -8.2655781880e-03,  2.4201189808e-04, -3.8600896369e-04,\n",
      "        -4.2187087238e-03, -9.5887137577e-03, -3.6297452170e-03,\n",
      "        -3.5328064114e-03, -7.4694040231e-03,  7.0402859710e-03,\n",
      "         2.1558266599e-03, -5.6328657083e-03, -1.0058368789e-03,\n",
      "         9.6905208193e-04,  6.3129365444e-03, -7.8717386350e-03,\n",
      "        -3.4376352560e-03,  4.3709329329e-03, -5.9236939996e-03,\n",
      "         1.4430461451e-03,  7.6884012669e-03,  2.6828916743e-03,\n",
      "         8.5804443806e-03, -1.8803594867e-03, -2.0440800581e-03,\n",
      "         1.6860964242e-03, -9.1062597930e-03, -7.0888181217e-03,\n",
      "         6.9440505467e-03,  4.8271850683e-03, -2.3077963851e-03,\n",
      "         7.6283104718e-03,  1.1808950221e-03,  4.2339963838e-03,\n",
      "         1.5320145758e-04, -3.2326295041e-03, -1.2489715591e-03,\n",
      "        -4.9871429801e-03,  4.5041856356e-03, -4.5348536223e-03,\n",
      "        -8.9389076456e-03, -7.9086385667e-03, -9.6828173846e-03,\n",
      "         2.7103715111e-03,  4.1066007689e-03, -2.4414195213e-03,\n",
      "        -4.5767603442e-03,  6.5297656693e-03, -2.0677701104e-03,\n",
      "         3.6815132480e-03, -2.3699959274e-03, -7.0966188796e-03,\n",
      "        -5.5032474920e-03,  5.0611882471e-03, -4.4836238958e-03,\n",
      "        -7.7222008258e-03,  7.4792080559e-03, -4.5299120247e-03,\n",
      "         8.2998247817e-03,  9.1332858428e-03,  3.0478576664e-03,\n",
      "         4.8068086617e-03,  8.9363707229e-03, -7.8855939209e-03,\n",
      "        -3.3567508217e-03, -6.3145733438e-03,  6.5458612517e-03,\n",
      "        -5.0532962196e-03, -9.7496388480e-03,  2.4384188000e-03,\n",
      "        -9.5950029790e-03,  1.7860828666e-03,  8.1823943183e-03,\n",
      "         6.8806395866e-03,  1.1234992417e-03, -5.6264591403e-03,\n",
      "        -7.9611735418e-03,  2.7609171811e-03,  5.4567540064e-03,\n",
      "        -3.7847801577e-03, -6.3396096230e-03,  3.4189640428e-04,\n",
      "        -5.0081145018e-03, -7.2948108427e-03, -2.9973480850e-03,\n",
      "         2.1866371389e-03,  6.9513772614e-03, -3.7531992421e-03,\n",
      "        -6.4220828936e-03, -8.2684215158e-03,  7.5755803846e-03,\n",
      "         4.7614327632e-03, -1.4730101684e-03,  8.5801270325e-04,\n",
      "         5.9895087034e-03, -3.2206024043e-03,  2.2726412863e-03,\n",
      "         6.5321624279e-03,  2.3346380331e-03,  9.6471766010e-03,\n",
      "        -1.5038663987e-03,  1.8232751172e-03, -3.5278692376e-03,\n",
      "         7.9415319487e-04,  9.4309896231e-03, -6.0626841150e-04,\n",
      "         2.2906062659e-03, -7.2932373732e-03,  7.9022459686e-03,\n",
      "        -9.1520957649e-03,  1.7637297278e-03,  3.3317939378e-03,\n",
      "         9.1670034453e-03,  1.7363810912e-03, -3.9199637249e-03,\n",
      "        -4.9943947233e-03, -1.2158968020e-03, -7.6240352355e-03,\n",
      "        -5.7152910158e-03,  4.0663899854e-03, -5.6352565298e-04,\n",
      "        -2.9148221947e-03, -8.4034064785e-03,  9.2453388497e-03,\n",
      "        -4.9714939669e-03,  3.6964893807e-03, -1.3335883850e-03,\n",
      "         7.7659492381e-03, -4.5000999235e-03, -8.2306778058e-03,\n",
      "        -4.6490048990e-03,  5.6106494740e-03, -4.2127789930e-03,\n",
      "         8.6708320305e-03,  7.7170026489e-03,  7.1296244860e-03,\n",
      "        -4.0762946010e-03, -1.8412682693e-03,  4.5618801378e-03,\n",
      "        -7.8952945769e-03,  9.1811995953e-03, -8.2481736317e-03,\n",
      "        -7.6484335586e-03, -8.7799923494e-03,  3.6399576347e-03,\n",
      "         9.7279017791e-03,  6.3158283010e-03,  7.0358314551e-03,\n",
      "         5.4751276039e-03,  3.2823837828e-03, -4.1479733773e-03,\n",
      "        -3.7159238127e-04,  5.8500962332e-03, -4.7317529097e-03,\n",
      "        -6.1907985946e-04, -6.9310893305e-03,  5.2435597172e-04,\n",
      "         8.5811521858e-03,  1.7373118317e-03, -6.1907316558e-03,\n",
      "        -2.4786293507e-03, -7.0098219439e-03, -3.4419505391e-03,\n",
      "         7.6092858799e-03, -4.4199493714e-03, -9.4830762828e-04,\n",
      "         5.2855429240e-03,  2.5706570596e-03])), ('fc2.weight', tensor([[-0.0031403352, -0.0023717717, -0.0421081111,  ...,\n",
      "         -0.0174237918,  0.0347014070, -0.0065325825],\n",
      "        [-0.0001147975, -0.0439092442,  0.0147901243,  ...,\n",
      "          0.0188876987,  0.0133829145,  0.0227271337],\n",
      "        [-0.0111768907, -0.0170953199,  0.0198662281,  ...,\n",
      "         -0.0185233448,  0.0067248773, -0.0189201515],\n",
      "        ...,\n",
      "        [-0.0053448789,  0.0435743444, -0.0309020001,  ...,\n",
      "         -0.0006705353,  0.0235857666,  0.0150498804],\n",
      "        [ 0.0277078282, -0.0440985002, -0.0187085904,  ...,\n",
      "         -0.0058323126,  0.0209896360,  0.0365711190],\n",
      "        [ 0.0386282913, -0.0180999003, -0.0388682298,  ...,\n",
      "          0.0266338848, -0.0374618024,  0.0102800373]])), ('fc2.bias', tensor([ 0.0411350057,  0.0202441420, -0.0306935105, -0.0256062653,\n",
      "        -0.0077419863,  0.0286896806, -0.0142072858,  0.0411892347,\n",
      "        -0.0083363727, -0.0346228704, -0.0390221290,  0.0312963612,\n",
      "         0.0123172794,  0.0114348400,  0.0260103531,  0.0196876470,\n",
      "         0.0428752154,  0.0067943879,  0.0400355086,  0.0066979718,\n",
      "        -0.0197164118,  0.0238280464, -0.0361837521,  0.0218594149,\n",
      "         0.0164278671,  0.0150814485,  0.0077093802,  0.0198504906,\n",
      "        -0.0203842800,  0.0236376859, -0.0047944570,  0.0095805051,\n",
      "        -0.0121834837,  0.0160191376, -0.0373735055,  0.0048209880,\n",
      "        -0.0313037708, -0.0003275548, -0.0199804250, -0.0335213318,\n",
      "         0.0341006629, -0.0246933382,  0.0126401614,  0.0004177543,\n",
      "        -0.0341725312, -0.0423081666,  0.0020352397,  0.0281752199,\n",
      "        -0.0131710954,  0.0245346762,  0.0227911193,  0.0269786827,\n",
      "        -0.0200221762,  0.0125538493,  0.0251189210,  0.0012467038,\n",
      "         0.0088334475, -0.0393558294, -0.0172670782,  0.0218359232,\n",
      "         0.0389217697,  0.0279409848, -0.0419440381, -0.0397228822,\n",
      "        -0.0281178951,  0.0062239883, -0.0079449024,  0.0357874557,\n",
      "         0.0201474372,  0.0048129591, -0.0418656282, -0.0354001336,\n",
      "        -0.0283737537,  0.0204536915,  0.0406294502,  0.0329002142,\n",
      "        -0.0241622925,  0.0413388759, -0.0261278376, -0.0200613514,\n",
      "        -0.0164509267,  0.0025250493,  0.0093335621,  0.0253388435,\n",
      "        -0.0163309295, -0.0268921554,  0.0231159963, -0.0125646126,\n",
      "        -0.0346394405,  0.0367098711, -0.0038623055,  0.0262127630,\n",
      "        -0.0147037497,  0.0145832514,  0.0299877767,  0.0246687606,\n",
      "        -0.0135199083, -0.0111623453, -0.0411592275, -0.0100658154,\n",
      "         0.0222265460,  0.0176464170, -0.0066804648, -0.0368485935,\n",
      "        -0.0199555475,  0.0168977398,  0.0104413126, -0.0158088449,\n",
      "         0.0200780146, -0.0218799505, -0.0078029460, -0.0016810850,\n",
      "        -0.0213906113, -0.0060232375,  0.0049015940,  0.0177958589,\n",
      "        -0.0289559811,  0.0404478312, -0.0068914574, -0.0307990573,\n",
      "         0.0165825244,  0.0082405200,  0.0386744589,  0.0267034955,\n",
      "        -0.0243223552, -0.0062763821, -0.0252844896,  0.0290291943,\n",
      "         0.0399950705, -0.0426840894,  0.0327392705,  0.0168140363,\n",
      "        -0.0299582537,  0.0008667973,  0.0313551985, -0.0157868452,\n",
      "         0.0130693689,  0.0073804925, -0.0090483958,  0.0197994728,\n",
      "         0.0320932828,  0.0293810740,  0.0048076385,  0.0067275483,\n",
      "         0.0041090017,  0.0027091836,  0.0410100669,  0.0234587081,\n",
      "        -0.0186955258, -0.0100587513, -0.0005278155,  0.0267227869,\n",
      "        -0.0256066862, -0.0354230814,  0.0095163630,  0.0272816010,\n",
      "         0.0106142676,  0.0387707502, -0.0044301501,  0.0355044305,\n",
      "        -0.0205340441,  0.0355650000, -0.0130040413, -0.0208277032,\n",
      "         0.0208010655,  0.0214283057,  0.0047370843, -0.0181678887,\n",
      "        -0.0365562327, -0.0286691543, -0.0187782180, -0.0134889456,\n",
      "        -0.0386539698, -0.0410879701, -0.0253965259, -0.0098783942,\n",
      "        -0.0101714572,  0.0413154922,  0.0309854820, -0.0317156091,\n",
      "         0.0352432504,  0.0423897542,  0.0046629850, -0.0110138990,\n",
      "        -0.0322478116,  0.0150383748, -0.0195975564,  0.0434235074,\n",
      "         0.0247370377,  0.0166654121,  0.0025086068,  0.0235292092,\n",
      "         0.0280899312,  0.0240228865, -0.0220444500,  0.0358320400,\n",
      "        -0.0341373198,  0.0420349054, -0.0291102529,  0.0091212364,\n",
      "         0.0294826888,  0.0287118498, -0.0147256926,  0.0100103822,\n",
      "         0.0127558913, -0.0238455385,  0.0093061822, -0.0388221256,\n",
      "         0.0331859328, -0.0208311640, -0.0016663600,  0.0122630578,\n",
      "         0.0236410201, -0.0184082892, -0.0051534111,  0.0097250585,\n",
      "         0.0021223309, -0.0266744290, -0.0282185059,  0.0349314436,\n",
      "         0.0230838805, -0.0396194793, -0.0267965384,  0.0111541683,\n",
      "        -0.0237547010, -0.0102559719, -0.0117851328,  0.0225087237,\n",
      "         0.0095735192,  0.0229013897,  0.0289062373,  0.0142161846,\n",
      "        -0.0208312273,  0.0012584470,  0.0335848741, -0.0122285550,\n",
      "         0.0389975123,  0.0219335891,  0.0141078196,  0.0372089483,\n",
      "        -0.0235194433,  0.0185055062,  0.0065734489,  0.0211539026,\n",
      "         0.0094307363,  0.0132303806,  0.0285755154,  0.0009199023,\n",
      "        -0.0242899451,  0.0153492922, -0.0205932613,  0.0195012782,\n",
      "        -0.0255862288, -0.0023374904,  0.0332505815, -0.0130242296])), ('pi.weight', tensor([[ 0.0490221530,  0.0555588156, -0.0160232484,  ...,\n",
      "         -0.0022515133, -0.0255600959, -0.0222368613],\n",
      "        [-0.0146297365, -0.0010458678, -0.0344341993,  ...,\n",
      "         -0.0523528680,  0.0401171595,  0.0430056527],\n",
      "        [ 0.0518585145, -0.0443392470,  0.0285437182,  ...,\n",
      "          0.0126461238,  0.0013638213, -0.0177936107],\n",
      "        ...,\n",
      "        [-0.0155679211,  0.0123596489, -0.0181023479,  ...,\n",
      "         -0.0577803105,  0.0081114620,  0.0228021443],\n",
      "        [-0.0320866704, -0.0437441990,  0.0306400731,  ...,\n",
      "         -0.0375618041, -0.0423698574, -0.0056825355],\n",
      "        [ 0.0064267740, -0.0394974798, -0.0477673709,  ...,\n",
      "          0.0622480735, -0.0064174086,  0.0105429739]])), ('pi.bias', tensor([-1.5377193689e-02, -2.2775821388e-02, -1.4624506235e-02,\n",
      "         3.4936048090e-02,  2.8250053525e-02,  4.1743159294e-02,\n",
      "        -4.2439147830e-02, -1.2067198753e-02,  5.1581926644e-02,\n",
      "         5.0308361650e-02,  4.7360196710e-02,  3.1483724713e-02,\n",
      "         3.7784852087e-02,  4.2798362672e-02, -2.4223700166e-02,\n",
      "         1.3127662241e-02, -5.9068128467e-02, -7.9415738583e-05,\n",
      "        -1.7243400216e-02, -1.3276882470e-02,  3.9503872395e-02,\n",
      "         1.9941210747e-02, -4.7266259789e-03, -2.7841925621e-02,\n",
      "         3.5028606653e-03, -3.5077273846e-02, -1.8068321049e-02,\n",
      "         1.7135210335e-02, -3.4487590194e-02,  6.1609193683e-02,\n",
      "         3.0484065413e-02,  2.6643879712e-02, -5.1726393402e-02,\n",
      "         5.2938386798e-03,  4.1412301362e-02, -8.1818699837e-03,\n",
      "        -2.8220333159e-02, -2.5838099420e-02, -2.1182708442e-02,\n",
      "        -2.4337925017e-02, -3.8082152605e-03,  4.3984740973e-02,\n",
      "        -5.3041979671e-02, -1.2679703534e-02, -1.2288928032e-02,\n",
      "        -4.1938632727e-02, -2.8220303357e-02, -4.6135708690e-02,\n",
      "         8.1402212381e-03,  4.1635274887e-02, -2.3634977639e-02,\n",
      "         5.4987475276e-02,  4.0795452893e-02,  5.8245167136e-02,\n",
      "        -3.7097610533e-02, -5.0608068705e-03,  2.1975278854e-02,\n",
      "         3.2850064337e-02,  2.0214460790e-02,  4.9717858434e-02,\n",
      "         7.0857331157e-03,  5.9026136994e-02,  3.2724387944e-02,\n",
      "         3.2057970762e-02,  2.1622397006e-02,  8.2314759493e-04,\n",
      "         3.5328999162e-02, -2.6573963463e-02,  1.7391368747e-03,\n",
      "         4.1205741465e-02, -3.6780394614e-02, -6.0966700315e-02,\n",
      "        -8.9003890753e-04, -3.5842768848e-02,  6.3069537282e-03,\n",
      "         5.0941504538e-02, -1.0198831558e-02,  2.4181529880e-02,\n",
      "        -4.5267425478e-02, -4.7931924462e-02, -1.1506304145e-02])), ('v.weight', tensor([[ 0.0234778672, -0.0439034328,  0.0033288226,  0.0491413251,\n",
      "          0.0144823343,  0.0094040111, -0.0222844258, -0.0366648287,\n",
      "          0.0563870221, -0.0077149123,  0.0211245418, -0.0038922057,\n",
      "         -0.0035927519,  0.0510554016,  0.0527722090, -0.0204211846,\n",
      "          0.0535692126, -0.0154277608,  0.0501304567,  0.0361720547,\n",
      "         -0.0470042303,  0.0357586369,  0.0418912470, -0.0469449684,\n",
      "         -0.0046575144, -0.0222588554, -0.0198587477, -0.0429424345,\n",
      "          0.0272252485,  0.0231596678, -0.0265326351,  0.0076012835,\n",
      "         -0.0576930195, -0.0344664901,  0.0135251954,  0.0369071439,\n",
      "         -0.0213236138,  0.0070009008,  0.0510156825,  0.0389098227,\n",
      "          0.0034745783, -0.0347782299,  0.0359657109, -0.0003191903,\n",
      "          0.0146201253, -0.0598497391, -0.0272661224,  0.0269770101,\n",
      "          0.0458253026, -0.0468745604,  0.0569151118, -0.0420628041,\n",
      "         -0.0397768617, -0.0153671876,  0.0413137376, -0.0601290837,\n",
      "          0.0445457622, -0.0151485726, -0.0222613364,  0.0447160155,\n",
      "          0.0500813797,  0.0133387893, -0.0471746251, -0.0107960850,\n",
      "         -0.0057286546, -0.0610199124, -0.0150580108,  0.0235880315,\n",
      "         -0.0335118696,  0.0026603267,  0.0609260872,  0.0288692117,\n",
      "         -0.0305265412, -0.0557909533, -0.0581873283,  0.0126916692,\n",
      "         -0.0146834478,  0.0347616896,  0.0363611430,  0.0344369113,\n",
      "          0.0186561346, -0.0357778519,  0.0075829327,  0.0183724165,\n",
      "         -0.0377893895, -0.0172811598, -0.0523118377,  0.0349509791,\n",
      "         -0.0044574738,  0.0372314751,  0.0155782253,  0.0468539968,\n",
      "          0.0065129548,  0.0365922749,  0.0515266284, -0.0305208191,\n",
      "          0.0502395853, -0.0110270754, -0.0509279147, -0.0580829233,\n",
      "         -0.0119730905,  0.0274653956,  0.0458121672, -0.0272913352,\n",
      "         -0.0002911165,  0.0310485810, -0.0347556844,  0.0034051463,\n",
      "         -0.0372085795, -0.0182825625,  0.0224057510,  0.0071214512,\n",
      "         -0.0305037647,  0.0113659352,  0.0213297233, -0.0476519838,\n",
      "          0.0264876932, -0.0423328951,  0.0400105119,  0.0155660361,\n",
      "          0.0164509043,  0.0319877416,  0.0573494956, -0.0221266299,\n",
      "         -0.0287630409, -0.0221028849,  0.0599413514,  0.0110582337,\n",
      "          0.0101630613, -0.0261835456, -0.0556782186, -0.0313642994,\n",
      "         -0.0317727178, -0.0469423607,  0.0503187180,  0.0475812182,\n",
      "          0.0569688976, -0.0130571723,  0.0614368170,  0.0333240181,\n",
      "         -0.0160696656,  0.0494764671, -0.0348572508,  0.0464573950,\n",
      "          0.0543427691, -0.0226367638,  0.0351823047, -0.0262467861,\n",
      "          0.0142736658,  0.0624970645, -0.0021751523,  0.0169192404,\n",
      "          0.0277369022,  0.0017007738, -0.0599438921, -0.0169048011,\n",
      "         -0.0571952015,  0.0010013357,  0.0078289285, -0.0196762756,\n",
      "         -0.0132763162,  0.0085944384, -0.0088405460,  0.0249240473,\n",
      "          0.0574225485,  0.0620396361,  0.0502229482, -0.0208790228,\n",
      "         -0.0416047871,  0.0360075831, -0.0248166025,  0.0174266323,\n",
      "         -0.0442516506, -0.0401447192, -0.0038629100,  0.0491122678,\n",
      "         -0.0589988008, -0.0518253222, -0.0511482507,  0.0144613087,\n",
      "          0.0436476842, -0.0179543719,  0.0333375558, -0.0415427238,\n",
      "          0.0036988780,  0.0176753923, -0.0078983009, -0.0434686840,\n",
      "          0.0428926721,  0.0560489371,  0.0245631337,  0.0089244545,\n",
      "         -0.0189492106,  0.0455368832,  0.0375167355, -0.0504293591,\n",
      "         -0.0398098826, -0.0329908133, -0.0264124498, -0.0470862240,\n",
      "          0.0587874204, -0.0084049031,  0.0057880133,  0.0160642639,\n",
      "          0.0424002260, -0.0059593394,  0.0249023139, -0.0537419543,\n",
      "         -0.0296171382, -0.0422774851, -0.0573927611, -0.0047639310,\n",
      "         -0.0098163784, -0.0605278909, -0.0405747145,  0.0478893816,\n",
      "          0.0406461284, -0.0526914075,  0.0121149793,  0.0551559627,\n",
      "         -0.0585893691,  0.0332027301, -0.0126020014,  0.0488136187,\n",
      "          0.0125792623,  0.0141978785, -0.0125565231,  0.0601007491,\n",
      "         -0.0496852919,  0.0552605465, -0.0475932509,  0.0333410874,\n",
      "         -0.0207303688,  0.0340556055, -0.0277845412, -0.0412127227,\n",
      "          0.0009997338, -0.0495490134,  0.0047622174, -0.0128738731,\n",
      "         -0.0050126836, -0.0388141796, -0.0024099052,  0.0469381884,\n",
      "          0.0561667830, -0.0530608222,  0.0048837885, -0.0115706697,\n",
      "         -0.0454047397, -0.0197983831,  0.0460124612, -0.0549898520,\n",
      "          0.0379358754,  0.0190384090,  0.0282781571, -0.0472525805]])), ('v.bias', tensor([-0.0520399511]))])\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "torch.set_printoptions(precision=10,threshold=2000)\n",
    "model = UTTT()  # Your model\n",
    "state_dict = model.state_dict()\n",
    "print(sum(p.numel() for p in model.parameters()))\n",
    "print(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2dbf7101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94330\n",
      "UTTT(\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.09, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.09, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=648, out_features=128, bias=True)\n",
      "  (pi): Linear(in_features=128, out_features=81, bias=True)\n",
      "  (v): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "OrderedDict([('conv1.weight', tensor([[[[ 0.2038275450, -0.1400500238, -0.0253705587],\n",
      "          [ 0.0976642817,  0.2959917784, -0.2481583804],\n",
      "          [-0.2956174612,  0.1206390485, -0.0556780919]]],\n",
      "\n",
      "\n",
      "        [[[-0.1393942535, -0.2853843868, -0.1149618253],\n",
      "          [ 0.1874097586, -0.0363383293,  0.0347592458],\n",
      "          [ 0.0054167113,  0.0915203542, -0.2663037479]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3215827346, -0.3106656969,  0.1523028612],\n",
      "          [ 0.3032392263, -0.0256567001, -0.2411995381],\n",
      "          [-0.0619821958,  0.0540222339, -0.2247215211]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0933838338, -0.0088364286, -0.2611546218],\n",
      "          [ 0.1203800067, -0.2055361718, -0.2929385304],\n",
      "          [ 0.2769640088, -0.1507977247, -0.3154134154]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0038482349, -0.2917054594,  0.3317433000],\n",
      "          [ 0.0990868434, -0.1697897613,  0.0431695394],\n",
      "          [-0.1963134706,  0.0793828592,  0.2037670612]]],\n",
      "\n",
      "\n",
      "        [[[-0.0668784827, -0.3265329599, -0.2941296995],\n",
      "          [ 0.1288257539,  0.2260332555, -0.2734954953],\n",
      "          [-0.0519816875, -0.2904534340,  0.1777779311]]],\n",
      "\n",
      "\n",
      "        [[[-0.0693958253, -0.2214454114, -0.0592139587],\n",
      "          [ 0.1491338909, -0.0591642484, -0.0409944877],\n",
      "          [-0.1489369869, -0.1218665838,  0.2336919755]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2818567157,  0.0901197195, -0.1738293618],\n",
      "          [-0.1354495734, -0.2852513492, -0.1800318211],\n",
      "          [-0.1708399951, -0.2766869962,  0.0159640312]]]])), ('bn1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1.])), ('bn1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0.])), ('bn1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0.])), ('bn1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1.])), ('bn1.num_batches_tracked', tensor(0)), ('conv2.weight', tensor([[[[ 0.0612304769, -0.0796695724,  0.0796850547],\n",
      "          [-0.0854519904,  0.0615894012, -0.0263537224],\n",
      "          [ 0.0430473574, -0.0268933140, -0.0664473623]],\n",
      "\n",
      "         [[-0.0546488687, -0.0877028555, -0.0219308883],\n",
      "          [ 0.1067534313, -0.0745223463, -0.0698976368],\n",
      "          [-0.1036858261,  0.0700144023, -0.0219869576]],\n",
      "\n",
      "         [[ 0.1020275205,  0.0312595293, -0.0598134324],\n",
      "          [ 0.0047112452, -0.0232953914, -0.1095616296],\n",
      "          [-0.0538077578,  0.0544454940, -0.0952959359]],\n",
      "\n",
      "         [[ 0.0499994382,  0.0240220465,  0.0724919587],\n",
      "          [ 0.0033094969, -0.0068398295, -0.0589782782],\n",
      "          [-0.0901891738,  0.0253502484, -0.0756528378]],\n",
      "\n",
      "         [[-0.0783395395,  0.0663302168,  0.0570211448],\n",
      "          [-0.0179746337,  0.0164084993, -0.1041355059],\n",
      "          [ 0.0375396349, -0.0125440117, -0.1100088805]],\n",
      "\n",
      "         [[-0.0383667536,  0.0066037648, -0.0471113548],\n",
      "          [ 0.0709745064,  0.0597547777, -0.1144916490],\n",
      "          [-0.0881196782,  0.0827159733, -0.0434054509]],\n",
      "\n",
      "         [[ 0.0631824806,  0.1101971120,  0.1000471488],\n",
      "          [-0.0120264208, -0.0913126767,  0.0029826763],\n",
      "          [-0.0796636418,  0.0304156393, -0.0885020047]],\n",
      "\n",
      "         [[-0.0314743407,  0.0451670364,  0.1087264791],\n",
      "          [-0.0340610743,  0.0856834054,  0.0485500358],\n",
      "          [-0.0219965801,  0.1065242887,  0.0148748588]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0513622165, -0.0830343217,  0.1149535775],\n",
      "          [ 0.0424993634,  0.0561164357,  0.0879737213],\n",
      "          [-0.0953940824, -0.1045987457, -0.0800856724]],\n",
      "\n",
      "         [[ 0.1019884497, -0.0151197184, -0.1121739522],\n",
      "          [ 0.0912999064, -0.1045558378,  0.0678694770],\n",
      "          [ 0.0360268466,  0.0402237177, -0.0450197197]],\n",
      "\n",
      "         [[-0.0259582307, -0.1010550484,  0.0833641067],\n",
      "          [-0.0070605949,  0.0004313870, -0.0845559314],\n",
      "          [ 0.0693605468, -0.0474878252,  0.0124489143]],\n",
      "\n",
      "         [[ 0.0906521007, -0.0217506252, -0.0294614621],\n",
      "          [ 0.0549258292,  0.0095419763,  0.0789343044],\n",
      "          [-0.0741429403,  0.0722291321, -0.1049970835]],\n",
      "\n",
      "         [[ 0.0628641993,  0.1066107601, -0.0711452439],\n",
      "          [-0.0966994241,  0.0104911234,  0.0366293751],\n",
      "          [-0.0741733089, -0.0634749681, -0.0107246591]],\n",
      "\n",
      "         [[ 0.0709918886,  0.0492956303, -0.0772278458],\n",
      "          [ 0.0214480963, -0.0366378464,  0.0710124224],\n",
      "          [-0.0137796029, -0.0359091870, -0.0020611074]],\n",
      "\n",
      "         [[ 0.1001119986,  0.1143679470,  0.0865625441],\n",
      "          [ 0.0596397594,  0.0268653147, -0.0136791393],\n",
      "          [ 0.0810460448, -0.1132005230,  0.0438920110]],\n",
      "\n",
      "         [[-0.0842542350,  0.0622645915, -0.1006147563],\n",
      "          [-0.0055002482, -0.1019091979, -0.0677237585],\n",
      "          [ 0.0687805414, -0.0098834364,  0.0897823125]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0232703425,  0.0010991336,  0.1093895733],\n",
      "          [-0.0132824387, -0.0690228567, -0.0650334433],\n",
      "          [-0.0114953564, -0.1072518751, -0.1082273200]],\n",
      "\n",
      "         [[ 0.0524209440, -0.0639143735, -0.0491887443],\n",
      "          [ 0.0284207724, -0.0060222647, -0.0327058695],\n",
      "          [-0.0457338132,  0.0939237177, -0.0671964660]],\n",
      "\n",
      "         [[-0.0186442491,  0.0602359399,  0.0601624474],\n",
      "          [ 0.0565250069,  0.0416495018,  0.0079539809],\n",
      "          [ 0.1124540567,  0.0100862188, -0.0701945201]],\n",
      "\n",
      "         [[ 0.0941745788,  0.1151788086, -0.0721834898],\n",
      "          [-0.1075908765, -0.1069278494, -0.0168800801],\n",
      "          [-0.0726368800, -0.0810407177,  0.0675005540]],\n",
      "\n",
      "         [[ 0.0338974185,  0.0350483358, -0.0488376319],\n",
      "          [ 0.1168069318, -0.0528364144,  0.0501768924],\n",
      "          [-0.0744079575, -0.0772767812, -0.0799343213]],\n",
      "\n",
      "         [[ 0.0289136227, -0.0699700788,  0.0946356207],\n",
      "          [ 0.0518937446,  0.0724752694, -0.0421350338],\n",
      "          [-0.0167875253, -0.0291105621,  0.0935151577]],\n",
      "\n",
      "         [[-0.0244846642,  0.0770013779, -0.0019775443],\n",
      "          [-0.0135488072, -0.0733333007,  0.0800396502],\n",
      "          [-0.0891469195,  0.0015366179, -0.1053755507]],\n",
      "\n",
      "         [[ 0.0953099281, -0.0603331029,  0.0970026851],\n",
      "          [-0.0194748230,  0.0200623497,  0.0124689061],\n",
      "          [-0.0448309556, -0.0077129435,  0.0671203211]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0819988176,  0.0576527864, -0.1128669679],\n",
      "          [-0.0414432213,  0.1111573949, -0.0757637620],\n",
      "          [-0.0068906303,  0.0779623166, -0.0452997983]],\n",
      "\n",
      "         [[ 0.1045917720, -0.0419015810,  0.0196787436],\n",
      "          [-0.0742280781,  0.0643140525,  0.1134278476],\n",
      "          [ 0.0968518555,  0.0080937687, -0.0479196049]],\n",
      "\n",
      "         [[ 0.0456482954, -0.0840866268,  0.0393061936],\n",
      "          [ 0.0913126394, -0.0279143639,  0.0168163404],\n",
      "          [-0.0462764390,  0.0134737156,  0.0946824029]],\n",
      "\n",
      "         [[-0.1154422238, -0.0765110850, -0.0001413043],\n",
      "          [ 0.1031958982,  0.0155138616,  0.1104515493],\n",
      "          [-0.0697171241, -0.0559642985,  0.0099145686]],\n",
      "\n",
      "         [[-0.0350864790,  0.0976639390, -0.0640480965],\n",
      "          [-0.0067647095,  0.0040974603, -0.0929961354],\n",
      "          [-0.1062829196,  0.1101263687,  0.0939484313]],\n",
      "\n",
      "         [[ 0.0457461476,  0.0800743923, -0.0396989174],\n",
      "          [-0.0406737477,  0.0043033338, -0.0959735140],\n",
      "          [ 0.0305584744, -0.0066642035, -0.0992826223]],\n",
      "\n",
      "         [[ 0.0152653921,  0.0220542513, -0.0949277580],\n",
      "          [-0.1152582690,  0.0356009081, -0.0904262885],\n",
      "          [ 0.0140986405, -0.1020959765, -0.0391490571]],\n",
      "\n",
      "         [[ 0.0004578131,  0.0305556506,  0.1153994501],\n",
      "          [-0.0153241865,  0.0968944281, -0.0039989213],\n",
      "          [-0.0428993963,  0.1067940146, -0.0457932949]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1043968722,  0.0781241283, -0.0468980782],\n",
      "          [-0.0545508191, -0.0057497434,  0.0737998784],\n",
      "          [-0.0437116064, -0.0637949705,  0.0539898761]],\n",
      "\n",
      "         [[-0.0587079898, -0.0095375227,  0.1173384860],\n",
      "          [-0.0803008452, -0.0236641485, -0.0539856739],\n",
      "          [ 0.0224483106,  0.0081786662,  0.0949413404]],\n",
      "\n",
      "         [[ 0.1060221121, -0.0474781431,  0.0931838006],\n",
      "          [ 0.0323263928,  0.0928659439,  0.0617229491],\n",
      "          [-0.0895190611, -0.1099418774, -0.0495410934]],\n",
      "\n",
      "         [[-0.0996421054, -0.0907194763,  0.0268896334],\n",
      "          [-0.0869223997, -0.0593620948, -0.0261439439],\n",
      "          [ 0.0710305497, -0.0235491302, -0.0971917287]],\n",
      "\n",
      "         [[ 0.0153017221,  0.0884546414,  0.0680097565],\n",
      "          [-0.0811938792,  0.0343756005, -0.0080785677],\n",
      "          [-0.0112498365,  0.0692661926, -0.0353726149]],\n",
      "\n",
      "         [[ 0.0322447419,  0.0921371430, -0.0033596659],\n",
      "          [ 0.0038604406, -0.0759142190,  0.1052040830],\n",
      "          [-0.0474329479,  0.0911633372, -0.1025313288]],\n",
      "\n",
      "         [[-0.0746858194,  0.0339308828, -0.0143742105],\n",
      "          [-0.0056551518,  0.0677493885,  0.0332171395],\n",
      "          [-0.1177529171,  0.0224249195, -0.0913288742]],\n",
      "\n",
      "         [[ 0.0747779906, -0.0830551982,  0.1166650057],\n",
      "          [ 0.0394856557,  0.0206377525,  0.0842999518],\n",
      "          [-0.0557265058, -0.1120703369, -0.0018821799]]],\n",
      "\n",
      "\n",
      "        [[[-0.0564347580,  0.0351256318,  0.0066974573],\n",
      "          [ 0.1009100527, -0.0782337934,  0.0700452253],\n",
      "          [-0.0738734081, -0.0446377695, -0.1100491732]],\n",
      "\n",
      "         [[ 0.0787753835, -0.0050519318, -0.0638129562],\n",
      "          [ 0.0232412480, -0.0077605275,  0.0052771927],\n",
      "          [-0.0510099642, -0.0605433173,  0.0930600315]],\n",
      "\n",
      "         [[-0.0158263519,  0.0942118466,  0.1069061682],\n",
      "          [-0.0294700321,  0.0253626388, -0.0094254119],\n",
      "          [ 0.1059238985,  0.0864605829, -0.0230328180]],\n",
      "\n",
      "         [[-0.0248306468,  0.0185015537, -0.0608760379],\n",
      "          [ 0.1164889187, -0.0716844425,  0.1118400171],\n",
      "          [-0.1154605076, -0.0254333057, -0.0082780067]],\n",
      "\n",
      "         [[ 0.0312134083, -0.0701675937,  0.0891986936],\n",
      "          [-0.1047948822, -0.0239079688,  0.1068744585],\n",
      "          [ 0.0207772031, -0.0191904437, -0.0963845849]],\n",
      "\n",
      "         [[-0.0165172666, -0.0961499587,  0.0597538352],\n",
      "          [ 0.0836485401,  0.0370449871, -0.0523709841],\n",
      "          [-0.0238424856,  0.0425823368,  0.0435608625]],\n",
      "\n",
      "         [[ 0.0812457502,  0.0889406651,  0.0816652775],\n",
      "          [ 0.1000977531,  0.0832564458, -0.0751200169],\n",
      "          [ 0.0071277767, -0.0609199256,  0.0889649168]],\n",
      "\n",
      "         [[-0.0780140534,  0.0234540608,  0.0367313847],\n",
      "          [ 0.0494231917,  0.0489171930,  0.0174126904],\n",
      "          [-0.0995924696, -0.0615248866,  0.0658634156]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0641844943,  0.0700346902,  0.1035220474],\n",
      "          [ 0.1010652035, -0.0521891937,  0.0465295017],\n",
      "          [ 0.0940556377, -0.0567594431, -0.0273348298]],\n",
      "\n",
      "         [[ 0.0612180457,  0.0152354259,  0.0814203918],\n",
      "          [-0.0104312189,  0.1151976883, -0.0348446965],\n",
      "          [ 0.0146619054,  0.0161345433, -0.0631623492]],\n",
      "\n",
      "         [[ 0.0700888187,  0.0442757010,  0.1003299430],\n",
      "          [-0.0983250737,  0.0016204480,  0.1070246324],\n",
      "          [-0.0709324703,  0.0741729885, -0.0811047256]],\n",
      "\n",
      "         [[-0.1149979308, -0.0606657676,  0.0253442060],\n",
      "          [-0.0348358192, -0.0602255426, -0.0166119561],\n",
      "          [ 0.1133914217,  0.1174231991, -0.0279057380]],\n",
      "\n",
      "         [[ 0.0281626508, -0.0074702199, -0.0870093182],\n",
      "          [-0.0798592195,  0.0907030776, -0.0872901306],\n",
      "          [-0.0949678794,  0.0171059445,  0.1097488627]],\n",
      "\n",
      "         [[-0.0320958234, -0.0780865327,  0.0708261207],\n",
      "          [ 0.0673418865,  0.0575078279,  0.0350848362],\n",
      "          [-0.0420435034, -0.0282665007, -0.0207650494]],\n",
      "\n",
      "         [[-0.0806444660, -0.0487876050,  0.0416630581],\n",
      "          [-0.0161174182,  0.0865462199,  0.0803921893],\n",
      "          [-0.0200221408,  0.0960207358,  0.1126122475]],\n",
      "\n",
      "         [[-0.1157481819, -0.0524606891, -0.0490793176],\n",
      "          [-0.0122284023, -0.0369242653,  0.1166977808],\n",
      "          [-0.0739310682, -0.0387296379,  0.1080133244]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1080846936, -0.0082266992,  0.0813790187],\n",
      "          [-0.0126763536,  0.0946239159,  0.1146928594],\n",
      "          [ 0.0424926355,  0.0442375019, -0.0060670669]],\n",
      "\n",
      "         [[ 0.0372558050, -0.0583663471,  0.0020902026],\n",
      "          [ 0.0877087712,  0.0022837971, -0.1093422547],\n",
      "          [ 0.0543902256, -0.1051384211,  0.1135185584]],\n",
      "\n",
      "         [[-0.1032986641, -0.0594982430,  0.0896799788],\n",
      "          [ 0.0975355506, -0.0998829305,  0.1056448817],\n",
      "          [ 0.0271926969, -0.0061532431, -0.0732608289]],\n",
      "\n",
      "         [[-0.0994275883,  0.0770648420, -0.0790420473],\n",
      "          [ 0.1148935482,  0.0779419169, -0.0056737526],\n",
      "          [ 0.0641647279,  0.0927167907,  0.0883908048]],\n",
      "\n",
      "         [[-0.0546339080, -0.0132948160,  0.0729973614],\n",
      "          [ 0.0033905173,  0.0534193181, -0.0716534480],\n",
      "          [ 0.1142113134,  0.0477058478, -0.0274281576]],\n",
      "\n",
      "         [[-0.0956228822,  0.1132247299, -0.0589842610],\n",
      "          [ 0.0937460139,  0.1070279032, -0.0876987576],\n",
      "          [ 0.0846962035, -0.1040014923, -0.0531620979]],\n",
      "\n",
      "         [[ 0.0709450766,  0.0593850352, -0.0286007822],\n",
      "          [-0.1051039323, -0.1152677536,  0.0825435072],\n",
      "          [-0.1109969020, -0.0418234132, -0.0810720474]],\n",
      "\n",
      "         [[-0.0895668864,  0.0091867205, -0.0578973368],\n",
      "          [-0.0851817280, -0.0864676014,  0.0011388219],\n",
      "          [ 0.0916149542, -0.0152189182, -0.1041902304]]]])), ('bn2.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1.])), ('bn2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0.])), ('bn2.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0.])), ('bn2.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1.])), ('bn2.num_batches_tracked', tensor(0)), ('fc1.weight', tensor([[ 0.0149811776, -0.0299334899, -0.0341525525,  ...,\n",
      "         -0.0164007675, -0.0295382366, -0.0062086806],\n",
      "        [-0.0007888438,  0.0021117867, -0.0252349302,  ...,\n",
      "         -0.0328716971, -0.0030495166, -0.0212094150],\n",
      "        [-0.0028805733,  0.0060092793, -0.0373857580,  ...,\n",
      "         -0.0345208645, -0.0327798575, -0.0172449406],\n",
      "        ...,\n",
      "        [-0.0379391573,  0.0155951446,  0.0095217228,  ...,\n",
      "          0.0286965352,  0.0219553243,  0.0026465319],\n",
      "        [-0.0198930837, -0.0235405415, -0.0191515796,  ...,\n",
      "          0.0069029001,  0.0273299478,  0.0214631706],\n",
      "        [ 0.0084411241,  0.0359082557, -0.0331031159,  ...,\n",
      "         -0.0012330997, -0.0319565795, -0.0262464490]])), ('fc1.bias', tensor([-2.5800732896e-02, -2.4280674756e-02,  2.5897877291e-02,\n",
      "         6.8685878068e-03, -2.6692720130e-02, -8.2132313401e-03,\n",
      "        -9.8479390144e-03, -3.7345527671e-03,  2.5937638711e-03,\n",
      "        -3.3997438848e-02,  3.5263318568e-02,  9.0891553555e-04,\n",
      "        -2.6910917833e-02,  1.0663981549e-02,  6.1776512302e-03,\n",
      "         1.2906910852e-02, -3.3925820142e-02, -3.7979215384e-02,\n",
      "         2.6251398958e-04, -4.0986030363e-03,  3.3492555376e-03,\n",
      "        -3.1197581440e-02,  4.6013868414e-03,  3.4895904362e-02,\n",
      "         3.7347629666e-02, -1.0664618574e-02, -2.6418853551e-02,\n",
      "         6.3946791925e-03, -4.3596890755e-03, -3.4454174340e-02,\n",
      "         3.3582821488e-02, -2.3877816275e-02,  3.0816344544e-02,\n",
      "        -8.1414273009e-03,  1.7450716114e-03,  3.5187914968e-02,\n",
      "         5.2316556685e-03,  1.8057152629e-02,  1.9933918491e-02,\n",
      "         3.7860356271e-02,  9.3499645591e-03,  2.3177217692e-02,\n",
      "         1.1348324828e-02, -1.0984874098e-03, -2.7729531750e-02,\n",
      "         6.5896082669e-03, -3.5682179034e-02,  1.9391518086e-02,\n",
      "        -1.1892904527e-02, -1.3635559939e-02, -7.8749377280e-03,\n",
      "         6.1148474924e-03,  2.2382922471e-02, -1.5261355788e-02,\n",
      "        -7.8541121911e-04,  1.5286474954e-03,  3.5804297775e-02,\n",
      "        -1.0794047266e-02,  3.4756343812e-02,  1.1248826049e-02,\n",
      "         4.5792879537e-03, -1.7177918926e-02, -2.2060686722e-02,\n",
      "         2.5027258322e-02,  2.2008990869e-02, -2.4383539334e-02,\n",
      "        -9.8193921149e-03,  8.1947524450e-05,  3.1862746924e-02,\n",
      "        -2.8974438086e-02, -2.1006036550e-02,  3.7641821109e-05,\n",
      "        -3.1712684780e-02,  3.6246612668e-02,  1.9153144211e-02,\n",
      "         1.5899300575e-02,  2.0440313965e-02,  9.6987159923e-03,\n",
      "         3.5307660699e-02, -3.5844225436e-02, -1.5190535225e-02,\n",
      "        -1.6536222771e-02, -1.9940774888e-02,  1.2784544197e-06,\n",
      "         1.0617222637e-02, -2.8482512571e-03, -3.6199912429e-02,\n",
      "        -3.2432444394e-02,  2.6648586616e-02,  1.2202261947e-02,\n",
      "         1.5975623392e-03,  5.8885659091e-03, -3.2107564621e-03,\n",
      "         6.2208096497e-03, -2.0563635975e-02, -1.0561335832e-02,\n",
      "        -3.5989335738e-03,  2.6288526133e-02, -1.2550606392e-02,\n",
      "        -2.0812667906e-02, -1.6377726570e-02, -3.2158445567e-02,\n",
      "         2.9225505888e-02,  1.9048063084e-02,  1.8875878304e-02,\n",
      "        -3.8547597826e-02, -8.6033381522e-03,  1.5831930563e-02,\n",
      "        -1.1627800995e-03, -1.0037112981e-02, -8.0168973655e-03,\n",
      "         5.8884206228e-03,  2.5580201298e-02, -7.6891778735e-04,\n",
      "        -1.4344680123e-02,  9.9761830643e-03, -6.0733375140e-03,\n",
      "         3.3835429698e-02, -3.2363541424e-02,  2.1640038118e-02,\n",
      "        -1.5161627380e-04, -1.6876844689e-02,  3.0726285651e-02,\n",
      "        -2.3731505498e-02,  2.1904200315e-02, -2.1604433656e-02,\n",
      "        -2.6558144018e-02, -3.1737860292e-02])), ('pi.weight', tensor([[-0.0037680019,  0.0369099118,  0.0008119274,  ...,\n",
      "          0.0837251171,  0.0368038192, -0.0392149650],\n",
      "        [-0.0181240924, -0.0874741524, -0.0071467357,  ...,\n",
      "         -0.0720603019, -0.0108455643,  0.0399167202],\n",
      "        [-0.0751737803,  0.0697542951, -0.0804197565,  ...,\n",
      "         -0.0880732909,  0.0596129633,  0.0779532269],\n",
      "        ...,\n",
      "        [ 0.0630142689, -0.0129596181,  0.0440728962,  ...,\n",
      "          0.0028767437,  0.0599394031,  0.0594129451],\n",
      "        [ 0.0653354079,  0.0747994781, -0.0035370898,  ...,\n",
      "         -0.0024974009, -0.0431337692,  0.0640927106],\n",
      "        [-0.0572381057,  0.0704250783, -0.0862866491,  ...,\n",
      "          0.0217780452,  0.0331567787, -0.0082810232]])), ('pi.bias', tensor([ 0.0846718475, -0.0847252980,  0.0149501720,  0.0495727547,\n",
      "        -0.0052036396,  0.0686037540,  0.0255078617,  0.0324536934,\n",
      "        -0.0857688114,  0.0085485717,  0.0119928960, -0.0819216818,\n",
      "        -0.0085920775, -0.0033185584, -0.0814088285,  0.0378758349,\n",
      "         0.0080684451, -0.0111521510, -0.0213335641, -0.0148722949,\n",
      "        -0.0555472262, -0.0185795203,  0.0871853828, -0.0832969248,\n",
      "        -0.0108086122,  0.0469658338,  0.0703138933,  0.0813452825,\n",
      "        -0.0686432347,  0.0700338706, -0.0800728276,  0.0156482402,\n",
      "        -0.0505810343,  0.0202202238, -0.0707250461,  0.0595826395,\n",
      "         0.0164478701,  0.0264935400,  0.0686508790,  0.0508682206,\n",
      "        -0.0611997396, -0.0270932056,  0.0583660081,  0.0318777673,\n",
      "         0.0549913310,  0.0388552733,  0.0219055396, -0.0525277965,\n",
      "         0.0423067957,  0.0762644708,  0.0640381426,  0.0208313428,\n",
      "         0.0331667252,  0.0342090167,  0.0024330427,  0.0169833042,\n",
      "         0.0149486233,  0.0869358629, -0.0660740882, -0.0309741180,\n",
      "        -0.0056968522,  0.0790430382, -0.0849361792,  0.0750190318,\n",
      "         0.0516430810,  0.0382583812,  0.0779336914, -0.0392048173,\n",
      "        -0.0194954779, -0.0729048550, -0.0488718934, -0.0050035156,\n",
      "         0.0276547279,  0.0776122212, -0.0492568947,  0.0186264403,\n",
      "        -0.0310271811,  0.0290265437, -0.0805940852,  0.0075510819,\n",
      "        -0.0194443855])), ('v.weight', tensor([[-0.0374430902, -0.0361184143,  0.0490534715,  0.0786763355,\n",
      "          0.0770780072, -0.0873327255, -0.0093441252, -0.0162427947,\n",
      "         -0.0533477850, -0.0385487713,  0.0721111670,  0.0775533319,\n",
      "          0.0513995998,  0.0009421823,  0.0348568447,  0.0397467837,\n",
      "          0.0089734541,  0.0176849551, -0.0044034394, -0.0535516255,\n",
      "         -0.0085784746, -0.0024752421,  0.0132437935,  0.0103526358,\n",
      "          0.0541048683, -0.0856107250, -0.0575287305,  0.0008482264,\n",
      "         -0.0283104070,  0.0620832555, -0.0393714346,  0.0450813733,\n",
      "         -0.0012995559, -0.0121691860, -0.0008819333,  0.0747963339,\n",
      "         -0.0794913247, -0.0631150082,  0.0867139548, -0.0008330852,\n",
      "         -0.0244844835, -0.0787267312,  0.0666803047, -0.0046665096,\n",
      "         -0.0668265149,  0.0032757900,  0.0011353202, -0.0349122137,\n",
      "          0.0561158955, -0.0195350219, -0.0762044415, -0.0166375637,\n",
      "         -0.0374525003,  0.0788426548,  0.0214137807, -0.0489290990,\n",
      "         -0.0055737626, -0.0430740453,  0.0601694919, -0.0383590162,\n",
      "          0.0479114093, -0.0002155917,  0.0542028472,  0.0048758108,\n",
      "          0.0141785899,  0.0385958701,  0.0782404467,  0.0058067502,\n",
      "          0.0230053719, -0.0525413863,  0.0154245868,  0.0651270375,\n",
      "          0.0244248994, -0.0541200712, -0.0225252043,  0.0031467048,\n",
      "          0.0653314590, -0.0658707470,  0.0533836931, -0.0850220546,\n",
      "         -0.0147733763, -0.0325662792,  0.0805227235, -0.0088022742,\n",
      "         -0.0679843500, -0.0527054220, -0.0785157531, -0.0689835548,\n",
      "          0.0838468894, -0.0554592349, -0.0037513117,  0.0020934129,\n",
      "         -0.0225069746, -0.0264663976, -0.0452547893,  0.0461308956,\n",
      "         -0.0817381442,  0.0754215419, -0.0430394746, -0.0853715390,\n",
      "          0.0296197832,  0.0384183377,  0.0345241055,  0.0668072626,\n",
      "          0.0522712357,  0.0469945036,  0.0146765541,  0.0659191757,\n",
      "         -0.0384645313,  0.0872158706,  0.0260364469, -0.0879105777,\n",
      "         -0.0859530717, -0.0614847168,  0.0644389614,  0.0545880161,\n",
      "          0.0435027555, -0.0386105180, -0.0043054270, -0.0737684667,\n",
      "          0.0451593660, -0.0068332581, -0.0115191340,  0.0769624338,\n",
      "         -0.0576292723,  0.0266141966, -0.0511103012,  0.0499553941]])), ('v.bias', tensor([-0.0883096904]))])\n"
     ]
    }
   ],
   "source": [
    "#torch.set_printoptions(precision=10,threshold=float(\"inf\"))\n",
    "\n",
    "model=UTTT(False,4,\"MIN\")\n",
    "print(sum(p.numel() for p in model.parameters()))\n",
    "print(model)\n",
    "state_dict = model.state_dict()\n",
    "print(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5df76272",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict_serializable = {k: v.tolist() for k, v in state_dict.items()}  \n",
    "with open(\"model_weights.json\", \"w\") as f:\n",
    "    json.dump(state_dict_serializable, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acfeb7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
